{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Hello \ud83d\udc4b\ud83c\udffd # Welcome to my BITS WILP Knowledge Base. This is a personal note book for all the notes I take as part of my journey here at BITS. To know more about what a knowledge base is check this out. So what is the purpose of this? \ud83e\udd37\ud83c\udffd\u200d\u2642\ufe0f # My learning method includes taking a lot of notes through a local note taking tool called Obsidian . This website simply hosts that vault of Obsidian notes. The purpose of this page is to make the notes taken throughout my coursework accessible to myself and others in the same boat as me. Maybe this can help you too \ud83e\udd18\ud83c\udffd To know more about Obsidian and what it is, you can read about it in my blog article here So what now? \ud83d\udc81\ud83c\udffd\u200d\u2642\ufe0f # Now that you know what this page is all about, dive into the !KBIndex page to enter the first index page to this knowledge base. :)","title":"Hello \ud83d\udc4b\ud83c\udffd"},{"location":"index.html#hello-","text":"Welcome to my BITS WILP Knowledge Base. This is a personal note book for all the notes I take as part of my journey here at BITS. To know more about what a knowledge base is check this out.","title":"Hello \ud83d\udc4b\ud83c\udffd"},{"location":"index.html#so-what-is-the-purpose-of-this-","text":"My learning method includes taking a lot of notes through a local note taking tool called Obsidian . This website simply hosts that vault of Obsidian notes. The purpose of this page is to make the notes taken throughout my coursework accessible to myself and others in the same boat as me. Maybe this can help you too \ud83e\udd18\ud83c\udffd To know more about Obsidian and what it is, you can read about it in my blog article here","title":"So what is the purpose of this? \ud83e\udd37\ud83c\udffd\u200d\u2642\ufe0f"},{"location":"index.html#so-what-now-","text":"Now that you know what this page is all about, dive into the !KBIndex page to enter the first index page to this knowledge base. :)","title":"So what now? \ud83d\udc81\ud83c\udffd\u200d\u2642\ufe0f"},{"location":"about.html","text":"About Me \ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb # I am Akhil Sudhakaran, a full time software developer based in Bangalore, currently pursuing a masters program through BITS WILP. This Knowledge Base is hosted via . If you are interested in contributing, do check the above link out. My online presence #","title":"About Me \ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb"},{"location":"about.html#about-me-","text":"I am Akhil Sudhakaran, a full time software developer based in Bangalore, currently pursuing a masters program through BITS WILP. This Knowledge Base is hosted via . If you are interested in contributing, do check the above link out.","title":"About Me \ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb"},{"location":"about.html#my-online-presence","text":"","title":"My online presence"},{"location":"Knowledge%20Base/%21KBIndex.html","text":"Knowledge Base Index # This page is an index for all semesters Title Link Induction Orienation InductionOrienatation All Semesters Index !AllSemestersIndex","title":"Knowledge Base Index"},{"location":"Knowledge%20Base/%21KBIndex.html#knowledge-base-index","text":"This page is an index for all semesters Title Link Induction Orienation InductionOrienatation All Semesters Index !AllSemestersIndex","title":"Knowledge Base Index"},{"location":"Knowledge%20Base/InductionOrienatation.html","text":"WILP Induction Orientation Details # The BITS WILP (Work Integrated earning Program) is exclusively meant for the working professionals to make them remain relevant, employable and grow in their chosen profession while contributing to their organization, sector and society. Platforms and services for accessing content # The BITS Work Integrated Learning Program has the following services for access to content from emails, to courses and other resources Service URL What it is for Impartus http://a.impartus.com/login/#/ Platform to join and watch live lectures that are conducted ELearn Portal https://elearn.bits-pilani.ac.in/ Single platform for Taxila courses, Old Materials and important announcements Email @wilp.bits-pilani.ac.in All Institution Communications Apart from the above services, students also have access to Experimental Learning through Virtual Labs and Remote Labs. Students also have access to an eLibrary where one have access to academic publications (Through Open VPN) General Orientation # Grading Procedure # Students are graded with relative grading Letter grades Range from A, A-, B, B-, C, C-, D and E where each letter corresponds to grade points 10, 9, 8, 7, 6, 5, 4 and 2 respectively For project work a non-letter grade is awarded such as EXCELLENT, GOOD, FAIR and POOR. If a student is absent for any of the written examination, the student will be declared as a RRA (Required to Register Again) for that course. The CGPA awarded in a 10 point scale is calculated as: \\[ CGPA = {(U_1G_1 + U_2G_2 + U_3G_3 + U_4G_4)\\over(U1 + U2 + U3 + U4)} \\] Where U 1 , U 2 , U 3 and U 4 denote the Units associated with the courses taken G 1 , G 2 , G 3 and G 4 denote the Grade Points awarded in the respective courses. Non Letter Grades DO NOT go into CGPA Computation General Examination Schedules and Evaluative Components # Two exams are conducted throughout the semester. A mid semester Test A Comprehensive Exam Each of these two exams are conducted twice as a regular mode and a make up mode where one can take an examination at a separate date if one was not able to join the regular exam. Evaluative Components: # Evaluative Component Name Type Duration Session Weightage EC-1 Quizzes/Assignments/Labs Online As per course handouts As per course page ~20% EC-2 Mid-Semester Test Online Open Book 2 Hours Friday, Saturday and Sunday ~30% EC-3 Quizzes/Assignments/Labs Online Open Book 2 Hours Friday, Saturday and Sunday ~50% Program Specific Orientation (Software Systems with Data Analytics Specialization) # Course Structure # The MTech courses consists of 4 Core courses and 8 elective courses along with a dissertation. The Core courses are as follows: 1. Data Structures and Algorithms Design 2. Database Design and Applications 3. Distributed Computing 4. Software Architectures The General pool of electives are as follows: 1. Artifical Intelligence 2. Computer Organization 3. Distributed Data Systems 4. Software Engineering and Mangement 5. Usability Engineering 6. Object OPriented Analysis and Design The Specialization pool of electives for Data Analytics are as follows: 1. Adv. Statistical Techniques for Analytics 2. Applied Machine Learning 3. Metaheuristics for Optimization 4. Data Mining 5. Data Warehousing 6. Deep Learning 7. Information Retrieval 8. Mathematical Foundations for Data Science (This is a mandatory course for this specialization) 9. Natural Language Processing Semester Organization for Software Systems # Year Semester I Units Semester II Units I Data Structures & Algorithms Design 5 Software Architectures 5 DataBase Design & Applications 5 Elective 2 3(min) Distributed Computing 5 Elective 3 3(min) Elective 1 3(min) Elective 4 4(min) TOTAL 18(min) TOTAL 15(min) II Elective 5 3(min) Elective 6 3(min) Disertation 16 Elective 7 3(min) Elective 8 3(min) TOTAL 14(min) TOTAL 16","title":"WILP Induction Orientation Details"},{"location":"Knowledge%20Base/InductionOrienatation.html#wilp-induction-orientation-details","text":"The BITS WILP (Work Integrated earning Program) is exclusively meant for the working professionals to make them remain relevant, employable and grow in their chosen profession while contributing to their organization, sector and society.","title":"WILP Induction Orientation Details"},{"location":"Knowledge%20Base/InductionOrienatation.html#platforms-and-services-for-accessing-content","text":"The BITS Work Integrated Learning Program has the following services for access to content from emails, to courses and other resources Service URL What it is for Impartus http://a.impartus.com/login/#/ Platform to join and watch live lectures that are conducted ELearn Portal https://elearn.bits-pilani.ac.in/ Single platform for Taxila courses, Old Materials and important announcements Email @wilp.bits-pilani.ac.in All Institution Communications Apart from the above services, students also have access to Experimental Learning through Virtual Labs and Remote Labs. Students also have access to an eLibrary where one have access to academic publications (Through Open VPN)","title":"Platforms and services for accessing content"},{"location":"Knowledge%20Base/InductionOrienatation.html#general-orientation","text":"","title":"General Orientation"},{"location":"Knowledge%20Base/InductionOrienatation.html#grading-procedure","text":"Students are graded with relative grading Letter grades Range from A, A-, B, B-, C, C-, D and E where each letter corresponds to grade points 10, 9, 8, 7, 6, 5, 4 and 2 respectively For project work a non-letter grade is awarded such as EXCELLENT, GOOD, FAIR and POOR. If a student is absent for any of the written examination, the student will be declared as a RRA (Required to Register Again) for that course. The CGPA awarded in a 10 point scale is calculated as: \\[ CGPA = {(U_1G_1 + U_2G_2 + U_3G_3 + U_4G_4)\\over(U1 + U2 + U3 + U4)} \\] Where U 1 , U 2 , U 3 and U 4 denote the Units associated with the courses taken G 1 , G 2 , G 3 and G 4 denote the Grade Points awarded in the respective courses. Non Letter Grades DO NOT go into CGPA Computation","title":"Grading Procedure"},{"location":"Knowledge%20Base/InductionOrienatation.html#general-examination-schedules-and-evaluative-components","text":"Two exams are conducted throughout the semester. A mid semester Test A Comprehensive Exam Each of these two exams are conducted twice as a regular mode and a make up mode where one can take an examination at a separate date if one was not able to join the regular exam.","title":"General Examination Schedules and Evaluative Components"},{"location":"Knowledge%20Base/InductionOrienatation.html#evaluative-components","text":"Evaluative Component Name Type Duration Session Weightage EC-1 Quizzes/Assignments/Labs Online As per course handouts As per course page ~20% EC-2 Mid-Semester Test Online Open Book 2 Hours Friday, Saturday and Sunday ~30% EC-3 Quizzes/Assignments/Labs Online Open Book 2 Hours Friday, Saturday and Sunday ~50%","title":"Evaluative Components:"},{"location":"Knowledge%20Base/InductionOrienatation.html#program-specific-orientation-software-systems-with-data-analytics-specialization","text":"","title":"Program Specific Orientation (Software Systems with Data Analytics Specialization)"},{"location":"Knowledge%20Base/InductionOrienatation.html#course-structure","text":"The MTech courses consists of 4 Core courses and 8 elective courses along with a dissertation. The Core courses are as follows: 1. Data Structures and Algorithms Design 2. Database Design and Applications 3. Distributed Computing 4. Software Architectures The General pool of electives are as follows: 1. Artifical Intelligence 2. Computer Organization 3. Distributed Data Systems 4. Software Engineering and Mangement 5. Usability Engineering 6. Object OPriented Analysis and Design The Specialization pool of electives for Data Analytics are as follows: 1. Adv. Statistical Techniques for Analytics 2. Applied Machine Learning 3. Metaheuristics for Optimization 4. Data Mining 5. Data Warehousing 6. Deep Learning 7. Information Retrieval 8. Mathematical Foundations for Data Science (This is a mandatory course for this specialization) 9. Natural Language Processing","title":"Course Structure"},{"location":"Knowledge%20Base/InductionOrienatation.html#semester-organization-for-software-systems","text":"Year Semester I Units Semester II Units I Data Structures & Algorithms Design 5 Software Architectures 5 DataBase Design & Applications 5 Elective 2 3(min) Distributed Computing 5 Elective 3 3(min) Elective 1 3(min) Elective 4 4(min) TOTAL 18(min) TOTAL 15(min) II Elective 5 3(min) Elective 6 3(min) Disertation 16 Elective 7 3(min) Elective 8 3(min) TOTAL 14(min) TOTAL 16","title":"Semester Organization for Software Systems"},{"location":"Knowledge%20Base/All%20Semesters/%21AllSemestersIndex.html","text":"All Semesters Index # This page is an index for all semesters Semester Index Semster 1 !Semester1Index Semster 2 Semster 3 Semster 4","title":"All Semesters Index"},{"location":"Knowledge%20Base/All%20Semesters/%21AllSemestersIndex.html#all-semesters-index","text":"This page is an index for all semesters Semester Index Semster 1 !Semester1Index Semster 2 Semster 3 Semster 4","title":"All Semesters Index"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/%21Semester1Index.html","text":"Semester 1 Index # Linked pages to subjects # Datastructures and Algorithms: !DatastructuresAndAlgorithmsIndex Distributed Computing: !DistributedComputingIndex Database Design and Application: !DatabaseDesignAndApplicationIndex Mathematical Foundation for Data Science: !MathematicalFoundationsIndex Lecturer Contact Details # Datastuctures and Algorithms : Pritam Bhattacharya Distributed Computing : Barsha Mitra Database Design and Application : Uma Maheswari Mathematical Foundation for Data Science : Instructor : G Venkiteswaran TA : Aparna Ramesh Kumar Tags: !AllSemestersIndex","title":"Semester 1 Index"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/%21Semester1Index.html#semester-1-index","text":"","title":"Semester 1 Index"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/%21Semester1Index.html#linked-pages-to-subjects","text":"Datastructures and Algorithms: !DatastructuresAndAlgorithmsIndex Distributed Computing: !DistributedComputingIndex Database Design and Application: !DatabaseDesignAndApplicationIndex Mathematical Foundation for Data Science: !MathematicalFoundationsIndex","title":"Linked pages to subjects"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/%21Semester1Index.html#lecturer-contact-details","text":"Datastuctures and Algorithms : Pritam Bhattacharya Distributed Computing : Barsha Mitra Database Design and Application : Uma Maheswari Mathematical Foundation for Data Science : Instructor : G Venkiteswaran TA : Aparna Ramesh Kumar Tags: !AllSemestersIndex","title":"Lecturer Contact Details"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/%21DatabaseDesignAndApplicationIndex.html","text":"Database Design and Application Index # This is an Index page for all Database Design and Application Content Week 1 Lecture Notes: Week1DBA Week 2 Lecture Notes: Week2DBA Week 3 Lecture Notes: Week3DBA Week 5 Lecture Notes: Week5DBA Week 6 Lecture Notes: Week6DBA Tags: !Semester1Index","title":"Database Design and Application Index"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/%21DatabaseDesignAndApplicationIndex.html#database-design-and-application-index","text":"This is an Index page for all Database Design and Application Content Week 1 Lecture Notes: Week1DBA Week 2 Lecture Notes: Week2DBA Week 3 Lecture Notes: Week3DBA Week 5 Lecture Notes: Week5DBA Week 6 Lecture Notes: Week6DBA Tags: !Semester1Index","title":"Database Design and Application Index"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html","text":"Week 1 # Lecturer : Uma Maheswari, Faculty for BITS Pilani WILP Date : 24/Jul/2021 Topics Covered # Intro to DBMS Advantages of DBMS Operations of DBMS # Database catalogue or dictionary is the metadata used by DBMS to save the information about the type of data, structures and constraints of the data. Constructing the database is the process of storing the data on some stoprage and medium that is controlled by the DBMS Manipulating a DB includes functions such as querying the DB to retrieve specidic data, updating the DB and querying the DB Sharing the db regfers to sharing it via a server access to DB - Embedded SQL ( EXEC block in C programming language) - Create a special API to call SQL commands (JDBC, ODBC) - Allow external code to be executed from within SQL How to design database # Three layer Architecture # Each layer handles two issues External Layer # The above shows two views generated Conceptual layer # shows stored data in terms of the data model of the DBMS Ina relational DBMS the conceptial schema descibes all relations that are stored in the DB This couse is aimed at this level Physical Layer: # FM -> DM -> BM All data is stored in the form of pages, and the file manager keeps track of these The Disk manager brings it to memory 1. Specify additional storage details 2. File organization 3. ETL (Extract Transform Load) # Pysicall data independence # irrespective of where the data is Mapping # Allow for external code to be executed from within SQL EXECUTE can be used to run external scripts example python protection Sys protection (Against hw and sw) sec protection (against unauth) Characteristics of DB # self describing nature : there exists a data called meta data that describes the structure database. This is used by DBMS software and DB users who need infor about db structure Insulation between programs and data : There exists a data abstraction. The interface that allows for a program to access the data in the form of functions Support for multiple views : subsets of the database, contains vcirtual data derived from databse files but is not explicitly stored. Multi User DBMS allow users to use distinct apps and must provide facilities to create multiple views Sharing of data concurrency control software(make sure that multi user changes on data is controlled), Online transaction processing (OLTP) application Transactions are rolled back since it is not commited Example architecture # Data independence : all schemas are logical and the actual data is stored in bots in disk, so they both are inherently separate Mapping : The act of mapping two levels in a 3 level DBMS System catalog # It contains information such as: - user accounts/default settings - priveledges - performance stats - object sizing - object growth - table str - index str - table constraints - user sessions - internal db settings - location of DB files CRUD # Create Read Update Delete ERP and CRM # History # DBMS WORKERS or Users # Tags: !DatabaseDesignAndApplicationIndex","title":"Week 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#week-1","text":"Lecturer : Uma Maheswari, Faculty for BITS Pilani WILP Date : 24/Jul/2021","title":"Week 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#topics-covered","text":"Intro to DBMS Advantages of DBMS","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#operations-of-dbms","text":"Database catalogue or dictionary is the metadata used by DBMS to save the information about the type of data, structures and constraints of the data. Constructing the database is the process of storing the data on some stoprage and medium that is controlled by the DBMS Manipulating a DB includes functions such as querying the DB to retrieve specidic data, updating the DB and querying the DB Sharing the db regfers to sharing it via a server access to DB - Embedded SQL ( EXEC block in C programming language) - Create a special API to call SQL commands (JDBC, ODBC) - Allow external code to be executed from within SQL","title":"Operations of DBMS"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#how-to-design-database","text":"","title":"How to design database"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#three-layer-architecture","text":"Each layer handles two issues","title":"Three layer Architecture"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#external-layer","text":"The above shows two views generated","title":"External Layer"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#conceptual-layer","text":"shows stored data in terms of the data model of the DBMS Ina relational DBMS the conceptial schema descibes all relations that are stored in the DB This couse is aimed at this level","title":"Conceptual layer"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#physical-layer","text":"FM -> DM -> BM All data is stored in the form of pages, and the file manager keeps track of these The Disk manager brings it to memory 1. Specify additional storage details 2. File organization 3.","title":"Physical Layer:"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#etl-extract-transform-load","text":"","title":"ETL (Extract Transform Load)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#pysicall-data-independence","text":"irrespective of where the data is","title":"Pysicall data independence"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#mapping","text":"Allow for external code to be executed from within SQL EXECUTE can be used to run external scripts example python protection Sys protection (Against hw and sw) sec protection (against unauth)","title":"Mapping"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#characteristics-of-db","text":"self describing nature : there exists a data called meta data that describes the structure database. This is used by DBMS software and DB users who need infor about db structure Insulation between programs and data : There exists a data abstraction. The interface that allows for a program to access the data in the form of functions Support for multiple views : subsets of the database, contains vcirtual data derived from databse files but is not explicitly stored. Multi User DBMS allow users to use distinct apps and must provide facilities to create multiple views Sharing of data concurrency control software(make sure that multi user changes on data is controlled), Online transaction processing (OLTP) application Transactions are rolled back since it is not commited","title":"Characteristics of DB"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#example-architecture","text":"Data independence : all schemas are logical and the actual data is stored in bots in disk, so they both are inherently separate Mapping : The act of mapping two levels in a 3 level DBMS","title":"Example architecture"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#system-catalog","text":"It contains information such as: - user accounts/default settings - priveledges - performance stats - object sizing - object growth - table str - index str - table constraints - user sessions - internal db settings - location of DB files","title":"System catalog"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#crud","text":"Create Read Update Delete","title":"CRUD"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#erp-and-crm","text":"","title":"ERP and CRM"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#history","text":"","title":"History"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week1DBA.html#dbms-workers-or-users","text":"Tags: !DatabaseDesignAndApplicationIndex","title":"DBMS WORKERS or Users"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html","text":"Week 2 # Lecturer : Uma Maheswari, Faculty for BITS Pilani WILP Date : 31/Jul/2021 Topics Covered # Intro to DBMS Advantages of DBMS Mapping # Traditional Multimedia dbs Geographical (GIS) Data warehouses (OLAP) (analyze useful business information from very large databses, support descision making) Real time and active DB Time series db (volatile stocks/financial data) Database design process # Database design phases # 1. Requirements specification 1. Produces data reqs and functional reqs 2. Conceptual design 1. We develop an ER model or UML class diagram 2. We describe different entities, their relation and their attributes 3. Logical design 1. Based on the ER diagrams created, the designers create 2. Primary and foreign keys are determined 3. Normalization is to eliminate redundancy and potential update anomalies. 4. Physical design 1. This phase is to develop the database 2. Decide the datatypes 3. The SQL clauses are written to ccreate the DBs Example : Conceptual database design # Domains, Atttributes, Tuples, and Relations # Entity Relationship Diagram # Entity in ER # Example of Entity # Attributes in ER # Simple and composite : Simple cannot be split, it is atomic Composite can be divided into smaller sub parts (It is a combination of simple attributes example address) Single valued and multivalued : Single valued means there is only one value for that column (Example name) Multivalued means there are more than one value for that column (Example Phone numbers) Stored attributes and Derived attribute : Attributes from which other attributes can be derived is a stored attribute (Example birth date, job join date) This will be stored in the DB Derived attribute are attributes that are derived from stored attributes (Example age from birth date, experience from job joining date) This value would not be stored in the DB Key Attributes Relationship between the physical design to the conceptual design # Table -> Entity Type Row \u2192 Entity/Tuple Column \u2192 Domain Set of all rows \u2192 Entity Set Drawing attributes # flightid: Composite id and single valued Rollno: key attribute since every STUDENT will have a unique value Tags: !DatabaseDesignAndApplicationIndex","title":"Week 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#week-2","text":"Lecturer : Uma Maheswari, Faculty for BITS Pilani WILP Date : 31/Jul/2021","title":"Week 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#topics-covered","text":"Intro to DBMS Advantages of DBMS","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#mapping","text":"Traditional Multimedia dbs Geographical (GIS) Data warehouses (OLAP) (analyze useful business information from very large databses, support descision making) Real time and active DB Time series db (volatile stocks/financial data)","title":"Mapping"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#database-design-process","text":"","title":"Database design process"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#database-design-phases","text":"1. Requirements specification 1. Produces data reqs and functional reqs 2. Conceptual design 1. We develop an ER model or UML class diagram 2. We describe different entities, their relation and their attributes 3. Logical design 1. Based on the ER diagrams created, the designers create 2. Primary and foreign keys are determined 3. Normalization is to eliminate redundancy and potential update anomalies. 4. Physical design 1. This phase is to develop the database 2. Decide the datatypes 3. The SQL clauses are written to ccreate the DBs Example :","title":"Database design phases"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#conceptual-database-design","text":"","title":"Conceptual database design"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#domains-atttributes-tuples-and-relations","text":"","title":"Domains, Atttributes, Tuples, and Relations"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#entity-relationship-diagram","text":"","title":"Entity Relationship Diagram"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#entity-in-er","text":"","title":"Entity in ER"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#example-of-entity","text":"","title":"Example of Entity"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#attributes-in-er","text":"Simple and composite : Simple cannot be split, it is atomic Composite can be divided into smaller sub parts (It is a combination of simple attributes example address) Single valued and multivalued : Single valued means there is only one value for that column (Example name) Multivalued means there are more than one value for that column (Example Phone numbers) Stored attributes and Derived attribute : Attributes from which other attributes can be derived is a stored attribute (Example birth date, job join date) This will be stored in the DB Derived attribute are attributes that are derived from stored attributes (Example age from birth date, experience from job joining date) This value would not be stored in the DB Key Attributes","title":"Attributes in ER"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#relationship-between-the-physical-design-to-the-conceptual-design","text":"Table -> Entity Type Row \u2192 Entity/Tuple Column \u2192 Domain Set of all rows \u2192 Entity Set","title":"Relationship between the physical design to the conceptual design"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week2DBA.html#drawing-attributes","text":"flightid: Composite id and single valued Rollno: key attribute since every STUDENT will have a unique value Tags: !DatabaseDesignAndApplicationIndex","title":"Drawing attributes"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html","text":"Week 3 # Lecturer : Uma Maheswari, Faculty for BITS Pilani WILP Date : 07/Aug/2021 Topics Covered # Answer to questions from previous class Answer to questions from previous class # Q1 : Answer Name -> Simple Age -> Derived addr -> Composite pho -> Simple, Multi Valued DOB -> Stored Q2 : Answer Since there are two addresses, the attribute is multivalued. and since the address itself is a composite attribute, the Employee addr is a composite multivalued Q3 : Answer We know that \\(P_k \\in C_k \\in S_k\\) 1. Super Key \\(S_k\\) -> BookID, BookID-Name, BookID-Author, Name-Author, BookID-Name-Author 2. Candidate Key \\(C_k\\) -> BookID, Name-Author 3. Primary Key \\(P_k\\) -> BookID Q4 : Answer 1. Candidate Key \\(C_k\\) -> PAN, Licence#-address 2. Primary Key \\(P_k\\) -> PAN Q5 : Answer K1 is the Pk since it has the least composition Q6 : Answer Composite Key attributes -> Custid-orderid, Name-addr Relationship # graph LR A[Employee]---B{Works For} B---C[Department] In the above diagram, the two entities are having the relationship 'works for'. Relationship Properties # Degree of relationship # graph LR A[SALESASSIST]---B{SELLS} B---C[PRODUCT] B---D[CUSTOMER] In the above example the degree of the SELLS relationship is 3 graph LR A[Employee]---B{Works For} B---C[Department] In the above example the degree of the Works For relation is 2 graph LR A[EMPLOYEE]-- supervisor ---B{SUPERVISION} B-- supervisee ---A The above relation is a unary relationship where the relationship is with itself Role Name # In case of Unary relationship, we give a role name to the entities. For example in the supervision relationship, there are some employees who are supervisor and some will be supervisee. Here supervisor and supervisee are the role names Mapping Constraints # Cardinality Constraints # 1 to 1 relationship graph LR A[Employee]-- 1 ---B{Manages} B-- 1 ---C[Department] N to 1 relationship graph LR A[Employee]-- N ---B{Works For} B-- 1 ---C[Department] N employees work on M to N relationship graph LR A[Employee]-- M ---B{Works On} B-- N ---C[Projects] M employees can work on 1 project or 1 employee can work on N projects Participation Constraints # How many people are participating in a relationship Total Participation graph LR A[Employee]-- N ---B{Works For} B-- 1 ---C[Department] All employess participate in a department But not all departments need to have \\(Cardinality + Optionality = multiplicity\\) Relationship with attributes: # Consider the following 1 to 1 case: graph LR A[Employee]-- 1 ---B{Manages} B-- 1 ---C[Department] B---D([Start-Date]) Start date attribute can show when the employee managed a department, hence the start date can be in either of the entity set Consider the following N to 1 case: graph LR A[Employee]-- N ---B{Work For} B-- 1 ---C[Department] B---D([Start-Date]) Here start date is associated to every employee , since start date is unique for every employee but not the other way around, start date can be in employee table. Consider the following M to N case: graph LR A[Employee]-- M ---B{Work On} B-- N ---C[Project] B---D([Hours]) In the above case, the hour data must be in the relationship table since it cannot be associated to either employee or a project tables. MIN-MAX constraint # graph LR A[Employee]-- N ---B{Work For} B-- 1 ---C[Department] In the above relation min-max form for Employee is {1,N} and for department is {0,1} Entity Types # Weak and Strong # - An entity that does not have a key attribute is a weak entity (Denoted by double rectangle) - And a strong one has a key - A double diamond relationship denotes a relationship between a strong and weak entity - In the above example the Dependents entity does not have a key, hence it uses the employee id as the key - Driver license entity cannot exist without person entity ER Model # Refinement Invese refinement Binary and Ternary Relationships # Example of entities having more than 1 relationships # Removing redundant relationship # Aggregation # Questions Answered # Q1 Answer Taught during Q2 graph LR A[Employee]-- M ---B{Work On} B-- N ---C[Project] B---D([Hours]) Q5 Tags: !DatabaseDesignAndApplicationIndex","title":"Week 3"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#week-3","text":"Lecturer : Uma Maheswari, Faculty for BITS Pilani WILP Date : 07/Aug/2021","title":"Week 3"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#topics-covered","text":"Answer to questions from previous class","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#answer-to-questions-from-previous-class","text":"Q1 : Answer Name -> Simple Age -> Derived addr -> Composite pho -> Simple, Multi Valued DOB -> Stored Q2 : Answer Since there are two addresses, the attribute is multivalued. and since the address itself is a composite attribute, the Employee addr is a composite multivalued Q3 : Answer We know that \\(P_k \\in C_k \\in S_k\\) 1. Super Key \\(S_k\\) -> BookID, BookID-Name, BookID-Author, Name-Author, BookID-Name-Author 2. Candidate Key \\(C_k\\) -> BookID, Name-Author 3. Primary Key \\(P_k\\) -> BookID Q4 : Answer 1. Candidate Key \\(C_k\\) -> PAN, Licence#-address 2. Primary Key \\(P_k\\) -> PAN Q5 : Answer K1 is the Pk since it has the least composition Q6 : Answer Composite Key attributes -> Custid-orderid, Name-addr","title":"Answer to questions from previous class"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#relationship","text":"graph LR A[Employee]---B{Works For} B---C[Department] In the above diagram, the two entities are having the relationship 'works for'.","title":"Relationship"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#relationship-properties","text":"","title":"Relationship Properties"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#degree-of-relationship","text":"graph LR A[SALESASSIST]---B{SELLS} B---C[PRODUCT] B---D[CUSTOMER] In the above example the degree of the SELLS relationship is 3 graph LR A[Employee]---B{Works For} B---C[Department] In the above example the degree of the Works For relation is 2 graph LR A[EMPLOYEE]-- supervisor ---B{SUPERVISION} B-- supervisee ---A The above relation is a unary relationship where the relationship is with itself","title":"Degree of relationship"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#role-name","text":"In case of Unary relationship, we give a role name to the entities. For example in the supervision relationship, there are some employees who are supervisor and some will be supervisee. Here supervisor and supervisee are the role names","title":"Role Name"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#mapping-constraints","text":"","title":"Mapping Constraints"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#cardinality-constraints","text":"1 to 1 relationship graph LR A[Employee]-- 1 ---B{Manages} B-- 1 ---C[Department] N to 1 relationship graph LR A[Employee]-- N ---B{Works For} B-- 1 ---C[Department] N employees work on M to N relationship graph LR A[Employee]-- M ---B{Works On} B-- N ---C[Projects] M employees can work on 1 project or 1 employee can work on N projects","title":"Cardinality Constraints"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#participation-constraints","text":"How many people are participating in a relationship Total Participation graph LR A[Employee]-- N ---B{Works For} B-- 1 ---C[Department] All employess participate in a department But not all departments need to have \\(Cardinality + Optionality = multiplicity\\)","title":"Participation Constraints"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#relationship-with-attributes","text":"Consider the following 1 to 1 case: graph LR A[Employee]-- 1 ---B{Manages} B-- 1 ---C[Department] B---D([Start-Date]) Start date attribute can show when the employee managed a department, hence the start date can be in either of the entity set Consider the following N to 1 case: graph LR A[Employee]-- N ---B{Work For} B-- 1 ---C[Department] B---D([Start-Date]) Here start date is associated to every employee , since start date is unique for every employee but not the other way around, start date can be in employee table. Consider the following M to N case: graph LR A[Employee]-- M ---B{Work On} B-- N ---C[Project] B---D([Hours]) In the above case, the hour data must be in the relationship table since it cannot be associated to either employee or a project tables.","title":"Relationship with attributes:"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#min-max-constraint","text":"graph LR A[Employee]-- N ---B{Work For} B-- 1 ---C[Department] In the above relation min-max form for Employee is {1,N} and for department is {0,1}","title":"MIN-MAX constraint"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#entity-types","text":"","title":"Entity Types"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#weak-and-strong","text":"- An entity that does not have a key attribute is a weak entity (Denoted by double rectangle) - And a strong one has a key - A double diamond relationship denotes a relationship between a strong and weak entity - In the above example the Dependents entity does not have a key, hence it uses the employee id as the key - Driver license entity cannot exist without person entity","title":"Weak and Strong"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#er-model","text":"Refinement Invese refinement","title":"ER Model"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#binary-and-ternary-relationships","text":"","title":"Binary and Ternary Relationships"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#example-of-entities-having-more-than-1-relationships","text":"","title":"Example of entities having more than 1 relationships"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#removing-redundant-relationship","text":"","title":"Removing redundant relationship"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#aggregation","text":"","title":"Aggregation"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week3DBA.html#questions-answered","text":"Q1 Answer Taught during Q2 graph LR A[Employee]-- M ---B{Work On} B-- N ---C[Project] B---D([Hours]) Q5 Tags: !DatabaseDesignAndApplicationIndex","title":"Questions Answered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week5DBA.html","text":"Week 5 # Lecturer : Uma Maheswari, Faculty for BITS Pilani WILP Date : 21/Aug/2021 Topics Covered # Data Model and Schema Relational Model (Logical Data Model) Characteristics and concepts of relational model Relational Schema Diagram Example Data Model and Schema # data model captures what kind of data is stored how it must be organized etc Data model has a description of datam data semantics and consistency constraints of data There are 3 different types of data models: conceptual data models, logical data models, and physical data models and each has it's own purpose: 1. Conceptual : ER, EER and UML diagrams used to represent how data is organized. We define scope and business concepts and rules 2. Logical : How the system is implemented independent of the DBMS. Will be used by data architects and analysts. The purpose ius to develop technical map of rules and data structures (Schema, it is a plan on how the database needs to be implemented) 3. Physical : This describes how the system will be implemented using a specific DBMS system. This model is typically created by DBA and developers. The files that are used to save tables are part of this model Relational Model (Logical Data Model) # It is based upon the mathematical concepts of relations, set theory and predicate logic A relation is a set of values. Domain : Domain D is a set of atomic values By atomic we mean that each value in the domain is indivisible Method of specifying a domain is to specify a data type USA_Phone_number: The set of ten digit phone numbers valid in US SSN: Set of valid nine digit SSNs Sex: a member of the set {female, male} GPA: A real number between 0.0 to 4.0 Names: The set of character strings that represent names of person The above rules are called logical definitions if domains A domain is thus given a name, data type and a format. Attribute : Attributes are columns for a given entity type and have a name The domain for an attribute \\(A\\) is given as \\(dom(A)\\) and it holds all the values that the attribute can hold Tuple : A Row in an entity is called a tuple The mapping of attributes and its values Example {Name -> \"Akhil Sudhakaran\", Sex -> Male, IQ -> 9000} Relational Schema : Relational schema is given by \\(R\\) , and it is the relation's name. It is denoted by \\(R(A_1, A_2, A_3,...,A_n)\\) Each attribute \\(A_i\\) is identified by \\(dom(A_i)\\) The degree of a relation is the number of attributes of its relation Using data type of each attributem the definition is sometimes written as: \\[STUDENT(Name: string,\\ Ssn: string,\\ Home\\_phone: string,\\ Address: string,\\ Office\\_phone: string,\\ Age: integer,\\ Gpa: real)\\] Attribute \\(A_i\\) can be qualified with the relation name \\(R\\) to which it belongs by using the dot notation \\(R.A_i\\) , for example \\(STUDENT.name\\) Relation State : Denoted by \\(r(R)\\) , is a set if n-tuples \\(r = \\{t_1, t_2, t_3, ... , t_n\\}\\) Each tuple \\(t\\) is an ordered list of n values \\(t=<v_1, v_2, ... , v_n>\\) Each \\(v_i\\) is an element of \\(dom(A_i)\\) It is possible for several attributes to have the same domain. The domain 'USA_phone_numbers' can be used for the attributes 'Home_phone' and 'Office_phone' as well Relation : A named set of tuples all of the same form (Having same set of attributes). The term table is a loose synonym A relation state is a subset of the Cartesian product of the domains defining the relation schema Relational Database : A collection if relations, each one needs to have a logical relationship, then that collection is called relational database Characteristics and concepts of relational model # A relation is a set of tuples and have no duplicates and have no order Ordering of tuples cannot be possible Logically the tuples have no order Physically in disk there can be an order When we display a relation as a table, the rows are displated in a vertain ordeer by different attributes Ordering if attributes: A tuple is best viewed as a mapping from its attributes. The null value: Used for dont know, not applicable or value undefined etc. For example if an attribute Phone_number is not available then we can store the value NULL to denote that Composite and multivalued attributes are not allowed Values of attributes: All values must be atomic and must not contain composite or multi valued. r(R) < dom(A_1) x dom(A_2) x ... x dom(A_n) R: Schema of relation r of R: a specific value or popuilation if R R is also calledf the intension of relation Let S_1 = {0, 1} Let S_2 - {a, b, c} Let R < S1 x S2 then for example: r(R) = {<0, a>, <0, b>, <1, c>}. There are a lot of constraints or restrictions on the actual valuies in a datrabase state Constraints on DBB can generally be divided: Implicit constraints : constraints in the data model.No two tupples can have duplicate values The salary of employee cannot exceed the salary of the supervisor Maximum number of hours an employee can work in a week is 56 Triggers and assertions can be used to enforce semantic based constraints schema based : Constraints expressed in schema, typically done in DDL Domain Constraints: Within each tuple, the value of each attribute \\(A\\) must be atomic. Each attribute must be either null or must be from the \\(dom(A)\\) Some DBMS allow to impost a not null constraint as well Key constraint : Means no two tuples can have the same combination if values for all their attributes Subsets of attributes of a relation in schema \\(R\\) with the property that no two tuples in any relation state r of R is called a super key. Whenever a super key has redundant values, they are removed and a candidate key is generated. One from this candidate key is the primary key. These keys are underlined in the relational schema Relation database state \\(S\\) is a set of relational schema \\(S = \\{R_1, R_2, ... , R_m\\}\\) A snapshot of the relationship database is the data at the current relation schema Integrity constraint : This states that no primary key value can be NULL Referential Integrity Constraint : This is implemented for foreign keys Referential Integrity Violation : When foreign key is updated and that foreign key is not a PK of the foreign tuple When primary key is updated and the entities that refer to this PK as FK must also be updated application based Relational Schema Diagram Example # Tags: !DatabaseDesignAndApplicationIndex","title":"Week 5"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week5DBA.html#week-5","text":"Lecturer : Uma Maheswari, Faculty for BITS Pilani WILP Date : 21/Aug/2021","title":"Week 5"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week5DBA.html#topics-covered","text":"Data Model and Schema Relational Model (Logical Data Model) Characteristics and concepts of relational model Relational Schema Diagram Example","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week5DBA.html#data-model-and-schema","text":"data model captures what kind of data is stored how it must be organized etc Data model has a description of datam data semantics and consistency constraints of data There are 3 different types of data models: conceptual data models, logical data models, and physical data models and each has it's own purpose: 1. Conceptual : ER, EER and UML diagrams used to represent how data is organized. We define scope and business concepts and rules 2. Logical : How the system is implemented independent of the DBMS. Will be used by data architects and analysts. The purpose ius to develop technical map of rules and data structures (Schema, it is a plan on how the database needs to be implemented) 3. Physical : This describes how the system will be implemented using a specific DBMS system. This model is typically created by DBA and developers. The files that are used to save tables are part of this model","title":"Data Model and Schema"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week5DBA.html#relational-model-logical-data-model","text":"It is based upon the mathematical concepts of relations, set theory and predicate logic A relation is a set of values. Domain : Domain D is a set of atomic values By atomic we mean that each value in the domain is indivisible Method of specifying a domain is to specify a data type USA_Phone_number: The set of ten digit phone numbers valid in US SSN: Set of valid nine digit SSNs Sex: a member of the set {female, male} GPA: A real number between 0.0 to 4.0 Names: The set of character strings that represent names of person The above rules are called logical definitions if domains A domain is thus given a name, data type and a format. Attribute : Attributes are columns for a given entity type and have a name The domain for an attribute \\(A\\) is given as \\(dom(A)\\) and it holds all the values that the attribute can hold Tuple : A Row in an entity is called a tuple The mapping of attributes and its values Example {Name -> \"Akhil Sudhakaran\", Sex -> Male, IQ -> 9000} Relational Schema : Relational schema is given by \\(R\\) , and it is the relation's name. It is denoted by \\(R(A_1, A_2, A_3,...,A_n)\\) Each attribute \\(A_i\\) is identified by \\(dom(A_i)\\) The degree of a relation is the number of attributes of its relation Using data type of each attributem the definition is sometimes written as: \\[STUDENT(Name: string,\\ Ssn: string,\\ Home\\_phone: string,\\ Address: string,\\ Office\\_phone: string,\\ Age: integer,\\ Gpa: real)\\] Attribute \\(A_i\\) can be qualified with the relation name \\(R\\) to which it belongs by using the dot notation \\(R.A_i\\) , for example \\(STUDENT.name\\) Relation State : Denoted by \\(r(R)\\) , is a set if n-tuples \\(r = \\{t_1, t_2, t_3, ... , t_n\\}\\) Each tuple \\(t\\) is an ordered list of n values \\(t=<v_1, v_2, ... , v_n>\\) Each \\(v_i\\) is an element of \\(dom(A_i)\\) It is possible for several attributes to have the same domain. The domain 'USA_phone_numbers' can be used for the attributes 'Home_phone' and 'Office_phone' as well Relation : A named set of tuples all of the same form (Having same set of attributes). The term table is a loose synonym A relation state is a subset of the Cartesian product of the domains defining the relation schema Relational Database : A collection if relations, each one needs to have a logical relationship, then that collection is called relational database","title":"Relational Model (Logical Data Model)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week5DBA.html#characteristics-and-concepts-of-relational-model","text":"A relation is a set of tuples and have no duplicates and have no order Ordering of tuples cannot be possible Logically the tuples have no order Physically in disk there can be an order When we display a relation as a table, the rows are displated in a vertain ordeer by different attributes Ordering if attributes: A tuple is best viewed as a mapping from its attributes. The null value: Used for dont know, not applicable or value undefined etc. For example if an attribute Phone_number is not available then we can store the value NULL to denote that Composite and multivalued attributes are not allowed Values of attributes: All values must be atomic and must not contain composite or multi valued. r(R) < dom(A_1) x dom(A_2) x ... x dom(A_n) R: Schema of relation r of R: a specific value or popuilation if R R is also calledf the intension of relation Let S_1 = {0, 1} Let S_2 - {a, b, c} Let R < S1 x S2 then for example: r(R) = {<0, a>, <0, b>, <1, c>}. There are a lot of constraints or restrictions on the actual valuies in a datrabase state Constraints on DBB can generally be divided: Implicit constraints : constraints in the data model.No two tupples can have duplicate values The salary of employee cannot exceed the salary of the supervisor Maximum number of hours an employee can work in a week is 56 Triggers and assertions can be used to enforce semantic based constraints schema based : Constraints expressed in schema, typically done in DDL Domain Constraints: Within each tuple, the value of each attribute \\(A\\) must be atomic. Each attribute must be either null or must be from the \\(dom(A)\\) Some DBMS allow to impost a not null constraint as well Key constraint : Means no two tuples can have the same combination if values for all their attributes Subsets of attributes of a relation in schema \\(R\\) with the property that no two tuples in any relation state r of R is called a super key. Whenever a super key has redundant values, they are removed and a candidate key is generated. One from this candidate key is the primary key. These keys are underlined in the relational schema Relation database state \\(S\\) is a set of relational schema \\(S = \\{R_1, R_2, ... , R_m\\}\\) A snapshot of the relationship database is the data at the current relation schema Integrity constraint : This states that no primary key value can be NULL Referential Integrity Constraint : This is implemented for foreign keys Referential Integrity Violation : When foreign key is updated and that foreign key is not a PK of the foreign tuple When primary key is updated and the entities that refer to this PK as FK must also be updated application based","title":"Characteristics and concepts of relational model"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week5DBA.html#relational-schema-diagram-example","text":"Tags: !DatabaseDesignAndApplicationIndex","title":"Relational Schema Diagram Example"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html","text":"Week 6 # Lecturer : Uma Maheswari, Faculty for BITS Pilani WILP Date : 21/Aug/2021 Topics Covered # Logical Design Phase Logical Design Phase # A summary of design phases: Converting strong entity types: # Each entity type becomes a table single valued attributes becomes a column Derived attributes are ignored Composite attributes are represented by components Multivalued attributes are represented by a separate table The key attributes of the entry type becomes the primary key of the table Entity Example 1 # - Here address is a composite attribute - Years of service is a derived attribute so can be ignored - Skill set is a multivalued attribute The converted relational schema for the above example: Employee ( E# , Name, Door_No, Street, City, Pincode, Date_Of_Joining) Emp_Skillset( E# , Skillset) Entity Example 2 # - Weak entity types are converted into a table oif their own, with the primary key of the strong entity acting as a foreign key in the table - This foreign key along with the key of the weak entity form the composite primary key of this table The converted relational schema for the above example: Employee ( E# , ...) Dependant( E# , Dependant_ID , Name, Address) Converting relationships: # Binary 1:1 # Case 1: Combination of participation types # - The primary key of the partial participant will become the foreign key of the total participant - The manager employee for the department will be a foreign key wrt Employee table The converted relational schema: Employee( E# , Name, ....) Department( Dept# , Name, .... , MgrE#) Case 2: Uniform participation types # The converted relational schema: Employee( E# , Name, ....) Chair( Item# , Model, Location, used_by) Employee( E# , Name, .... , Sits_on) Chair( Item# , Model, Location) Binary 1:N # - Teacher in Subject table is the foreign key for Teacher entity The converted relational schema: Teacher( ID , Name, Telephone, ....) Subject( Code , Name, .... , Teacher ) Binary M:N # - The relation is moved to a separate table - This table uses the PK of the other two tables as the foreign keys The converted relational schema: Student( Sid# , Title, .... ) Enrolls( Sid# , C# ) Course( C# , CName, .... ) Self Referencing Binary 1:1 # - E# is the primary key - Spouse is the foreign key to employee table The converted relational schema: Employee( E# , Name, .... , Spouse ) Self Referencing Binary 1:N # - Manager is the FK to the table Employee The converted relational schema: Employee( E# , Name, .... , Manager ) Self Referencing Binary M:N # - Guarantor, Beneficiary are FK to the table Employee The converted relational schema: Employee( E# , Name, ....) Guarantr( Guarantor , Beneficiary ) Ternary Relationship # The converted relational schema: Prescription ( Doctor# , Patient# , Medicine# ) ER Constructs to relations: # SuperSSN : FK to Employee table that shows supervisor WorksOn: This relationship is it's own table since it is M:N Supervising_DNO : FK to the Dept table that shows the supervising department Works_For_DNO : FK to the Dept table that shows the supervising department Employee( SSN , Name, Sex, .... , SuperSSN , Works_For_DNO ) Dept( DNO , Name, ManagerSSN , start_date) Dept_locations( DNO , Location) Project( PNO , Name, Location, Supervising_DNO ) Dependent(Name, Sex, DOB, Relationship Employee_SSN , ) WorksOn( PNO , SSN , hours) Ternary relationship conversion example: # EER to Relational Mapping Steps # Tags: !DatabaseDesignAndApplicationIndex","title":"Week 6"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#week-6","text":"Lecturer : Uma Maheswari, Faculty for BITS Pilani WILP Date : 21/Aug/2021","title":"Week 6"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#topics-covered","text":"Logical Design Phase","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#logical-design-phase","text":"A summary of design phases:","title":"Logical Design Phase"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#converting-strong-entity-types","text":"Each entity type becomes a table single valued attributes becomes a column Derived attributes are ignored Composite attributes are represented by components Multivalued attributes are represented by a separate table The key attributes of the entry type becomes the primary key of the table","title":"Converting strong entity types:"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#entity-example-1","text":"- Here address is a composite attribute - Years of service is a derived attribute so can be ignored - Skill set is a multivalued attribute The converted relational schema for the above example: Employee ( E# , Name, Door_No, Street, City, Pincode, Date_Of_Joining) Emp_Skillset( E# , Skillset)","title":"Entity Example 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#entity-example-2","text":"- Weak entity types are converted into a table oif their own, with the primary key of the strong entity acting as a foreign key in the table - This foreign key along with the key of the weak entity form the composite primary key of this table The converted relational schema for the above example: Employee ( E# , ...) Dependant( E# , Dependant_ID , Name, Address)","title":"Entity Example 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#converting-relationships","text":"","title":"Converting relationships:"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#binary-11","text":"","title":"Binary 1:1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#case-1-combination-of-participation-types","text":"- The primary key of the partial participant will become the foreign key of the total participant - The manager employee for the department will be a foreign key wrt Employee table The converted relational schema: Employee( E# , Name, ....) Department( Dept# , Name, .... , MgrE#)","title":"Case 1: Combination of participation types"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#case-2-uniform-participation-types","text":"The converted relational schema: Employee( E# , Name, ....) Chair( Item# , Model, Location, used_by) Employee( E# , Name, .... , Sits_on) Chair( Item# , Model, Location)","title":"Case 2: Uniform participation types"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#binary-1n","text":"- Teacher in Subject table is the foreign key for Teacher entity The converted relational schema: Teacher( ID , Name, Telephone, ....) Subject( Code , Name, .... , Teacher )","title":"Binary 1:N"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#binary-mn","text":"- The relation is moved to a separate table - This table uses the PK of the other two tables as the foreign keys The converted relational schema: Student( Sid# , Title, .... ) Enrolls( Sid# , C# ) Course( C# , CName, .... )","title":"Binary M:N"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#self-referencing-binary-11","text":"- E# is the primary key - Spouse is the foreign key to employee table The converted relational schema: Employee( E# , Name, .... , Spouse )","title":"Self Referencing Binary 1:1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#self-referencing-binary-1n","text":"- Manager is the FK to the table Employee The converted relational schema: Employee( E# , Name, .... , Manager )","title":"Self Referencing Binary 1:N"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#self-referencing-binary-mn","text":"- Guarantor, Beneficiary are FK to the table Employee The converted relational schema: Employee( E# , Name, ....) Guarantr( Guarantor , Beneficiary )","title":"Self Referencing Binary M:N"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#ternary-relationship","text":"The converted relational schema: Prescription ( Doctor# , Patient# , Medicine# )","title":"Ternary Relationship"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#er-constructs-to-relations","text":"SuperSSN : FK to Employee table that shows supervisor WorksOn: This relationship is it's own table since it is M:N Supervising_DNO : FK to the Dept table that shows the supervising department Works_For_DNO : FK to the Dept table that shows the supervising department Employee( SSN , Name, Sex, .... , SuperSSN , Works_For_DNO ) Dept( DNO , Name, ManagerSSN , start_date) Dept_locations( DNO , Location) Project( PNO , Name, Location, Supervising_DNO ) Dependent(Name, Sex, DOB, Relationship Employee_SSN , ) WorksOn( PNO , SSN , hours)","title":"ER Constructs to relations:"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#ternary-relationship-conversion-example","text":"","title":"Ternary relationship conversion example:"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Database%20Design%20and%20Application/Week6DBA.html#eer-to-relational-mapping-steps","text":"Tags: !DatabaseDesignAndApplicationIndex","title":"EER to Relational Mapping Steps"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/%21DatastructuresAndAlgorithmsIndex.html","text":"Datastructure and Algorithm Index # This is an Index page for all Distributed Computing Content Week 1 Lecture Notes: Week1DSA Week 2 Lecture Notes: Week2DSA Week 4 Lecture Notes: Week4DSA Lecture Notes: Week4DSA2 Week 6 Lecture Notes: Week6DSA Tags: !Semester1Index","title":"Datastructure and Algorithm Index"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/%21DatastructuresAndAlgorithmsIndex.html#datastructure-and-algorithm-index","text":"This is an Index page for all Distributed Computing Content Week 1 Lecture Notes: Week1DSA Week 2 Lecture Notes: Week2DSA Week 4 Lecture Notes: Week4DSA Lecture Notes: Week4DSA2 Week 6 Lecture Notes: Week6DSA Tags: !Semester1Index","title":"Datastructure and Algorithm Index"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week1DSA.html","text":"Week 1 # Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 24/Jul/2021 Topics Covered # What is an algorithm? What is time and space complexity? What is an algorithm? # An algorithm is a finite sequence of steps to be followed to reach a pre determined goal for a predetermined set of inputs. An algorithm has the following properties: 1. Finiteness : the sequence of steps the algorithm has must be finite 2. Definiteness : Each step should be atomic and precise and cause no confusion on what it does 3. Input : There may or may not be an input passed to the algorithm to work on 4. Termination : Due to the finiteness of algorithms the algorithm must terminate and produce an output 5. Correctness : The output produces must be the right one for any given input What is time and space complexity? # It is a way to analyze the performance of algorithms. Experimental studies for analyzing algorithms have some limitations: 1. It is difficult to compare running times of two algorithms in different software/hardware configurations 2. To truly know the performance we need to implement and run the algorithms on a computer since things like type of data provided for an algorithm can greatly alter the running time of the algorithm (For example an algorithm can run really slow for a single but large value and faster for multiple values) 3. One must need to make sure that the set of inputs used to analyze the algorithms are representative, meaning that the inputs must cover some particular use case (say for a sorting algorithm, we can have one input where all values are already sorted, sorted in reverse, all values being same and all values being jumbled) Consider the following example: Algorithm arrayMax(A, n): Input: An array A storing n >= 1 integers. Output: The maximum element in A currentMax <- A[0] for i <- 1 to n - 1 do if currentMax < A[i] then currentMax <- A[i] return currentMax The above example is what we call a pseudo code . It is meant to represent the flow of logic to find the maximum value in a given array. Consider A = [3, 2, 7, 5] Step i What we are comparing it with currentMax 0 null = A[0] = 3 1 A[1] = 2 3 > 2 so 3 2 A[2] = 7 3 < 7 so 7 3 A[3] = 5 7 > 5 so 7 So going over the steps we see that at the end we can determine that the max value is A[2] = 7. We see that: \"Algorithm arrayMax runs in time proportional to n\" If we were to actually run experiments, then the running time of arrayMax given any input of size n would never exceed c.n where c is the amount of time taken by the given software to run for an input of size 1. As seen above the constant c depends on the language used to run the algorithm and the hardware used to run the algorithm. A workstation can compute a more complex algorithm faster than a slow computer would for a less complex algorithm, hence to truly compare two algorithms all the parameters (The language, software and the hardware used) must be the same. Given two algorithms has two implementations where: 1. A algorithm : that runs proportional to \\(N\\) and 2. B algorithm that runs proportional to \\(N^2\\) we need to ideally makes sure that the algorithm chosen is the one that is proportional to N since for a very large input A would perform better. Addition, Multiplication, Subtraction and Division are examples of primitive operations. Primitive operation are those that cannot be further broken down to more simpler steps. In the above algorithm we can see the analysis as follows: currentMax <- A[0] ---> 2 = 1 (for indexing) + 1 (for assignment) i <- 1 ---> 1 (for assignment) while i < n ---> n (1 for the every comparison) if currentMax < A[i] then ---> 2 = 1 (for indexing) + 1 (for comparison) currentMax <- A[i] ---> 2 = 1 (for indexing) + 1 (for assignment) i = i + 1 ---> 2 = 1 (for addition) + 1 (for assignment) return currentMax ---> 1 From the above analysis we can say that the algorithm time complexity at the worst case where every iteration goes into the if block, is: \\[TimeComplexity < (2 + 1 + n + (n - 1) * (2 + 2 + 2) + 1)\\] \\[TimeComplexity < 7n - 2\\] \\[TimeComplexity < 7n\\] We say \\(<\\) because there are cases where the statements under the if condition is not calculated. Tags: !DatastructuresAndAlgorithmsIndex","title":"Week 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week1DSA.html#week-1","text":"Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 24/Jul/2021","title":"Week 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week1DSA.html#topics-covered","text":"What is an algorithm? What is time and space complexity?","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week1DSA.html#what-is-an-algorithm","text":"An algorithm is a finite sequence of steps to be followed to reach a pre determined goal for a predetermined set of inputs. An algorithm has the following properties: 1. Finiteness : the sequence of steps the algorithm has must be finite 2. Definiteness : Each step should be atomic and precise and cause no confusion on what it does 3. Input : There may or may not be an input passed to the algorithm to work on 4. Termination : Due to the finiteness of algorithms the algorithm must terminate and produce an output 5. Correctness : The output produces must be the right one for any given input","title":"What is an algorithm?"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week1DSA.html#what-is-time-and-space-complexity","text":"It is a way to analyze the performance of algorithms. Experimental studies for analyzing algorithms have some limitations: 1. It is difficult to compare running times of two algorithms in different software/hardware configurations 2. To truly know the performance we need to implement and run the algorithms on a computer since things like type of data provided for an algorithm can greatly alter the running time of the algorithm (For example an algorithm can run really slow for a single but large value and faster for multiple values) 3. One must need to make sure that the set of inputs used to analyze the algorithms are representative, meaning that the inputs must cover some particular use case (say for a sorting algorithm, we can have one input where all values are already sorted, sorted in reverse, all values being same and all values being jumbled) Consider the following example: Algorithm arrayMax(A, n): Input: An array A storing n >= 1 integers. Output: The maximum element in A currentMax <- A[0] for i <- 1 to n - 1 do if currentMax < A[i] then currentMax <- A[i] return currentMax The above example is what we call a pseudo code . It is meant to represent the flow of logic to find the maximum value in a given array. Consider A = [3, 2, 7, 5] Step i What we are comparing it with currentMax 0 null = A[0] = 3 1 A[1] = 2 3 > 2 so 3 2 A[2] = 7 3 < 7 so 7 3 A[3] = 5 7 > 5 so 7 So going over the steps we see that at the end we can determine that the max value is A[2] = 7. We see that: \"Algorithm arrayMax runs in time proportional to n\" If we were to actually run experiments, then the running time of arrayMax given any input of size n would never exceed c.n where c is the amount of time taken by the given software to run for an input of size 1. As seen above the constant c depends on the language used to run the algorithm and the hardware used to run the algorithm. A workstation can compute a more complex algorithm faster than a slow computer would for a less complex algorithm, hence to truly compare two algorithms all the parameters (The language, software and the hardware used) must be the same. Given two algorithms has two implementations where: 1. A algorithm : that runs proportional to \\(N\\) and 2. B algorithm that runs proportional to \\(N^2\\) we need to ideally makes sure that the algorithm chosen is the one that is proportional to N since for a very large input A would perform better. Addition, Multiplication, Subtraction and Division are examples of primitive operations. Primitive operation are those that cannot be further broken down to more simpler steps. In the above algorithm we can see the analysis as follows: currentMax <- A[0] ---> 2 = 1 (for indexing) + 1 (for assignment) i <- 1 ---> 1 (for assignment) while i < n ---> n (1 for the every comparison) if currentMax < A[i] then ---> 2 = 1 (for indexing) + 1 (for comparison) currentMax <- A[i] ---> 2 = 1 (for indexing) + 1 (for assignment) i = i + 1 ---> 2 = 1 (for addition) + 1 (for assignment) return currentMax ---> 1 From the above analysis we can say that the algorithm time complexity at the worst case where every iteration goes into the if block, is: \\[TimeComplexity < (2 + 1 + n + (n - 1) * (2 + 2 + 2) + 1)\\] \\[TimeComplexity < 7n - 2\\] \\[TimeComplexity < 7n\\] We say \\(<\\) because there are cases where the statements under the if condition is not calculated. Tags: !DatastructuresAndAlgorithmsIndex","title":"What is time and space complexity?"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week2DSA.html","text":"Week 2 # Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 31/Jul/2021 Topics Covered # Questions Answered on Previous Week Topics Concept of Recursion Questions Answered on Previous Week Topics # Question : If an algorithm for solving a problem has a loop that runs \\(n\\) times and another algorithm to solve the same problem and has a loop that runs \\(n\\over2\\) , then what is the comparative analysis for these two algorithms? Answer : Both are proportional to \\(n\\) since the only thing that changed here is the constant \\(c\\) , which is \\(1\\) in the first case and \\(1\\over2\\) in the other. Question : Do all primitives have the same constant running time? Answer : This is not the case but as a concept it is taken as to be the same since the running time for a given operation is not dependent on the number of inputs. Question : From the array max example (discussed here: Week1DSA#What is time and space complexity ) we see that the algorithm in its worst case is \\(7n - 2\\) , what is it in its best case? Answer : In the best case, the maximum value is in the starting of the array \\(A[0]\\) itself. In this case the inside of the if block will not even execute so we can reduce \\(2\\) primitive steps from the calculation, this will lead to the following analysis: \\[TimeComplexity < (2 + 1 + n + (n - 1) * (2 + 0 + 2) + 1)\\] \\[TimeComplexity < 5n\\] Concept of Recursion # Consider the algorithm for finding the factorial of a number: Algorithm factorial(n): Input: A number n > 0. Output: The factorial of n. product <- 1 for i <- 1 to n do product <- i * product return product The above algorithm is called an iterative one since it employs loops, the same can be written through recursive function calls such as below: Algorithm factorial(n): Input: A number n > 0. Output: The factorial of n. product <- 1 if n = 1 then return 1 else result = n * factorial(n - 1) return result Here you see that the loop is removed and the algorithm is called recursively, but it yields the same result. One must be careful to have at least one base case (Here \\(product \\longleftarrow 1\\) ) must exist, else recursion will go on indefinitely. Now a recursive implementation for the array max algorithm ( Week1DSA#What is time and space complexity ) would be as follows: Algorithm recursiveMax(A, n): Input: An array A storing n >= 1 integers. Output: The maximum element in A if n = 1 then return A[0] return max{recursiveMax(A, n-1), A[n-1]} The running time for the same will be shows as below: \\[T(n) = 3,\\ if\\ n=1\\] \\[T(n) = T(n-1)+7,\\ otherwise\\] Tags: !DatastructuresAndAlgorithmsIndex","title":"Week 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week2DSA.html#week-2","text":"Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 31/Jul/2021","title":"Week 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week2DSA.html#topics-covered","text":"Questions Answered on Previous Week Topics Concept of Recursion","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week2DSA.html#questions-answered-on-previous-week-topics","text":"Question : If an algorithm for solving a problem has a loop that runs \\(n\\) times and another algorithm to solve the same problem and has a loop that runs \\(n\\over2\\) , then what is the comparative analysis for these two algorithms? Answer : Both are proportional to \\(n\\) since the only thing that changed here is the constant \\(c\\) , which is \\(1\\) in the first case and \\(1\\over2\\) in the other. Question : Do all primitives have the same constant running time? Answer : This is not the case but as a concept it is taken as to be the same since the running time for a given operation is not dependent on the number of inputs. Question : From the array max example (discussed here: Week1DSA#What is time and space complexity ) we see that the algorithm in its worst case is \\(7n - 2\\) , what is it in its best case? Answer : In the best case, the maximum value is in the starting of the array \\(A[0]\\) itself. In this case the inside of the if block will not even execute so we can reduce \\(2\\) primitive steps from the calculation, this will lead to the following analysis: \\[TimeComplexity < (2 + 1 + n + (n - 1) * (2 + 0 + 2) + 1)\\] \\[TimeComplexity < 5n\\]","title":"Questions Answered on Previous Week Topics"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week2DSA.html#concept-of-recursion","text":"Consider the algorithm for finding the factorial of a number: Algorithm factorial(n): Input: A number n > 0. Output: The factorial of n. product <- 1 for i <- 1 to n do product <- i * product return product The above algorithm is called an iterative one since it employs loops, the same can be written through recursive function calls such as below: Algorithm factorial(n): Input: A number n > 0. Output: The factorial of n. product <- 1 if n = 1 then return 1 else result = n * factorial(n - 1) return result Here you see that the loop is removed and the algorithm is called recursively, but it yields the same result. One must be careful to have at least one base case (Here \\(product \\longleftarrow 1\\) ) must exist, else recursion will go on indefinitely. Now a recursive implementation for the array max algorithm ( Week1DSA#What is time and space complexity ) would be as follows: Algorithm recursiveMax(A, n): Input: An array A storing n >= 1 integers. Output: The maximum element in A if n = 1 then return A[0] return max{recursiveMax(A, n-1), A[n-1]} The running time for the same will be shows as below: \\[T(n) = 3,\\ if\\ n=1\\] \\[T(n) = T(n-1)+7,\\ otherwise\\] Tags: !DatastructuresAndAlgorithmsIndex","title":"Concept of Recursion"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA.html","text":"Week 4 # Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 21/Aug/2021 Topics Covered # Deriving Big \\(\\mathcal{O}\\) From Growth Rate Significance of Growth Rate Examples Rules to Find Big \\(\\mathcal{O}\\) Notation Deriving Big \\(\\mathcal{O}\\) From Growth Rate # Significance of Growth Rate # Consider f(n) and g(n), Let us consider what a growth rate of a function is. Growth rate \\(f(n) = 1000n\\) \\(g(n) = 2n^2\\) \\(n\\) \\(f(n)\\) \\(g(n)\\) \\(f(n)/f(n-1)\\) \\(g(n)/g(n-1)\\) 1 1000 2 - - 2 2000 8 2 4 3 3000 18 1.5 2.25 4 4000 32 1.33 1.78 5 5000 50 1.2 1.56 Seeing the above pattern in the rate of growth, we see that for any particular value of \\(n\\) the \\(g(n)\\) ratio is bigger than that for \\(f(n)\\) , and this is seen as we incrementing \\(n\\) . So we can conclude that \\(g(n)\\) has a faster rate of growth. We can also find the value of n for which the value of \\(g(n)\\) will shoot up more than \\(f(n)\\) : \\(g(n) \\ge f(n)\\) \\(2.n^2 \\ge 1000n\\) \\(n \\ge 500\\) This shows that since the \\(g(n)\\) grows faster (quadratic growth), whenever \\(n\\) is greater than \\(500\\) then \\(g(n)\\) will always be greater than \\(f(n)\\) so we can conclude that the algorithm that has a run time of \\(f(n)\\) will be overall better than one that has a run time of \\(g(n)\\) . Examples # Example 1 : \\(f(n) = 20.n^3 + 10.n.log(n) + 5\\) is \\(\\mathcal{O}(n^3)\\) Proof : \\(20.n^3 + 10.n.log(n) + 5 \\le 35.n^3\\) , for \\(n \\ge 1\\) Example 2 : \\(f(n) = 2^{100}\\) is \\(\\mathcal{O}(1)\\) Proof : \\(2^{100} \\le 2^{100}.1\\) , for \\(n \\ge 1\\) Example 3 : \\(f(n) = 3^log(n) + log(log(n))\\) is \\(\\mathcal{O}(log(n))\\) Proof : \\(3^log(n) + log(log(n)) \\le log(n)\\) , for \\(n \\ge 2\\) and \\(c = 4\\) Rules to Find Big \\(\\mathcal{O}\\) Notation # Some examples: Tags: !DatastructuresAndAlgorithmsIndex","title":"Week 4"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA.html#week-4","text":"Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 21/Aug/2021","title":"Week 4"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA.html#topics-covered","text":"Deriving Big \\(\\mathcal{O}\\) From Growth Rate Significance of Growth Rate Examples Rules to Find Big \\(\\mathcal{O}\\) Notation","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA.html#deriving-bigmathcalo-from-growth-rate","text":"","title":"Deriving Big\\(\\mathcal{O}\\) From Growth Rate"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA.html#significance-of-growth-rate","text":"Consider f(n) and g(n), Let us consider what a growth rate of a function is. Growth rate \\(f(n) = 1000n\\) \\(g(n) = 2n^2\\) \\(n\\) \\(f(n)\\) \\(g(n)\\) \\(f(n)/f(n-1)\\) \\(g(n)/g(n-1)\\) 1 1000 2 - - 2 2000 8 2 4 3 3000 18 1.5 2.25 4 4000 32 1.33 1.78 5 5000 50 1.2 1.56 Seeing the above pattern in the rate of growth, we see that for any particular value of \\(n\\) the \\(g(n)\\) ratio is bigger than that for \\(f(n)\\) , and this is seen as we incrementing \\(n\\) . So we can conclude that \\(g(n)\\) has a faster rate of growth. We can also find the value of n for which the value of \\(g(n)\\) will shoot up more than \\(f(n)\\) : \\(g(n) \\ge f(n)\\) \\(2.n^2 \\ge 1000n\\) \\(n \\ge 500\\) This shows that since the \\(g(n)\\) grows faster (quadratic growth), whenever \\(n\\) is greater than \\(500\\) then \\(g(n)\\) will always be greater than \\(f(n)\\) so we can conclude that the algorithm that has a run time of \\(f(n)\\) will be overall better than one that has a run time of \\(g(n)\\) .","title":"Significance of Growth Rate"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA.html#examples","text":"Example 1 : \\(f(n) = 20.n^3 + 10.n.log(n) + 5\\) is \\(\\mathcal{O}(n^3)\\) Proof : \\(20.n^3 + 10.n.log(n) + 5 \\le 35.n^3\\) , for \\(n \\ge 1\\) Example 2 : \\(f(n) = 2^{100}\\) is \\(\\mathcal{O}(1)\\) Proof : \\(2^{100} \\le 2^{100}.1\\) , for \\(n \\ge 1\\) Example 3 : \\(f(n) = 3^log(n) + log(log(n))\\) is \\(\\mathcal{O}(log(n))\\) Proof : \\(3^log(n) + log(log(n)) \\le log(n)\\) , for \\(n \\ge 2\\) and \\(c = 4\\)","title":"Examples"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA.html#rules-to-find-bigmathcalo-notation","text":"Some examples: Tags: !DatastructuresAndAlgorithmsIndex","title":"Rules to Find Big\\(\\mathcal{O}\\) Notation"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA2.html","text":"Week 4 (cont.) # Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 22/Aug/2021 Topics Covered # Rules to Find Big \\(\\mathcal{O}\\) Notation (cont.) Little \\(\\mathcal{o}\\) and ## Little \\(\\omega\\) Bubble Sort Rules to Find Big \\(\\mathcal{O}\\) Notation (cont.) # It is considered poor taste to include constant factors and lower order terms in the big \\(\\mathcal{O}\\) notation Consider a function \\(2n^2\\) is \\(\\mathcal{O}(4n^2 + 6nlog(n))\\) , although this is right it is always easier and simpler to write \\(\\mathcal{O}(n^2)\\) Logrithmic Linear Quadractic Polynomial Exponential \\(\\mathcal{O}(log(n))\\) \\(\\mathcal{O}(n)\\) \\(\\mathcal{O}(n^2)\\) \\(\\mathcal{O}(n^k)\\ (k \\ge 1)\\) \\(\\mathcal{O}(a^n)\\ (a \\gt 1)\\) Even though in general we ignore constants in the big \\(\\mathcal{O}\\) notation, we need to be careful and check if the constants have very large constants, in this case big \\(\\mathcal{O}\\) might not be the right assumption for an algorithm. Some Functions Ordered By Growth Rate Commone Name \\(\\mathcal{O}(log(n))\\) Logrithmic \\(\\mathcal{O}(log^2(n))\\) Polytlogrithmic \\(\\mathcal{O}(\\sqrt{n})\\) Square Root \\(\\mathcal{O}(n)\\) Linear \\(\\mathcal{O}(nlog(n))\\) Linearithmic \\(\\mathcal{O}(n^2)\\) Quadratic \\(\\mathcal{O}(n^3)\\) Cubic \\(\\mathcal{O}(2^n)\\) Exponential In the above chart you see that \\(\\sqrt{n}\\) crosses over much later over \\(log^2(n)\\) in comparison to other function pairs. Little \\(\\mathcal{o}\\) and ## Little \\(\\omega\\) # No matter what value of \\(c \\gt 0\\) we choose, we need to see if \\(g(n) \\ge f(n)\\) . For example for a functions \\(12n^2 + 6n\\) , the little \\(\\mathcal{o}\\) is \\(\\mathcal{o}(n^3)\\) . if \\(f(n\\) ) is \\(\\mathcal{o}(g(n)\\) then \\(g(n)\\) is \\(\\omega(f(n))\\) Bubble Sort # BubbleSort ( int [] A , int n ) Input : An array A containing n >= 1 integers Output : The sorted version of the array A for i = 0 to ( n - 1 ) for j = 0 to ( n - 1 - i ) if A [ i ] > A [ j + 1 ] # swap A[j] with A[j + 1] temp <- A [ j ] A [ j ] <- A [ j + 1 ] A [ j + 1 ] <- temp return A Analysis of the above algorithm: Number of primitive operations BubbleSortOptimized ( int [] A , int n ) Input : An array A containing n >= 1 integers Output : The sorted version of the array A for i = 0 to ( n - 1 ) swaps = 0 for j = 1 to ( n - 1 - i ) if A [ i ] > A [ j + 1 ] # swap A[j] with A[j + 1] temp <- A [ j ] A [ j ] <- A [ j + 1 ] A [ j + 1 ] <- temp swaps <- swaps + 1 if swaps == 0 break return A Tags: !DatastructuresAndAlgorithmsIndex","title":"Week 4 (cont.)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA2.html#week-4-cont","text":"Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 22/Aug/2021","title":"Week 4 (cont.)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA2.html#topics-covered","text":"Rules to Find Big \\(\\mathcal{O}\\) Notation (cont.) Little \\(\\mathcal{o}\\) and ## Little \\(\\omega\\) Bubble Sort","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA2.html#rules-to-find-bigmathcalo-notation-cont","text":"It is considered poor taste to include constant factors and lower order terms in the big \\(\\mathcal{O}\\) notation Consider a function \\(2n^2\\) is \\(\\mathcal{O}(4n^2 + 6nlog(n))\\) , although this is right it is always easier and simpler to write \\(\\mathcal{O}(n^2)\\) Logrithmic Linear Quadractic Polynomial Exponential \\(\\mathcal{O}(log(n))\\) \\(\\mathcal{O}(n)\\) \\(\\mathcal{O}(n^2)\\) \\(\\mathcal{O}(n^k)\\ (k \\ge 1)\\) \\(\\mathcal{O}(a^n)\\ (a \\gt 1)\\) Even though in general we ignore constants in the big \\(\\mathcal{O}\\) notation, we need to be careful and check if the constants have very large constants, in this case big \\(\\mathcal{O}\\) might not be the right assumption for an algorithm. Some Functions Ordered By Growth Rate Commone Name \\(\\mathcal{O}(log(n))\\) Logrithmic \\(\\mathcal{O}(log^2(n))\\) Polytlogrithmic \\(\\mathcal{O}(\\sqrt{n})\\) Square Root \\(\\mathcal{O}(n)\\) Linear \\(\\mathcal{O}(nlog(n))\\) Linearithmic \\(\\mathcal{O}(n^2)\\) Quadratic \\(\\mathcal{O}(n^3)\\) Cubic \\(\\mathcal{O}(2^n)\\) Exponential In the above chart you see that \\(\\sqrt{n}\\) crosses over much later over \\(log^2(n)\\) in comparison to other function pairs.","title":"Rules to Find Big\\(\\mathcal{O}\\) Notation (cont.)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA2.html#littlemathcalo-and--littleomega","text":"No matter what value of \\(c \\gt 0\\) we choose, we need to see if \\(g(n) \\ge f(n)\\) . For example for a functions \\(12n^2 + 6n\\) , the little \\(\\mathcal{o}\\) is \\(\\mathcal{o}(n^3)\\) . if \\(f(n\\) ) is \\(\\mathcal{o}(g(n)\\) then \\(g(n)\\) is \\(\\omega(f(n))\\)","title":"Little\\(\\mathcal{o}\\) and ## Little\\(\\omega\\)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week4DSA2.html#bubble-sort","text":"BubbleSort ( int [] A , int n ) Input : An array A containing n >= 1 integers Output : The sorted version of the array A for i = 0 to ( n - 1 ) for j = 0 to ( n - 1 - i ) if A [ i ] > A [ j + 1 ] # swap A[j] with A[j + 1] temp <- A [ j ] A [ j ] <- A [ j + 1 ] A [ j + 1 ] <- temp return A Analysis of the above algorithm: Number of primitive operations BubbleSortOptimized ( int [] A , int n ) Input : An array A containing n >= 1 integers Output : The sorted version of the array A for i = 0 to ( n - 1 ) swaps = 0 for j = 1 to ( n - 1 - i ) if A [ i ] > A [ j + 1 ] # swap A[j] with A[j + 1] temp <- A [ j ] A [ j ] <- A [ j + 1 ] A [ j + 1 ] <- temp swaps <- swaps + 1 if swaps == 0 break return A Tags: !DatastructuresAndAlgorithmsIndex","title":"Bubble Sort"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week5DSA.html","text":"Week 5 # Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 22/Aug/2021 Topics Covered # Rules to Find Big \\(\\mathcal{O}\\) Notation (cont.) Little \\(\\mathcal{o}\\) and ## Little \\(\\omega\\) Bubble Sort Rules to Find Big \\(\\mathcal{O}\\) Notation (cont.) # It is considered poor taste to include constant factors and lower order terms in the big \\(\\mathcal{O}\\) notation Consider a function \\(2n^2\\) is \\(\\mathcal{O}(4n^2 + 6nlog(n))\\) , although this is right it is always easier and simpler to write \\(\\mathcal{O}(n^2)\\) Logrithmic Linear Quadractic Polynomial Exponential \\(\\mathcal{O}(log(n))\\) \\(\\mathcal{O}(n)\\) \\(\\mathcal{O}(n^2)\\) \\(\\mathcal{O}(n^k)\\ (k \\ge 1)\\) \\(\\mathcal{O}(a^n)\\ (a \\gt 1)\\) Even though in general we ignore constants in the big \\(\\mathcal{O}\\) notation, we need to be careful and check if the constants have very large constants, in this case big \\(\\mathcal{O}\\) might not be the right assumption for an algorithm. Some Functions Ordered By Growth Rate Commone Name \\(\\mathcal{O}(log(n))\\) Logrithmic \\(\\mathcal{O}(log^2(n))\\) Polytlogrithmic \\(\\mathcal{O}(\\sqrt{n})\\) Square Root \\(\\mathcal{O}(n)\\) Linear \\(\\mathcal{O}(nlog(n))\\) Linearithmic \\(\\mathcal{O}(n^2)\\) Quadratic \\(\\mathcal{O}(n^3)\\) Cubic \\(\\mathcal{O}(2^n)\\) Exponential In the above chart you see that \\(\\sqrt{n}\\) crosses over much later over \\(log^2(n)\\) in comparison to other function pairs. Little \\(\\mathcal{o}\\) and ## Little \\(\\omega\\) # No matter what value of \\(c \\gt 0\\) we choose, we need to see if \\(g(n) \\ge f(n)\\) . For example for a functions \\(12n^2 + 6n\\) , the little \\(\\mathcal{o}\\) is \\(\\mathcal{o}(n^3)\\) . if \\(f(n\\) ) is \\(\\mathcal{o}(g(n)\\) then \\(g(n)\\) is \\(\\omega(f(n))\\) Bubble Sort # BubbleSort ( int [] A , int n ) Input : An array A containing n >= 1 integers Output : The sorted version of the array A for i = 0 to ( n - 1 ) for j = 0 to ( n - 1 - i ) if A [ i ] > A [ j + 1 ] # swap A[j] with A[j + 1] temp <- A [ j ] A [ j ] <- A [ j + 1 ] A [ j + 1 ] <- temp return A Analysis of the above algorithm: Number of primitive operations BubbleSortOptimized ( int [] A , int n ) Input : An array A containing n >= 1 integers Output : The sorted version of the array A for i = 0 to ( n - 1 ) swaps = 0 for j = 1 to ( n - 1 - i ) if A [ i ] > A [ j + 1 ] # swap A[j] with A[j + 1] temp <- A [ j ] A [ j ] <- A [ j + 1 ] A [ j + 1 ] <- temp swaps <- swaps + 1 if swaps == 0 break return A Tags: !DatastructuresAndAlgorithmsIndex","title":"Week 5"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week5DSA.html#week-5","text":"Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 22/Aug/2021","title":"Week 5"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week5DSA.html#topics-covered","text":"Rules to Find Big \\(\\mathcal{O}\\) Notation (cont.) Little \\(\\mathcal{o}\\) and ## Little \\(\\omega\\) Bubble Sort","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week5DSA.html#rules-to-find-bigmathcalo-notation-cont","text":"It is considered poor taste to include constant factors and lower order terms in the big \\(\\mathcal{O}\\) notation Consider a function \\(2n^2\\) is \\(\\mathcal{O}(4n^2 + 6nlog(n))\\) , although this is right it is always easier and simpler to write \\(\\mathcal{O}(n^2)\\) Logrithmic Linear Quadractic Polynomial Exponential \\(\\mathcal{O}(log(n))\\) \\(\\mathcal{O}(n)\\) \\(\\mathcal{O}(n^2)\\) \\(\\mathcal{O}(n^k)\\ (k \\ge 1)\\) \\(\\mathcal{O}(a^n)\\ (a \\gt 1)\\) Even though in general we ignore constants in the big \\(\\mathcal{O}\\) notation, we need to be careful and check if the constants have very large constants, in this case big \\(\\mathcal{O}\\) might not be the right assumption for an algorithm. Some Functions Ordered By Growth Rate Commone Name \\(\\mathcal{O}(log(n))\\) Logrithmic \\(\\mathcal{O}(log^2(n))\\) Polytlogrithmic \\(\\mathcal{O}(\\sqrt{n})\\) Square Root \\(\\mathcal{O}(n)\\) Linear \\(\\mathcal{O}(nlog(n))\\) Linearithmic \\(\\mathcal{O}(n^2)\\) Quadratic \\(\\mathcal{O}(n^3)\\) Cubic \\(\\mathcal{O}(2^n)\\) Exponential In the above chart you see that \\(\\sqrt{n}\\) crosses over much later over \\(log^2(n)\\) in comparison to other function pairs.","title":"Rules to Find Big\\(\\mathcal{O}\\) Notation (cont.)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week5DSA.html#littlemathcalo-and--littleomega","text":"No matter what value of \\(c \\gt 0\\) we choose, we need to see if \\(g(n) \\ge f(n)\\) . For example for a functions \\(12n^2 + 6n\\) , the little \\(\\mathcal{o}\\) is \\(\\mathcal{o}(n^3)\\) . if \\(f(n\\) ) is \\(\\mathcal{o}(g(n)\\) then \\(g(n)\\) is \\(\\omega(f(n))\\)","title":"Little\\(\\mathcal{o}\\) and ## Little\\(\\omega\\)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week5DSA.html#bubble-sort","text":"BubbleSort ( int [] A , int n ) Input : An array A containing n >= 1 integers Output : The sorted version of the array A for i = 0 to ( n - 1 ) for j = 0 to ( n - 1 - i ) if A [ i ] > A [ j + 1 ] # swap A[j] with A[j + 1] temp <- A [ j ] A [ j ] <- A [ j + 1 ] A [ j + 1 ] <- temp return A Analysis of the above algorithm: Number of primitive operations BubbleSortOptimized ( int [] A , int n ) Input : An array A containing n >= 1 integers Output : The sorted version of the array A for i = 0 to ( n - 1 ) swaps = 0 for j = 1 to ( n - 1 - i ) if A [ i ] > A [ j + 1 ] # swap A[j] with A[j + 1] temp <- A [ j ] A [ j ] <- A [ j + 1 ] A [ j + 1 ] <- temp swaps <- swaps + 1 if swaps == 0 break return A Tags: !DatastructuresAndAlgorithmsIndex","title":"Bubble Sort"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week6DSA.html","text":"Week 6 # Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 4/Sep/2021 Topics Covered # Merge Sort Steps Algorithm Merge Function Sort Function Algorithm Analysis Space Complexity Time Complexity Merge Sort # Merge Sort is not an in-place sort like the other three that was explained above Steps # Let us consider the following arrays \\(4, 1, 7, 5, 2, 3\\) Now let us split this array into two halves: \\(4, 1, 7\\ |\\ 5, 2, 3\\) And let us sort these two parts: \\(1, 4, 7\\ |\\ 2, 3, 5\\) When merging the above two parts, we maintain two pointers that start on either parts, and we compare the elements pointed by these two and place the smaller element into a new array and advance that pointer and repeat the above procedure till all the elements are compared. Algorithm # Merge Function # merge ( S1 , S2 , S ): Input : Two arrays , S1 , S2 , of size n1 and n2 sorted in non decreasing order , and an empty array S of size n1 + n2 Ouput : S , containing the elements from S1 and S2 in sorted order i <- 0 j <- 0 while i < n1 and j < n2 do if S1 [ i ] <= S2 [ j ] then S [ i + j ] <- S1 [ i ] i <- i + 1 else S [ i + j ] <- S2 [ j ] j <- j + 1 while i <= n1 do S [ i + j ] <- S1 [ i ] i <- i + 1 while i <= n2 do S [ i + j ] <- S2 [ j ] j <- j + 1 Sort Function # The actual sorting is done in a divide and conquer fashion denoted by the below steps: 1. Divide: If \\(S\\) has zero or one element, return \\(S\\) immediately, it is already sorted, Otherwise put the elements of \\(S\\) into two sequences \\(S_1\\) and \\(S_2\\) , each containing about half of the elements of \\(S\\) 2. Recur: Recursively sort the sequences \\(S_1\\) and \\(S_2\\) 3. Conquer: Put back the elements into S by merging the sorted sequences \\(S_1\\) and \\(S_2\\) into a sorted sequence. sort ( S ): Input : An array of size n Ouput : The sorted version of the array S if n == 1 then return S if n == 2 then if S [ 0 ] > S [ 1 ] then S [ 0 ] <-> S [ 1 ] return S S1 <- { S [ 0 ], S [ 1 ], S [ 2 ], .... , S [ n / 2 ]} S1 <- { S [( n / 2 ) + 1 ], .... , S [ n - 2 ], S [ n - 1 ]} R1 <- sort ( S1 ) R2 <- sort ( S2 ) merge ( R1 , R2 , R ) # R is an empty array of size n return R Algorithm Analysis # Space Complexity # The recursive tree for a random input array would look something like this: From the above image you can see that the number of memory blocks from the root to the leaf node of the recursive tree is at max \\(n\\) , so: Space Complexity: \\(\\mathcal{O}(n)\\) Time Complexity # At every level, we do a total effort of merging in the order of \\(\\mathcal{O}(n)\\) The total height of the recursive tree is given by the order of \\(\\mathcal{O}(log\\ n)\\) So Time Complexity: \\(\\mathcal{O}(n\\ log\\ n)\\) Tags: !DatastructuresAndAlgorithmsIndex","title":"Week 6"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week6DSA.html#week-6","text":"Lecturer : Pritam Bhattacharya , BITS Pilani, Goa Campus Date : 4/Sep/2021","title":"Week 6"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week6DSA.html#topics-covered","text":"Merge Sort Steps Algorithm Merge Function Sort Function Algorithm Analysis Space Complexity Time Complexity","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week6DSA.html#merge-sort","text":"Merge Sort is not an in-place sort like the other three that was explained above","title":"Merge Sort"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week6DSA.html#steps","text":"Let us consider the following arrays \\(4, 1, 7, 5, 2, 3\\) Now let us split this array into two halves: \\(4, 1, 7\\ |\\ 5, 2, 3\\) And let us sort these two parts: \\(1, 4, 7\\ |\\ 2, 3, 5\\) When merging the above two parts, we maintain two pointers that start on either parts, and we compare the elements pointed by these two and place the smaller element into a new array and advance that pointer and repeat the above procedure till all the elements are compared.","title":"Steps"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week6DSA.html#algorithm","text":"","title":"Algorithm"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week6DSA.html#merge-function","text":"merge ( S1 , S2 , S ): Input : Two arrays , S1 , S2 , of size n1 and n2 sorted in non decreasing order , and an empty array S of size n1 + n2 Ouput : S , containing the elements from S1 and S2 in sorted order i <- 0 j <- 0 while i < n1 and j < n2 do if S1 [ i ] <= S2 [ j ] then S [ i + j ] <- S1 [ i ] i <- i + 1 else S [ i + j ] <- S2 [ j ] j <- j + 1 while i <= n1 do S [ i + j ] <- S1 [ i ] i <- i + 1 while i <= n2 do S [ i + j ] <- S2 [ j ] j <- j + 1","title":"Merge Function"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week6DSA.html#sort-function","text":"The actual sorting is done in a divide and conquer fashion denoted by the below steps: 1. Divide: If \\(S\\) has zero or one element, return \\(S\\) immediately, it is already sorted, Otherwise put the elements of \\(S\\) into two sequences \\(S_1\\) and \\(S_2\\) , each containing about half of the elements of \\(S\\) 2. Recur: Recursively sort the sequences \\(S_1\\) and \\(S_2\\) 3. Conquer: Put back the elements into S by merging the sorted sequences \\(S_1\\) and \\(S_2\\) into a sorted sequence. sort ( S ): Input : An array of size n Ouput : The sorted version of the array S if n == 1 then return S if n == 2 then if S [ 0 ] > S [ 1 ] then S [ 0 ] <-> S [ 1 ] return S S1 <- { S [ 0 ], S [ 1 ], S [ 2 ], .... , S [ n / 2 ]} S1 <- { S [( n / 2 ) + 1 ], .... , S [ n - 2 ], S [ n - 1 ]} R1 <- sort ( S1 ) R2 <- sort ( S2 ) merge ( R1 , R2 , R ) # R is an empty array of size n return R","title":"Sort Function"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week6DSA.html#algorithm-analysis","text":"","title":"Algorithm Analysis"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week6DSA.html#space-complexity","text":"The recursive tree for a random input array would look something like this: From the above image you can see that the number of memory blocks from the root to the leaf node of the recursive tree is at max \\(n\\) , so: Space Complexity: \\(\\mathcal{O}(n)\\)","title":"Space Complexity"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Datastructures%20and%20Algorithms/Week6DSA.html#time-complexity","text":"At every level, we do a total effort of merging in the order of \\(\\mathcal{O}(n)\\) The total height of the recursive tree is given by the order of \\(\\mathcal{O}(log\\ n)\\) So Time Complexity: \\(\\mathcal{O}(n\\ log\\ n)\\) Tags: !DatastructuresAndAlgorithmsIndex","title":"Time Complexity"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/%21DistributedComputingIndex.html","text":"Distributed Computing Index # This is an Index page for all Distributed Computing Content Week 1 Lecture Notes: Week1DC Pre Reading: PreReadingWeek1DC Week 2 Lecture Notes: Week2DC Week 3 Lecture Notes: Week3DC Week 4 Lecture Notes: Week4DC Lecture Notes: Week4DC2 Week 5 Lecture Notes: Week5DC Tags: !Semester1Index","title":"Distributed Computing Index"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/%21DistributedComputingIndex.html#distributed-computing-index","text":"This is an Index page for all Distributed Computing Content Week 1 Lecture Notes: Week1DC Pre Reading: PreReadingWeek1DC Week 2 Lecture Notes: Week2DC Week 3 Lecture Notes: Week3DC Week 4 Lecture Notes: Week4DC Lecture Notes: Week4DC2 Week 5 Lecture Notes: Week5DC Tags: !Semester1Index","title":"Distributed Computing Index"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html","text":"Pre Reading for Week 1 # NOTE THAT THIS PAGE HAS DIAGRAMS THAT ARE BEST VISIBLE IN LIGHT MODE Module 1 # Session 1 # Relation between software components # The middleware and the distributed application abstracts the fact that the application is being run by multiple computers to the user. Some popular examples of Distributed computing: 1. Tor distributed network 2. Internet of Things: A network of several entities (ranging from small sensors to full fledged PCs) connected over a network so that an application can make sense of this data as a whole 3. Cloud computing is also a distributed computing paradigm. Session 2 # Multiprocessor Vs Multi-computer systems # Multiprocessor # Multiple CPUs connected with multiple memory banks through a high speed connection network (Uniform or non uniform memory access model). One cannot allow a more than one processor access the same memory bank unless some sort of synchronization is done to serialize the arbitrate the access request. In a Symmetric multi processor machine all CPUs have the autonomy of deciding what it needs to be done (No master slave) In an Asymmetric multi processor machine, there is a concept of master slave where the master processor decide what the other processors needs to compute. The multiple processors can connect to a particular memory bank when a particular switch is clicked on in the case of cross point switch , this method is not feasible since the number of cross connection can be limiting for very large configurations of CPU and memory banks In case of an omega switching network , each omega switch is arranged in stages and the layers allow for lesser switches to pair the CPUs to the memory banks In both of the above cases the s Multi-computer # Multiple computers are connected over a high speed connection network, where the latency involved in this communication depends on the type of distributed computing designed (Varies from cluster computing, grid computing, IOT, or a common consumer computers connected together across the interweb) Unlike multiprocessor systems, the computers themselves do not need switching networks as explained above but can be connected over networks (LAN, WAN, MAN) Pros and Cons of Distributed systems # Pros Communication and resource sharing possible Price to performance ratio is better More reliable and easily scalable Potential for incremental growth Cons Requires OSs to be able to work in a distributed mode(same goes for applications) High speed reliable network connectivity is essential (Like GARUDA Grid) Security and privacy (Similar to networking, the risks of getting hacked affects distributed computers as well) Design issues # Scaling # If possible use asynchronous communication, since more the synchronous communication the worse it scales (Only if possible) One can also move parts of computation(To the client) in order to reduce latency from the server side Here you see that the form checking is done on the client side which will make the form processing part of the server more scalable. DNS is a good example for distributed query processing where a whole URL Other design issues # Lack of global knowledge Naming (Name resolutions done by DNS is a challenging task) Compatibility (When multiple resources are used together all must be compatible) Process synchronization Resource management (Hard to arbiterate tasks) Security Session 3 # RPC (Remote Procedure Call) # Issues: Identifying and accessing the remote procedure Parameters required to run the procedure Return values that need to be given once the call is sompleted Examples: Sun RPC Microsoft DCOM OMG's CORBA Java RMI CML/RPC SOAP/.NET AJAX(Asynch. Javascript and XML) In an RPC, there is a client machine that calls the procedures to the client-side stub (Which abstracts the remote calls) The binding server handles the queries by the client-side stub to know the server address to which the remote procedure must be sent to. The client processes the data (Like conversion of big endian and little endian differences) by something called marshalling parameters The server side stub unmarshals the params given and a call is done to do the work and the return value is again marshalled and sent to the client side stub The client again unmarshalls and gives the result back A given procedure can be identified by the following: 1. Hostname (IP Address) 2. Program identifier (32 bit integers) 3. Procedure identifier (32 bit integers) 4. Program Version identifier Example of RPC programming Create a RPC file as follows: struct square_in { long arg1 }; struct square_out { long res1 }; program SQUARE_PROG { version SQUARE_VERS { square_out SQUAREPROC(square_in) = 1; } = 1; } = 0x13451111; Take that file and give it to rpcgen (Developed by sun microsystems) the rpc gen automatically produces the necessary files. Now we need to write the Client side logic to make the Remote call: Here we are including the \"square.h\" file where we can get access to the structs for the input, and even a client handle to pass the required params to send to the processing server Now we need to write the server side logic to process the remote call: Here we define the remote function that needs to be run based on the conventions put on by sun microsystems Module 2 # Session 1 # What is a distributed program? # A program that consists of a set of n asynchronous processes . These processes do not share a global memory and use only message passing APIs for coms. These process do not share a global clock that is accessible at the same time. The process These process executions and message transfers are asynchronous . Model of distributed executions # Given 3 processes \\(p1\\) , \\(p2\\) and \\(p3\\) , we represent them in a space-time diagram where Time is in x and space is in y axis. Here we see the relationships between the events for each process Event Process Type \\(e1\\) \\(P1\\) Local Event \\(e2\\) \\(P1\\) Message Send Event (to \\(e5\\) ) \\(e3\\) \\(P1\\) Message Receive Event (from \\(e4\\) ) \\(e4\\) \\(P2\\) Message Send Event (to \\(e3\\) ) \\(e5\\) \\(P2\\) Message Receive Event (from \\(e2\\) ) \\(e6\\) \\(P3\\) Local Event \\(e7\\) \\(P3\\) Local Event \\(e8\\) \\(P3\\) Local Event A local event is an event that is local to a given process A Message send event is an event in a process which asynchronously sent a message to another process A Message receive event is an event in a process which asynchronously receives a message from another process The diagram above shows us causal-effect relationships between events across different processes that gives us an idea on how to design a distributed system Models of communication networks # There are namely 3: 1. FIFO 2. Non FIFO 3. Causal Ordering Consider the following processes ( \\(P1\\) , \\(P2\\) and \\(P3\\) ) with communication channels( \\(c1\\) , \\(c2\\) , \\(c3\\) and \\(c4\\) ): graph LR P1--c1-->P2 P2--c2-->P3 P1--c3-->P3 P3--c4-->P1 If \\(P2\\) sends messages \\(m1\\) first and then \\(m2\\) to \\(P3\\) through the channel \\(c2\\) , then if \\(c2\\) was a FIFO channel then \\(P3\\) receives \\(m1\\) first and then \\(m2\\) , making FIFO channels very predictable. If \\(P3\\) sends four messages \\(m1\\) , \\(m2\\) , \\(m3\\) and \\(m4\\) through the channel \\(c4\\) , then if \\(c4\\) was a Non FIFO channel then \\(P1\\) would receive the messages in random order. This is useful if the algorithms in place can handle receiving messages in random order. If a channel follows causal order, then we do not need to check if a message was sent in a particular order or not, since for every message sent there is a receipt even in a process and the ordering is maintained by the receiving end of the process. Global state of a DS # A local state of a process is the current execution state at which a particular process is in. A Global state of a DS is a collection of such above mentioned local states of processes and channels The global state \\(GS\\) is defined as: \\[GS = \\{\\ \\bigcup_i\\ LS_i^{xi}\\ ,\\ \\bigcup_{j,k}\\ SC_{jk}^{yj,\\ zk}\\ \\}\\] \\(GS\\) is the union of all Local States of all machines and all the messages across all the message channels. - A \\(GS\\) is meaningful only when all the states of all the components of the DS are recorded at the same instant - The only way that is possible is when all the processes are synchronous in nature or if there were a global, instantaneously accessible clock (Both of which are impossible in a typical DS) - To calculate the \\(GS\\) there exists multiple algorithms to calculate the same Consistent global state # - In the above diagram if we were to calculate the \\(GS_1\\) at the red line drawn, we can say that the \\(GS_1\\) is the sum of \\(LS_1\\) , \\(LS_2\\) , \\(LS_3\\) and \\(LS_4\\) . Here the \\(GS\\) is strongly consistent since there are no send or receive messages crossing in that slice of time. - In the same diagram \\(GS_2\\) is the sum of \\(LS_5\\) , \\(LS_6\\) , \\(LS_7\\) and \\(LS_8\\) . Here the \\(GS\\) does have a record of the message sent by \\(e_1^4\\) but not the state of the message being received by \\(e_3^5\\) , hence the \\(GS\\) although consistent enough to use it for calculating typical things such as deadlocks etc but just not strongly consistent. - An \\(GS\\) is said to be inconsistent if the local states were calculated in a way where the message receive event is considered but the corresponding message sent is missed. This makes the \\(GS\\) is rendered useless. Session 2 # Logical Clocks # Lamport Logical Clocks (Scalar Time) - Causality among events in a DS is a way of analyzing processes and infer details regarding the computation. - The knowledge of causal precedence relation among several events of different processes helps solve a variety of problems in a DS. Scalar Time # In a scalar time clock, we condense the process, its local view of the global time into a single variable called \\(C_i\\) . With the above assumption there exists 2 rules to update the internal clock: Rule 1 : Before executing an event, process \\(p_i\\) executes the clock value to be as: \\[ C_i := C_i + d\\ \\ \\ (d > 0) \\] In general, every time \\(R_1\\) is executed, \\(d\\) can also have a different value. 2. Rule 2 : Each message piggybacks the clock value of its sender at sending time. When a process \\(p_i\\) receives a message with timestamp \\(C{msg}\\) , it executes the following actions: \\[ C_i := max(C_i, C_{msg}) \\] Execute \\(R_1\\) Deliver the message Example: Looking at the above scenario we can infer that if one event ( \\(e_i\\) ) sends a message to another event( \\(e_j\\) ) we can say that: \\[ for\\ two\\ events\\ e_i\\ and\\ e_j\\ ,\\ e_i\\ ->\\ e_j =>C(e_i) < C(e_j) \\] But the reverse is not true. - There are the following problems when it comes to this clock : - Non consistency : We can never say that the event \\(e_1\\) had happened before \\(e_5\\) merely because the clock value of one was lesser than the other. This is because there is no direct or indirect link that connects \\(e_1\\) to \\(e_5\\) . - There is a problem when the clock values are same for two events. In this case we can take precedence by considering the precedence of the process itself (Take the process index values into consideration). Considering the above example \\(e_1\\) and \\(e_3\\) have the same clock values so we can never say which one happened before what, hence we can use the indexes of the process itself, since index of process \\(P_2\\) is greater than process \\(P_1\\) we can assume that \\(e_1\\) has happened before \\(e_3\\) Tags: !DistributedComputingIndex","title":"Pre Reading for Week 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#pre-reading-for-week-1","text":"NOTE THAT THIS PAGE HAS DIAGRAMS THAT ARE BEST VISIBLE IN LIGHT MODE","title":"Pre Reading for Week 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#module-1","text":"","title":"Module 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#session-1","text":"","title":"Session 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#relation-between-software-components","text":"The middleware and the distributed application abstracts the fact that the application is being run by multiple computers to the user. Some popular examples of Distributed computing: 1. Tor distributed network 2. Internet of Things: A network of several entities (ranging from small sensors to full fledged PCs) connected over a network so that an application can make sense of this data as a whole 3. Cloud computing is also a distributed computing paradigm.","title":"Relation between software components"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#session-2","text":"","title":"Session 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#multiprocessor-vs-multi-computer-systems","text":"","title":"Multiprocessor Vs Multi-computer systems"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#multiprocessor","text":"Multiple CPUs connected with multiple memory banks through a high speed connection network (Uniform or non uniform memory access model). One cannot allow a more than one processor access the same memory bank unless some sort of synchronization is done to serialize the arbitrate the access request. In a Symmetric multi processor machine all CPUs have the autonomy of deciding what it needs to be done (No master slave) In an Asymmetric multi processor machine, there is a concept of master slave where the master processor decide what the other processors needs to compute. The multiple processors can connect to a particular memory bank when a particular switch is clicked on in the case of cross point switch , this method is not feasible since the number of cross connection can be limiting for very large configurations of CPU and memory banks In case of an omega switching network , each omega switch is arranged in stages and the layers allow for lesser switches to pair the CPUs to the memory banks In both of the above cases the s","title":"Multiprocessor"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#multi-computer","text":"Multiple computers are connected over a high speed connection network, where the latency involved in this communication depends on the type of distributed computing designed (Varies from cluster computing, grid computing, IOT, or a common consumer computers connected together across the interweb) Unlike multiprocessor systems, the computers themselves do not need switching networks as explained above but can be connected over networks (LAN, WAN, MAN)","title":"Multi-computer"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#pros-and-cons-of-distributed-systems","text":"Pros Communication and resource sharing possible Price to performance ratio is better More reliable and easily scalable Potential for incremental growth Cons Requires OSs to be able to work in a distributed mode(same goes for applications) High speed reliable network connectivity is essential (Like GARUDA Grid) Security and privacy (Similar to networking, the risks of getting hacked affects distributed computers as well)","title":"Pros and Cons of Distributed systems"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#design-issues","text":"","title":"Design issues"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#scaling","text":"If possible use asynchronous communication, since more the synchronous communication the worse it scales (Only if possible) One can also move parts of computation(To the client) in order to reduce latency from the server side Here you see that the form checking is done on the client side which will make the form processing part of the server more scalable. DNS is a good example for distributed query processing where a whole URL","title":"Scaling"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#other-design-issues","text":"Lack of global knowledge Naming (Name resolutions done by DNS is a challenging task) Compatibility (When multiple resources are used together all must be compatible) Process synchronization Resource management (Hard to arbiterate tasks) Security","title":"Other design issues"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#session-3","text":"","title":"Session 3"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#rpc-remote-procedure-call","text":"Issues: Identifying and accessing the remote procedure Parameters required to run the procedure Return values that need to be given once the call is sompleted Examples: Sun RPC Microsoft DCOM OMG's CORBA Java RMI CML/RPC SOAP/.NET AJAX(Asynch. Javascript and XML) In an RPC, there is a client machine that calls the procedures to the client-side stub (Which abstracts the remote calls) The binding server handles the queries by the client-side stub to know the server address to which the remote procedure must be sent to. The client processes the data (Like conversion of big endian and little endian differences) by something called marshalling parameters The server side stub unmarshals the params given and a call is done to do the work and the return value is again marshalled and sent to the client side stub The client again unmarshalls and gives the result back A given procedure can be identified by the following: 1. Hostname (IP Address) 2. Program identifier (32 bit integers) 3. Procedure identifier (32 bit integers) 4. Program Version identifier Example of RPC programming Create a RPC file as follows: struct square_in { long arg1 }; struct square_out { long res1 }; program SQUARE_PROG { version SQUARE_VERS { square_out SQUAREPROC(square_in) = 1; } = 1; } = 0x13451111; Take that file and give it to rpcgen (Developed by sun microsystems) the rpc gen automatically produces the necessary files. Now we need to write the Client side logic to make the Remote call: Here we are including the \"square.h\" file where we can get access to the structs for the input, and even a client handle to pass the required params to send to the processing server Now we need to write the server side logic to process the remote call: Here we define the remote function that needs to be run based on the conventions put on by sun microsystems","title":"RPC (Remote Procedure Call)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#module-2","text":"","title":"Module 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#session-1_1","text":"","title":"Session 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#what-is-a-distributed-program","text":"A program that consists of a set of n asynchronous processes . These processes do not share a global memory and use only message passing APIs for coms. These process do not share a global clock that is accessible at the same time. The process These process executions and message transfers are asynchronous .","title":"What is a distributed program?"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#model-of-distributed-executions","text":"Given 3 processes \\(p1\\) , \\(p2\\) and \\(p3\\) , we represent them in a space-time diagram where Time is in x and space is in y axis. Here we see the relationships between the events for each process Event Process Type \\(e1\\) \\(P1\\) Local Event \\(e2\\) \\(P1\\) Message Send Event (to \\(e5\\) ) \\(e3\\) \\(P1\\) Message Receive Event (from \\(e4\\) ) \\(e4\\) \\(P2\\) Message Send Event (to \\(e3\\) ) \\(e5\\) \\(P2\\) Message Receive Event (from \\(e2\\) ) \\(e6\\) \\(P3\\) Local Event \\(e7\\) \\(P3\\) Local Event \\(e8\\) \\(P3\\) Local Event A local event is an event that is local to a given process A Message send event is an event in a process which asynchronously sent a message to another process A Message receive event is an event in a process which asynchronously receives a message from another process The diagram above shows us causal-effect relationships between events across different processes that gives us an idea on how to design a distributed system","title":"Model of distributed executions"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#models-of-communication-networks","text":"There are namely 3: 1. FIFO 2. Non FIFO 3. Causal Ordering Consider the following processes ( \\(P1\\) , \\(P2\\) and \\(P3\\) ) with communication channels( \\(c1\\) , \\(c2\\) , \\(c3\\) and \\(c4\\) ): graph LR P1--c1-->P2 P2--c2-->P3 P1--c3-->P3 P3--c4-->P1 If \\(P2\\) sends messages \\(m1\\) first and then \\(m2\\) to \\(P3\\) through the channel \\(c2\\) , then if \\(c2\\) was a FIFO channel then \\(P3\\) receives \\(m1\\) first and then \\(m2\\) , making FIFO channels very predictable. If \\(P3\\) sends four messages \\(m1\\) , \\(m2\\) , \\(m3\\) and \\(m4\\) through the channel \\(c4\\) , then if \\(c4\\) was a Non FIFO channel then \\(P1\\) would receive the messages in random order. This is useful if the algorithms in place can handle receiving messages in random order. If a channel follows causal order, then we do not need to check if a message was sent in a particular order or not, since for every message sent there is a receipt even in a process and the ordering is maintained by the receiving end of the process.","title":"Models of communication networks"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#global-state-of-a-ds","text":"A local state of a process is the current execution state at which a particular process is in. A Global state of a DS is a collection of such above mentioned local states of processes and channels The global state \\(GS\\) is defined as: \\[GS = \\{\\ \\bigcup_i\\ LS_i^{xi}\\ ,\\ \\bigcup_{j,k}\\ SC_{jk}^{yj,\\ zk}\\ \\}\\] \\(GS\\) is the union of all Local States of all machines and all the messages across all the message channels. - A \\(GS\\) is meaningful only when all the states of all the components of the DS are recorded at the same instant - The only way that is possible is when all the processes are synchronous in nature or if there were a global, instantaneously accessible clock (Both of which are impossible in a typical DS) - To calculate the \\(GS\\) there exists multiple algorithms to calculate the same","title":"Global state of a DS"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#consistent-global-state","text":"- In the above diagram if we were to calculate the \\(GS_1\\) at the red line drawn, we can say that the \\(GS_1\\) is the sum of \\(LS_1\\) , \\(LS_2\\) , \\(LS_3\\) and \\(LS_4\\) . Here the \\(GS\\) is strongly consistent since there are no send or receive messages crossing in that slice of time. - In the same diagram \\(GS_2\\) is the sum of \\(LS_5\\) , \\(LS_6\\) , \\(LS_7\\) and \\(LS_8\\) . Here the \\(GS\\) does have a record of the message sent by \\(e_1^4\\) but not the state of the message being received by \\(e_3^5\\) , hence the \\(GS\\) although consistent enough to use it for calculating typical things such as deadlocks etc but just not strongly consistent. - An \\(GS\\) is said to be inconsistent if the local states were calculated in a way where the message receive event is considered but the corresponding message sent is missed. This makes the \\(GS\\) is rendered useless.","title":"Consistent global state"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#session-2_1","text":"","title":"Session 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#logical-clocks","text":"Lamport Logical Clocks (Scalar Time) - Causality among events in a DS is a way of analyzing processes and infer details regarding the computation. - The knowledge of causal precedence relation among several events of different processes helps solve a variety of problems in a DS.","title":"Logical Clocks"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/PreReadingWeek1DC.html#scalar-time","text":"In a scalar time clock, we condense the process, its local view of the global time into a single variable called \\(C_i\\) . With the above assumption there exists 2 rules to update the internal clock: Rule 1 : Before executing an event, process \\(p_i\\) executes the clock value to be as: \\[ C_i := C_i + d\\ \\ \\ (d > 0) \\] In general, every time \\(R_1\\) is executed, \\(d\\) can also have a different value. 2. Rule 2 : Each message piggybacks the clock value of its sender at sending time. When a process \\(p_i\\) receives a message with timestamp \\(C{msg}\\) , it executes the following actions: \\[ C_i := max(C_i, C_{msg}) \\] Execute \\(R_1\\) Deliver the message Example: Looking at the above scenario we can infer that if one event ( \\(e_i\\) ) sends a message to another event( \\(e_j\\) ) we can say that: \\[ for\\ two\\ events\\ e_i\\ and\\ e_j\\ ,\\ e_i\\ ->\\ e_j =>C(e_i) < C(e_j) \\] But the reverse is not true. - There are the following problems when it comes to this clock : - Non consistency : We can never say that the event \\(e_1\\) had happened before \\(e_5\\) merely because the clock value of one was lesser than the other. This is because there is no direct or indirect link that connects \\(e_1\\) to \\(e_5\\) . - There is a problem when the clock values are same for two events. In this case we can take precedence by considering the precedence of the process itself (Take the process index values into consideration). Considering the above example \\(e_1\\) and \\(e_3\\) have the same clock values so we can never say which one happened before what, hence we can use the indexes of the process itself, since index of process \\(P_2\\) is greater than process \\(P_1\\) we can assume that \\(e_1\\) has happened before \\(e_3\\) Tags: !DistributedComputingIndex","title":"Scalar Time"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week1DC.html","text":"Week 1 # Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 24/Jul/2021 NOTE THAT THIS PAGE HAS DIAGRAMS THAT ARE BEST VISIBLE IN LIGHT MODE Topics Covered # What is a flipped mode course? What is a distributed system? Motivations for a distributed system Coupling Parallel Systems UMA (Uniform Memory Access) Model Omega Network (An example of UMA) What is a flipped mode course? # A course where there is content from a course ware and a live lecture the events Quizzes and Assignments will be done online in elearn portal 2 Quizzes (MCQ type) predetermined time slots 1 Assignment 1 Mid Sem (Half of the modules) (Theoretical) 1 Comprehensive (All modules) (Theoretical) What is a distributed system? # Collection of independent individual entities (Can function on it's own) to solve a given task collectively graph LR A[PM]---G B[PM]---G C[PM]---G G---D[PM] G---E[PM] G---F[PM] G((Communication Network WAN/LAN)) No common physical clock(system clock) No shared memory - employs message passing for communication Geographical separation - All the nodes taking part in the problem solving can be placed in different locations geographically Autonomy and heterogeneity Each node is a fully functioning independent system irrespective of being taking part in a distributed system. The processors of the nodes are loosely coupled Different processor speeds and operating systems are allowed And despite all these differences they cooperate with one another graph TB A[Application]---G B[Application]---G G---H H---E[Platform1] H---F[Platform2] G[Application Programming Interface API] H[Middleware Distributed Systems Services] Middleware drives the distributed system and the heterogeneity at a platform level is abstracted by APIs. Common Object Request Broker Architecture (CORBA) Remote Procedure Call (RPC) Distributed Component Object Model (DCOM) Remote Method Invocation (RMI) Motivations for a distributed system # Share resources Access to resources from different geographical locations (Like AWS Cloud servers at different locations or even a work from home situation can be covered) Increased performance/cost ratio, since there is a large resource pool and programs can be written in a way to efficiently use that pool to get tasks done more quickly Reliability, in the sense that since the system is distributed, even if one system breaks down, there is still a degree of availability of resources. Scaling, in the sense that it is easy to increase performance by merely adding more nodes to a distributed system. Modularity and Incremental Expandability. Coupling # High coupling: Homogeneous modules and hence have more restrictions imposed on these systems Low coupling: Heterogeneous modules and hence more flexibility is gained Parallel Systems # Multiprocessor systems: Direct access to shared memory area/address space Usually do not have a common system clock Eg, Omega, Butterfly Networks Multicomputer parallel systems There are multiple processors but no direct access to shared memory/address space There can be more than one nodes, but most likely are not geographically separated Eg, IBM Blue gene, CM* Connection Machine Array Processors Collocated Tightly Coupled Common system clock UMA (Uniform Memory Access) Model # Direct access to shared memory Access latency : Waiting time to complete an access to any memory location from any processor Access latency is same for all processors Processors remain in close proximity Connected by an interconnection network Processors are of the same type Omega Network (An example of UMA) # 2x2 switching elements data can be sent on any one for the input wires n-input and n-output network uses \\(log_2(n)\\) stages \\(log_2(n)\\) bits for addressing n processors, n memory banks \\(\\frac{n}{2}log_2(n)\\) switching elements of size 2/2 interconnection function defines how output \\(i\\) of one one stage is connected to input \\(j\\) of the next stage In this example the interconnection function is a left rotation operation on the binary representation of \\(i\\) to get \\(j\\) Tags: !DistributedComputingIndex","title":"Week 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week1DC.html#week-1","text":"Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 24/Jul/2021 NOTE THAT THIS PAGE HAS DIAGRAMS THAT ARE BEST VISIBLE IN LIGHT MODE","title":"Week 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week1DC.html#topics-covered","text":"What is a flipped mode course? What is a distributed system? Motivations for a distributed system Coupling Parallel Systems UMA (Uniform Memory Access) Model Omega Network (An example of UMA)","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week1DC.html#what-is-a-flipped-mode-course","text":"A course where there is content from a course ware and a live lecture the events Quizzes and Assignments will be done online in elearn portal 2 Quizzes (MCQ type) predetermined time slots 1 Assignment 1 Mid Sem (Half of the modules) (Theoretical) 1 Comprehensive (All modules) (Theoretical)","title":"What is a flipped mode course?"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week1DC.html#what-is-a-distributed-system","text":"Collection of independent individual entities (Can function on it's own) to solve a given task collectively graph LR A[PM]---G B[PM]---G C[PM]---G G---D[PM] G---E[PM] G---F[PM] G((Communication Network WAN/LAN)) No common physical clock(system clock) No shared memory - employs message passing for communication Geographical separation - All the nodes taking part in the problem solving can be placed in different locations geographically Autonomy and heterogeneity Each node is a fully functioning independent system irrespective of being taking part in a distributed system. The processors of the nodes are loosely coupled Different processor speeds and operating systems are allowed And despite all these differences they cooperate with one another graph TB A[Application]---G B[Application]---G G---H H---E[Platform1] H---F[Platform2] G[Application Programming Interface API] H[Middleware Distributed Systems Services] Middleware drives the distributed system and the heterogeneity at a platform level is abstracted by APIs. Common Object Request Broker Architecture (CORBA) Remote Procedure Call (RPC) Distributed Component Object Model (DCOM) Remote Method Invocation (RMI)","title":"What is a distributed system?"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week1DC.html#motivations-for-a-distributed-system","text":"Share resources Access to resources from different geographical locations (Like AWS Cloud servers at different locations or even a work from home situation can be covered) Increased performance/cost ratio, since there is a large resource pool and programs can be written in a way to efficiently use that pool to get tasks done more quickly Reliability, in the sense that since the system is distributed, even if one system breaks down, there is still a degree of availability of resources. Scaling, in the sense that it is easy to increase performance by merely adding more nodes to a distributed system. Modularity and Incremental Expandability.","title":"Motivations for a distributed system"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week1DC.html#coupling","text":"High coupling: Homogeneous modules and hence have more restrictions imposed on these systems Low coupling: Heterogeneous modules and hence more flexibility is gained","title":"Coupling"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week1DC.html#parallel-systems","text":"Multiprocessor systems: Direct access to shared memory area/address space Usually do not have a common system clock Eg, Omega, Butterfly Networks Multicomputer parallel systems There are multiple processors but no direct access to shared memory/address space There can be more than one nodes, but most likely are not geographically separated Eg, IBM Blue gene, CM* Connection Machine Array Processors Collocated Tightly Coupled Common system clock","title":"Parallel Systems"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week1DC.html#uma-uniform-memory-access-model","text":"Direct access to shared memory Access latency : Waiting time to complete an access to any memory location from any processor Access latency is same for all processors Processors remain in close proximity Connected by an interconnection network Processors are of the same type","title":"UMA (Uniform Memory Access) Model"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week1DC.html#omega-network-an-example-of-uma","text":"2x2 switching elements data can be sent on any one for the input wires n-input and n-output network uses \\(log_2(n)\\) stages \\(log_2(n)\\) bits for addressing n processors, n memory banks \\(\\frac{n}{2}log_2(n)\\) switching elements of size 2/2 interconnection function defines how output \\(i\\) of one one stage is connected to input \\(j\\) of the next stage In this example the interconnection function is a left rotation operation on the binary representation of \\(i\\) to get \\(j\\) Tags: !DistributedComputingIndex","title":"Omega Network (An example of UMA)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html","text":"Week 2 # Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 31/Jul/2021 NOTE THAT THIS PAGE HAS DIAGRAMS THAT ARE BEST VISIBLE IN LIGHT MODE Topics Covered # Module 1 Multicomputer parallel systems NUMA (Non Uniform Memory Access) Model Wraparound mesh interconnection in an MPS Hypercube interconnection in an MPS Distributed/Parallel Computing Jargon Parallelism/Speedup Parallel/Distributed Program Concurrency Distributed Communication Models RPC (Remote Procedure Call) Publish/Subscribe Module 2 Preliminary understandings Notations Space time diagram What are these letters? Causal precedence/dependency or happens before relation Concurrent events Module 1 # Multicomputer parallel systems # Processors do not have direct access to shared mem . Usually do not have a common clock . Processors are in close proximity . (THIS IS DIFFERENT FROM A DS) Very tightly coupled . (THIS IS DIFFERENT FROM A DS) Connected by an interconnection network. Communicate via Message passing APIs/common address space. (THIS IS DIFFERENT FROM A DS as DS can only use MP APIs). Typically this is used for high performance computing use cases. NUMA (Non Uniform Memory Access) Model # - Above you can see that the individual mem components are not clubbed together like the UMA Model (See here Week1DC#UMA Uniform Memory Access Model ). - The processor can still access the mem components but have a different access latency - non-uniform memory access - Different processor can have different access latency - Multicomputer system having a common address space . - Latency to access various shared memory location from the different processors varies. Wraparound mesh interconnection in an MPS # - The above diagram shows a 2d wraparound mesh - The above diagram corresponds to a \\(4x4\\) mesh containing 16 nodes. - Each node is connected to each and every node around it. The leaf nodes wrap around to the opposite leaf node of their respective row or column, hence the name Wrap Around Configuration . - If any of the nodes go down, the wrap around connection helps in maintaining the connection. - The connection can be bidirectional through a bus or any interconnection logic for that matter. Hypercube interconnection in an MPS # - A k dimensional hypercube has \\(2^k\\) processor and mem units (nodes) - Each node has at most \\(k\\) connections - Each dimension is associated with a bit position in the label - Labels of two adjacent nodes differ in the \\(k^{th}\\) bit position for the dimension k - From node \\(0000\\) we can see that each direction differs by a single bit. bottom is \\(0001\\) , right is \\(0010\\) and the adjacent one is \\(0100\\) - We can by applying the above rules get to know the label for the other adjacent nodes - The shortest path between any two processors is called Hamming distance - consider two bit labels \\(0110\\) and \\(1001\\) , the hamming distance would be 4 since all \\(4\\) bits differ. - consider two bit labels \\(0111\\) and \\(0110\\) , the hamming distance would be 1 since only \\(1\\) bit differs. - The above calculations can be used to connect the nodes according to the label - In the case of such an interconnection the \\(hamming\\ distance <= k\\) - Even if some of the nodes go down, there will be another path present to keep the connection alive. This provides fault tolerance and congestion control mechanism - Routing of messages happen hop by hop Distributed/Parallel Computing Jargon # Parallelism/Speedup # \\[Speedup = \\frac{T(1)}{T(n)}\\] \\(T(1)\\) = Time taken on a single processor \\(T(n)\\) = Time taken with n processors Measure of the relative speedup of a specific program on a given machine This depends on: Number of processors Mapping of the code to the processors Parallel/Distributed Program Concurrency # \\[Parallel\\ Program\\ Concurrency = \\frac{number\\ of\\ local\\ operations}{total\\ number\\ of\\ operations}\\] \\(number\\ of\\ local\\ operations\\) -> Non communication and non shared memory access operations \\(total\\ number\\ of\\ operations\\) -> All operations including communication or shared memory access Distributed Communication Models # RPC (Remote Procedure Call) # This topic is covered in a pre reading session here: PreReadingWeek1DC#RPC Remote Procedure Call - The client procedure calls a client stub to pass params - The client marshals the params (makes a common representation of the params), builds the message, and calls the local OS - The local OS sends the message to the remote OS - The server's remote OS gives the message to a server stub - The server stub de-marshals the params(Converts common form to server OS specific form) and calls the desired server routine - The server computes the result and hands it to the server stub - The server stub marshals the result into a message and calls the local OS - The server OS sends the message to the client OS - The client OS receives the message and sends it to the client stub - The client stub demarshals the result, and execution returns to the client Publish/Subscribe # - We have two entites mainly: - Publishers : Those who create information and publish them to a service (Through a Notify() call) - Subscriber : Those who consume the content published by publishers it had subscribed to. - The Subscriber gets data asynchronous though a notification, and they can continue their tasks until they receive notifications. - The subscriber has an option to unsubscribe as well Module 2 # Preliminary understanding # DS consists of a set of processors. There is an intercommunication network. Delay in communication is finite but is not predictable. Processors do not share a common global memory. Uses asynch message passing. No common physical global clock. Possibility of messages being delivered out of order. Messages may be lost, garbled or duplicated due to timeouts and retransmissions. There is always a possibility of communication and processor failure. Notations # \\(C_{ij}\\) : Channel from process \\(p_i\\) to process \\(p_j\\) \\(m_{ij}\\) : message sent by \\(p_i\\) to \\(p_j\\) Global state \\(GS\\) of a distributed computation consists of: States of the processes: Local memory state States of the communication channels: set of messages in transit Global state is explained in detail here PreReadingWeek1DC#Global state of a DS - Occurrences of events \\(e\\) - Causes changes in respective processes states - Causes changes in channels states - Causes transition in global system state Space time diagram # What are these letters? # \\(p_i\\) denotes the processes in the space axis \\(e_i^j\\) denotes the \\(j^{th}\\) event in process \\(p_i\\) Events that do not have arrows are The arrows denote the direction of the message sent. \\(e_1^2\\) is a message sending event \\(e_3^2\\) is a message receive event Causal precedence/dependency or happens before relation # - Relation ' \\(\\rightarrow\\) ' denotes flow of information in a distributed computation - \\(e_i \\rightarrow e_j\\) implies that all the information at \\(e_i\\) is accessible at \\(e_j\\) - In the above example we can see that \\(e_1^1\\) has a complete path to \\(e_3^3\\) hence we can be certain that \\(e_1^1 \\rightarrow e_3^3\\) Concurrent events # - For any two events \\(e_i\\) and \\(e_j\\) , if there are no paths that connect directly to each other then these two are concurrent and is denoted as \\(e_i\\ ||\\ e_j\\) - Concurrency is a non transitive relation meaning if \\(e_i\\ ||\\ e_j\\) and \\(e_j\\ ||\\ e_k\\) we cannot say that \\(e_i\\ ||\\ e_k\\) - In the above example \\(e_2^4\\) and \\(e_3^1\\) are not connected at all hence, we can say that \\(e_2^4\\ ||\\ e_3^1\\) Tags: !DistributedComputingIndex","title":"Week 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#week-2","text":"Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 31/Jul/2021 NOTE THAT THIS PAGE HAS DIAGRAMS THAT ARE BEST VISIBLE IN LIGHT MODE","title":"Week 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#topics-covered","text":"Module 1 Multicomputer parallel systems NUMA (Non Uniform Memory Access) Model Wraparound mesh interconnection in an MPS Hypercube interconnection in an MPS Distributed/Parallel Computing Jargon Parallelism/Speedup Parallel/Distributed Program Concurrency Distributed Communication Models RPC (Remote Procedure Call) Publish/Subscribe Module 2 Preliminary understandings Notations Space time diagram What are these letters? Causal precedence/dependency or happens before relation Concurrent events","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#module-1","text":"","title":"Module 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#multicomputer-parallel-systems","text":"Processors do not have direct access to shared mem . Usually do not have a common clock . Processors are in close proximity . (THIS IS DIFFERENT FROM A DS) Very tightly coupled . (THIS IS DIFFERENT FROM A DS) Connected by an interconnection network. Communicate via Message passing APIs/common address space. (THIS IS DIFFERENT FROM A DS as DS can only use MP APIs). Typically this is used for high performance computing use cases.","title":"Multicomputer parallel systems"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#numa-non-uniform-memory-access-model","text":"- Above you can see that the individual mem components are not clubbed together like the UMA Model (See here Week1DC#UMA Uniform Memory Access Model ). - The processor can still access the mem components but have a different access latency - non-uniform memory access - Different processor can have different access latency - Multicomputer system having a common address space . - Latency to access various shared memory location from the different processors varies.","title":"NUMA (Non Uniform Memory Access) Model"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#wraparound-mesh-interconnection-in-an-mps","text":"- The above diagram shows a 2d wraparound mesh - The above diagram corresponds to a \\(4x4\\) mesh containing 16 nodes. - Each node is connected to each and every node around it. The leaf nodes wrap around to the opposite leaf node of their respective row or column, hence the name Wrap Around Configuration . - If any of the nodes go down, the wrap around connection helps in maintaining the connection. - The connection can be bidirectional through a bus or any interconnection logic for that matter.","title":"Wraparound mesh interconnection in an MPS"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#hypercube-interconnection-in-an-mps","text":"- A k dimensional hypercube has \\(2^k\\) processor and mem units (nodes) - Each node has at most \\(k\\) connections - Each dimension is associated with a bit position in the label - Labels of two adjacent nodes differ in the \\(k^{th}\\) bit position for the dimension k - From node \\(0000\\) we can see that each direction differs by a single bit. bottom is \\(0001\\) , right is \\(0010\\) and the adjacent one is \\(0100\\) - We can by applying the above rules get to know the label for the other adjacent nodes - The shortest path between any two processors is called Hamming distance - consider two bit labels \\(0110\\) and \\(1001\\) , the hamming distance would be 4 since all \\(4\\) bits differ. - consider two bit labels \\(0111\\) and \\(0110\\) , the hamming distance would be 1 since only \\(1\\) bit differs. - The above calculations can be used to connect the nodes according to the label - In the case of such an interconnection the \\(hamming\\ distance <= k\\) - Even if some of the nodes go down, there will be another path present to keep the connection alive. This provides fault tolerance and congestion control mechanism - Routing of messages happen hop by hop","title":"Hypercube interconnection in an MPS"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#distributedparallel-computing-jargon","text":"","title":"Distributed/Parallel Computing Jargon"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#parallelismspeedup","text":"\\[Speedup = \\frac{T(1)}{T(n)}\\] \\(T(1)\\) = Time taken on a single processor \\(T(n)\\) = Time taken with n processors Measure of the relative speedup of a specific program on a given machine This depends on: Number of processors Mapping of the code to the processors","title":"Parallelism/Speedup"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#paralleldistributed-program-concurrency","text":"\\[Parallel\\ Program\\ Concurrency = \\frac{number\\ of\\ local\\ operations}{total\\ number\\ of\\ operations}\\] \\(number\\ of\\ local\\ operations\\) -> Non communication and non shared memory access operations \\(total\\ number\\ of\\ operations\\) -> All operations including communication or shared memory access","title":"Parallel/Distributed Program Concurrency"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#distributed-communication-models","text":"","title":"Distributed Communication Models"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#rpc-remote-procedure-call","text":"This topic is covered in a pre reading session here: PreReadingWeek1DC#RPC Remote Procedure Call - The client procedure calls a client stub to pass params - The client marshals the params (makes a common representation of the params), builds the message, and calls the local OS - The local OS sends the message to the remote OS - The server's remote OS gives the message to a server stub - The server stub de-marshals the params(Converts common form to server OS specific form) and calls the desired server routine - The server computes the result and hands it to the server stub - The server stub marshals the result into a message and calls the local OS - The server OS sends the message to the client OS - The client OS receives the message and sends it to the client stub - The client stub demarshals the result, and execution returns to the client","title":"RPC (Remote Procedure Call)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#publishsubscribe","text":"- We have two entites mainly: - Publishers : Those who create information and publish them to a service (Through a Notify() call) - Subscriber : Those who consume the content published by publishers it had subscribed to. - The Subscriber gets data asynchronous though a notification, and they can continue their tasks until they receive notifications. - The subscriber has an option to unsubscribe as well","title":"Publish/Subscribe"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#module-2","text":"","title":"Module 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#preliminary-understanding","text":"DS consists of a set of processors. There is an intercommunication network. Delay in communication is finite but is not predictable. Processors do not share a common global memory. Uses asynch message passing. No common physical global clock. Possibility of messages being delivered out of order. Messages may be lost, garbled or duplicated due to timeouts and retransmissions. There is always a possibility of communication and processor failure.","title":"Preliminary understanding"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#notations","text":"\\(C_{ij}\\) : Channel from process \\(p_i\\) to process \\(p_j\\) \\(m_{ij}\\) : message sent by \\(p_i\\) to \\(p_j\\) Global state \\(GS\\) of a distributed computation consists of: States of the processes: Local memory state States of the communication channels: set of messages in transit Global state is explained in detail here PreReadingWeek1DC#Global state of a DS - Occurrences of events \\(e\\) - Causes changes in respective processes states - Causes changes in channels states - Causes transition in global system state","title":"Notations"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#space-time-diagram","text":"","title":"Space time diagram"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#what-are-these-letters","text":"\\(p_i\\) denotes the processes in the space axis \\(e_i^j\\) denotes the \\(j^{th}\\) event in process \\(p_i\\) Events that do not have arrows are The arrows denote the direction of the message sent. \\(e_1^2\\) is a message sending event \\(e_3^2\\) is a message receive event","title":"What are these letters?"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#causal-precedencedependency-or-happens-before-relation","text":"- Relation ' \\(\\rightarrow\\) ' denotes flow of information in a distributed computation - \\(e_i \\rightarrow e_j\\) implies that all the information at \\(e_i\\) is accessible at \\(e_j\\) - In the above example we can see that \\(e_1^1\\) has a complete path to \\(e_3^3\\) hence we can be certain that \\(e_1^1 \\rightarrow e_3^3\\)","title":"Causal precedence/dependency or happens before relation"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week2DC.html#concurrent-events","text":"- For any two events \\(e_i\\) and \\(e_j\\) , if there are no paths that connect directly to each other then these two are concurrent and is denoted as \\(e_i\\ ||\\ e_j\\) - Concurrency is a non transitive relation meaning if \\(e_i\\ ||\\ e_j\\) and \\(e_j\\ ||\\ e_k\\) we cannot say that \\(e_i\\ ||\\ e_k\\) - In the above example \\(e_2^4\\) and \\(e_3^1\\) are not connected at all hence, we can say that \\(e_2^4\\ ||\\ e_3^1\\) Tags: !DistributedComputingIndex","title":"Concurrent events"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html","text":"Week 3 # Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 07/Aug/2021 Topics Covered # Models of Communication Networks FIFO Model Non FIFO Model Causal Ordering Model Global State of a DS Consistent Global State Cuts of a DC Consistent vs inconsistent cut Logical Time Scalar Time Notations Rules for updating scalar clock Height of an event Vector Time Notations Rules for updating vector clock Event Counting Models of Communication Networks # FIFO Model # Each channel acts as a FIFO queue Since the messages are sent in a queue, ordering is preserved by the channel If \\(P_1\\) sends \\(m_1\\) , \\(m_2\\) to \\(P_2\\) then \\(P_2\\) receives those two messages as a queue in the same order Non FIFO Model # The channel acts as a set of messages Since it is a set, the messages do not necessarily have the order maintained Sender process adds messages to channel Receiver process removes messages from it This helps in relieving the communication network from the overhead of maintaining the message ordering Causal Ordering Model # This is based on the happens before relation. Such a system must satisfy: If there are two messages \\(m_{ij}\\) and \\(m_{kj}\\) , then if \\(Send(m_{ij}) \\rightarrow Send(m_{kj})\\) , then it must also follow \\(Rec(m_{ij}) \\rightarrow Rec(m_{kj})\\) Note that the messages are coming to the same process. Causally ordered messages implies FIFO message delivery \\(CO \\subset FIFO \\subset Non FIFO\\) Global State of a DS # More details here Week2DC#Notations . - \\(LS_i^x\\) : State of process \\(p_i\\) after the occurrence of event \\(e_i^x\\) and before \\(e_i^{x+1}\\) - \\(SC_{ij}\\) : State of channel \\(C_{ij}\\) Consistent Global State # A state is meaningful, meaning that every message that is recorded as received is also recorded as sent For all \\(m_{ij}\\) , \\(send(m_{ij}) \\notin LS_i^x\\) \\(\\implies\\) \\(m_{ij} /notin SC_{ij} rec(m_{ij}) \\notin LS_j^y\\) The above space time diagram is consistent, because when we see all the \\(LS\\) that define the \\(GS\\) all the sends are recorded before the receives of that message Consider a \\(GS\\) of \\(LS_1^3, LS_2^3, LS_3^4, LS_4^2\\) , here the \\(GS\\) is inconsistent, because the receive of message \\(m_{21}\\) is recorded but not the send. Cuts of a DC # - Any zig-zag line drawn that cuts all the processes in a space time diagram - The events in a DS is partitioned into: - Past: Contains all events left of the cut - Future: Contains all events right of the cut - A cut is a representation of the \\(GS\\) at those points in the cut and processes Consistent vs inconsistent cut # - Consistent cut : - Every message received in the PAST of the cut was sent in the PAST of that cut - All messages that cross the cut from the PAST to the FUTURE are in transit - The above image \\(C2\\) is an example since all the sends and receives happen in the PAST and the message between \\(e_2^4\\) to \\(e_1^3\\) is in transit. - Inconsistent cut : - If the receive is recorded in the PAST and the send is in the FUTURE then it is an inconsistent cut - In the above image \\(C1\\) is inconsistent since \\(send(e_1^2)\\) is in the FUTURE and \\(rec(e_2^2)\\) is in the past. Logical Time # To show a sense of time in the sense of Logical time follows Monotonicity property: if event \\(\\alpha\\) has happened before event \\(\\beta\\) then the timestamp of event \\(\\alpha\\) is less that the timestamp of event \\(\\beta\\) Every process has a LC LC is advanced using a set of rules each event is assigned as timestamp There are two ways to represent logical time: Scalar Time Vector Time Scalar Time # Notations # This is covered in the pre reading content here: PreReadingWeek1DC#Scalar Time Time domain is the set of non negative integers \\(C_i\\) : Integer variable, denotes the logical clock of \\(p_i\\) Rules for updating scalar clock # R1 : Before executing an event, process \\(p_i\\) executes \\(C_i = C_i + d\\ (d \\gt 0)\\) d can be any value but usually is 1 R2 : When process \\(p_i\\) receives a message with a timestamp \\(C_{msg}\\) , it executes the following actions: \\(C_i = mac(C_i, C_{msg})\\) execute R1 deliver the message Whenever there is an internal event the R1 is executed The above rules can be seen in action in the steps below: Height of an event # Height is defined as the number of events that causally precedes it If \\(d = 1\\) , the height of a given event is 1 minus the timestamp at that event. Vector Time # Notations # Time domain is represented by a set of n-dimensional non-negative integer vectors. (Can be a row or a column vector) \\(vt_i[i]\\) , \\(vtj[j]\\) Rules for updating vector clock # R1 : First take the element wise max of the vector received and the local vector R2 : Add 1 to the local clock index of the vector decided above The above rules can be seen in action in the steps below: Event Counting # - if \\(d\\) is always \\(1\\) and \\(vt_i[i]\\) is the \\(i^{th}\\) component of vector clock at process \\(p_i\\) - Then \\(vt_i[i]\\) = no. of events that have occurred at \\(p_i\\) until that instant - \\(vh[j]\\) = number of events executed by process \\(p_j\\) that causally precede \\(e\\) - \\(\\sum vh[j] - 1\\) : Total no. of events that causally precede \\(e\\) in the DC Tags: !DistributedComputingIndex","title":"Week 3"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#week-3","text":"Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 07/Aug/2021","title":"Week 3"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#topics-covered","text":"Models of Communication Networks FIFO Model Non FIFO Model Causal Ordering Model Global State of a DS Consistent Global State Cuts of a DC Consistent vs inconsistent cut Logical Time Scalar Time Notations Rules for updating scalar clock Height of an event Vector Time Notations Rules for updating vector clock Event Counting","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#models-of-communication-networks","text":"","title":"Models of Communication Networks"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#fifo-model","text":"Each channel acts as a FIFO queue Since the messages are sent in a queue, ordering is preserved by the channel If \\(P_1\\) sends \\(m_1\\) , \\(m_2\\) to \\(P_2\\) then \\(P_2\\) receives those two messages as a queue in the same order","title":"FIFO Model"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#non-fifo-model","text":"The channel acts as a set of messages Since it is a set, the messages do not necessarily have the order maintained Sender process adds messages to channel Receiver process removes messages from it This helps in relieving the communication network from the overhead of maintaining the message ordering","title":"Non FIFO Model"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#causal-ordering-model","text":"This is based on the happens before relation. Such a system must satisfy: If there are two messages \\(m_{ij}\\) and \\(m_{kj}\\) , then if \\(Send(m_{ij}) \\rightarrow Send(m_{kj})\\) , then it must also follow \\(Rec(m_{ij}) \\rightarrow Rec(m_{kj})\\) Note that the messages are coming to the same process. Causally ordered messages implies FIFO message delivery \\(CO \\subset FIFO \\subset Non FIFO\\)","title":"Causal Ordering Model"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#global-state-of-a-ds","text":"More details here Week2DC#Notations . - \\(LS_i^x\\) : State of process \\(p_i\\) after the occurrence of event \\(e_i^x\\) and before \\(e_i^{x+1}\\) - \\(SC_{ij}\\) : State of channel \\(C_{ij}\\)","title":"Global State of a DS"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#consistent-global-state","text":"A state is meaningful, meaning that every message that is recorded as received is also recorded as sent For all \\(m_{ij}\\) , \\(send(m_{ij}) \\notin LS_i^x\\) \\(\\implies\\) \\(m_{ij} /notin SC_{ij} rec(m_{ij}) \\notin LS_j^y\\) The above space time diagram is consistent, because when we see all the \\(LS\\) that define the \\(GS\\) all the sends are recorded before the receives of that message Consider a \\(GS\\) of \\(LS_1^3, LS_2^3, LS_3^4, LS_4^2\\) , here the \\(GS\\) is inconsistent, because the receive of message \\(m_{21}\\) is recorded but not the send.","title":"Consistent Global State"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#cuts-of-a-dc","text":"- Any zig-zag line drawn that cuts all the processes in a space time diagram - The events in a DS is partitioned into: - Past: Contains all events left of the cut - Future: Contains all events right of the cut - A cut is a representation of the \\(GS\\) at those points in the cut and processes","title":"Cuts of a DC"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#consistent-vs-inconsistent-cut","text":"- Consistent cut : - Every message received in the PAST of the cut was sent in the PAST of that cut - All messages that cross the cut from the PAST to the FUTURE are in transit - The above image \\(C2\\) is an example since all the sends and receives happen in the PAST and the message between \\(e_2^4\\) to \\(e_1^3\\) is in transit. - Inconsistent cut : - If the receive is recorded in the PAST and the send is in the FUTURE then it is an inconsistent cut - In the above image \\(C1\\) is inconsistent since \\(send(e_1^2)\\) is in the FUTURE and \\(rec(e_2^2)\\) is in the past.","title":"Consistent vs inconsistent cut"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#logical-time","text":"To show a sense of time in the sense of Logical time follows Monotonicity property: if event \\(\\alpha\\) has happened before event \\(\\beta\\) then the timestamp of event \\(\\alpha\\) is less that the timestamp of event \\(\\beta\\) Every process has a LC LC is advanced using a set of rules each event is assigned as timestamp There are two ways to represent logical time: Scalar Time Vector Time","title":"Logical Time"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#scalar-time","text":"","title":"Scalar Time"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#notations","text":"This is covered in the pre reading content here: PreReadingWeek1DC#Scalar Time Time domain is the set of non negative integers \\(C_i\\) : Integer variable, denotes the logical clock of \\(p_i\\)","title":"Notations"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#rules-for-updating-scalar-clock","text":"R1 : Before executing an event, process \\(p_i\\) executes \\(C_i = C_i + d\\ (d \\gt 0)\\) d can be any value but usually is 1 R2 : When process \\(p_i\\) receives a message with a timestamp \\(C_{msg}\\) , it executes the following actions: \\(C_i = mac(C_i, C_{msg})\\) execute R1 deliver the message Whenever there is an internal event the R1 is executed The above rules can be seen in action in the steps below:","title":"Rules for updating scalar clock"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#height-of-an-event","text":"Height is defined as the number of events that causally precedes it If \\(d = 1\\) , the height of a given event is 1 minus the timestamp at that event.","title":"Height of an event"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#vector-time","text":"","title":"Vector Time"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#notations_1","text":"Time domain is represented by a set of n-dimensional non-negative integer vectors. (Can be a row or a column vector) \\(vt_i[i]\\) , \\(vtj[j]\\)","title":"Notations"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#rules-for-updating-vector-clock","text":"R1 : First take the element wise max of the vector received and the local vector R2 : Add 1 to the local clock index of the vector decided above The above rules can be seen in action in the steps below:","title":"Rules for updating vector clock"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week3DC.html#event-counting","text":"- if \\(d\\) is always \\(1\\) and \\(vt_i[i]\\) is the \\(i^{th}\\) component of vector clock at process \\(p_i\\) - Then \\(vt_i[i]\\) = no. of events that have occurred at \\(p_i\\) until that instant - \\(vh[j]\\) = number of events executed by process \\(p_j\\) that causally precede \\(e\\) - \\(\\sum vh[j] - 1\\) : Total no. of events that causally precede \\(e\\) in the DC Tags: !DistributedComputingIndex","title":"Event Counting"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC.html","text":"Week 4 # Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 21/Aug/2021 Topics Covered # Singhal-Kshemakalyani's Differential Technique Fowler-Zwaenepoel's Direct-Dependency Technique Problems in recording global state Some Key Concepts of Consistency and Channel State Snapshot Recording Algorithms Chandy Lamport Algorithm (For FIFO) Lai and Yang algorithm (For NON-FIFO) Singhal-Kshemakalyani's Differential Technique # 1. The message contains a list of tuples that follows the given syntax: \\(\\{(index, val)\\}\\) , where \\(index =\\) Process that has the clock value of \\(= val\\) . 2. We see that a process sends only the details of the clocks that are changed on that given process only. 3. This method considerably saves the amount of data that is sent between processed in the initial timing Fowler-Zwaenepoel's Direct-Dependency Technique # 1. Here we send only the local clock value of the process to the receiver 2. Dependency to other process that is directly not connected by messages is lost. 3. Direct dependence relationship is preserved Problems in recording global state # Lack of a globally shared memory Lack of a global clock Message transmission is asynchronous message transfer delays are finite but unpredictable Some Key Concepts of Consistency and Channel State # Snapshot Recording Algorithms # Chandy Lamport Algorithm (For FIFO) # Process \\(p_i\\) records its state For each outgoing channel \\(C\\) on which a marker has not been sent, \\(p_j\\) sends a marker along \\(C\\) before \\(p_i\\) sends further messages along \\(C\\) On receiving a marker along channel \\(C\\) : if \\(p_j\\) has not recorded its state then Record the state of \\(C\\) as empty set Execute the \"marker sending rule\" else Record the state of \\(C\\) as the set of messages received along \\(C\\) after \\(p_j\\) state was recorded and before \\(p_j\\) received the marker along \\(C\\) The vertical dashed lines are the amount of moneyt present between users A and B. The arrow shows a transaction between A and B Let \\(S1\\) sends a marker to \\(S2\\) through \\(C_{12}\\) , so \\(S1\\) => saves 450 as the local state \\(S2\\) => Since it has not saved its local state, it will record the value of \\(C_{12}\\) as empty and save the local state as 1030 After it has recorded \\(S2\\) , Since S1 has already set its local state, it will store the After \\(S1\\) has recorded its local state Lai and Yang algorithm (For NON-FIFO) # Since markers cannot be used in NON FIFO channels we use piggybacking, so that messages sent after and before the marker are distinguished. In Lai and Yang we use coloring scheme to do the piggy backing every process is initially white process turns red while taking a snapshot equivalent of the \"marker sending rule\" is executed when a process turns red Every message sent by a white process is colored white A white message is a message that was send before the sender of that message recorded its local snapshot Every message sent by a red process is colored white A white message is a message that was send before the sender of that message recorded its local snapshot \\(LS = 750\\) All subsequent messages are red messages \\(P2\\) turns red when 10 is received, \\(P2\\) will record the \\(LS\\) as 190 \\[C_{12} = white_message(20) + white_message(30) - white_message(20) = 30\\] \\[C_{21} = white_message(30) - 0 = 30\\] Tags: !DistributedComputingIndex","title":"Week 4"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC.html#week-4","text":"Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 21/Aug/2021","title":"Week 4"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC.html#topics-covered","text":"Singhal-Kshemakalyani's Differential Technique Fowler-Zwaenepoel's Direct-Dependency Technique Problems in recording global state Some Key Concepts of Consistency and Channel State Snapshot Recording Algorithms Chandy Lamport Algorithm (For FIFO) Lai and Yang algorithm (For NON-FIFO)","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC.html#singhal-kshemakalyanis-differential-technique","text":"1. The message contains a list of tuples that follows the given syntax: \\(\\{(index, val)\\}\\) , where \\(index =\\) Process that has the clock value of \\(= val\\) . 2. We see that a process sends only the details of the clocks that are changed on that given process only. 3. This method considerably saves the amount of data that is sent between processed in the initial timing","title":"Singhal-Kshemakalyani's Differential Technique"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC.html#fowler-zwaenepoels-direct-dependency-technique","text":"1. Here we send only the local clock value of the process to the receiver 2. Dependency to other process that is directly not connected by messages is lost. 3. Direct dependence relationship is preserved","title":"Fowler-Zwaenepoel's Direct-Dependency Technique"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC.html#problems-in-recording-global-state","text":"Lack of a globally shared memory Lack of a global clock Message transmission is asynchronous message transfer delays are finite but unpredictable","title":"Problems in recording global state"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC.html#some-key-concepts-of-consistency-and-channel-state","text":"","title":"Some Key Concepts of Consistency and Channel State"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC.html#snapshot-recording-algorithms","text":"","title":"Snapshot Recording Algorithms"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC.html#chandy-lamport-algorithm-for-fifo","text":"Process \\(p_i\\) records its state For each outgoing channel \\(C\\) on which a marker has not been sent, \\(p_j\\) sends a marker along \\(C\\) before \\(p_i\\) sends further messages along \\(C\\) On receiving a marker along channel \\(C\\) : if \\(p_j\\) has not recorded its state then Record the state of \\(C\\) as empty set Execute the \"marker sending rule\" else Record the state of \\(C\\) as the set of messages received along \\(C\\) after \\(p_j\\) state was recorded and before \\(p_j\\) received the marker along \\(C\\) The vertical dashed lines are the amount of moneyt present between users A and B. The arrow shows a transaction between A and B Let \\(S1\\) sends a marker to \\(S2\\) through \\(C_{12}\\) , so \\(S1\\) => saves 450 as the local state \\(S2\\) => Since it has not saved its local state, it will record the value of \\(C_{12}\\) as empty and save the local state as 1030 After it has recorded \\(S2\\) , Since S1 has already set its local state, it will store the After \\(S1\\) has recorded its local state","title":"Chandy Lamport Algorithm (For FIFO)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC.html#lai-and-yang-algorithm-for-non-fifo","text":"Since markers cannot be used in NON FIFO channels we use piggybacking, so that messages sent after and before the marker are distinguished. In Lai and Yang we use coloring scheme to do the piggy backing every process is initially white process turns red while taking a snapshot equivalent of the \"marker sending rule\" is executed when a process turns red Every message sent by a white process is colored white A white message is a message that was send before the sender of that message recorded its local snapshot Every message sent by a red process is colored white A white message is a message that was send before the sender of that message recorded its local snapshot \\(LS = 750\\) All subsequent messages are red messages \\(P2\\) turns red when 10 is received, \\(P2\\) will record the \\(LS\\) as 190 \\[C_{12} = white_message(20) + white_message(30) - white_message(20) = 30\\] \\[C_{21} = white_message(30) - 0 = 30\\] Tags: !DistributedComputingIndex","title":"Lai and Yang algorithm (For NON-FIFO)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html","text":"Week 4 (cont.) # Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 22/Aug/2021 Topics Covered # Terminology and Basic Algorithms Notations and Definitions Synchronous Single-Initiator Spanning Tree Algorithm using Flooding Algorithm Design Struct for each process \\(P_i\\) Algorithm pseudo code Algorithm in action Broadcast and Convergecast Algorithm on a Tree Broadcast Algorithm Convergecast Algorithm Complexity Message Ordering Terminology and Basic Algorithms # Notations and Definitions # Undirected unweighted graph \\(G = (M, L)\\) , represents topology of an example graph such as the one shown below: Vertices are nodes Edges are channels \\(n = |N|\\) , Cardinality of set of all nodes \\(N = [A, B, C, D, E, F]\\) \\(l = |L|\\) , Cardinality of set of all edges \\(L = [AB, BC, CF, DE, EF, AD, AE, CE]\\) diameter of a graph : minimum number of edges that need to be traversed to go from any node to any other node \\(Diameter = max_{i, j \\in N}\\) , Length of the shortest path between i and j where j belongs to the set N. We basically find all the minimum distances from i to all j and the diameter is the maximum value In the above example let \\(i = A\\) and \\(j = [A, B, C, D, E, F]\\) then we can say that the max value of the lengths is 2 (In case of the path length for A to F), so the \\(diameter = 2\\) A spanning tree is a tree where the graph does not have any edges that will cause cycles in it. An example for a spanning tree for the above example is shown below: As a rule of thumb, a spanning tree for a graph with \\(n\\) nodes, will have \\(n - 1\\) edges So in the example graph has 6 nodes and the number of edges in the spanning tree is 5. Synchronous Single-Initiator Spanning Tree Algorithm using Flooding # Algorithm executes steps synchronously (When a message is sent, the sender waits till all the other nodes receives the messages) Root of the graph initiates the algorithm (An arbitrary node can be selected as the root) QUERY messages are flooded . This means that first the root node will send a message to all its nearby nodes, and inturn those nodes will send it to its neighbors and so on. The final spanning tree will have the root node as the initial arbitrary node selected in the graph. Each process \\(P_i (P_i \\ne root)\\) should output its own parent for the spanning tree. In distributed computing we interchangeably use nodes and processes Algorithm Design # Struct for each process \\(P_i\\) # Variables maintained at each \\(P_i\\) Initial variable values at each \\(P_i\\) int visited 0 int depth 0 int parent NULL set of int Neighbors set of neighbors Algorithm pseudo code # Algorithm for Pi When Round r = 1 if Pi = root then visited = 1 depth = 0 send QUERY to Neighbors if Pi receives a QUERY message then visited = 1 depth = r parent = root plan to send QUERY to Neighbors at the next round When Round r > 1 and r < = diameter if Pi planned to send in previous round then Pi sends QUERY to Neighbors if Pi receives QUERY messages then visited = 1 depth = r parent = any randomly selected nodes from which Query was receives plan to send QUERY to Neighbors but not to any nodes from which send was received Algorithm in action # Round 1 : Root \\(A\\) sends \\(QUERY\\) to neighbors \\([B, F]\\) \\(B\\) and \\(F\\) set \\(A\\) as parent and plans to send \\(QUERY\\) to its neighbors Round 2 : \\(B\\) sends \\(QUERY\\) to neighbors \\([C, E]\\) and \\(F\\) sends \\(QUERY\\) to neighbors \\([E]\\) \\(E\\) randomly chooses \\(F\\) as parent and \\(C\\) chooses \\(B\\) as parent and both \\(E\\) and \\(F\\) plans to send \\(QUERY\\) to its neighbors Round 3 : \\(E\\) sends \\(QUERY\\) to neighbors \\([C, D]\\) and \\(C\\) sends \\(QUERY\\) to neighbors \\([E, D]\\) Since \\(C\\) and \\(E\\) are already visited, the \\(QUERY\\) is ignored in those cases and \\(D\\) randomly chooses \\(C\\) as parent over \\(E\\) The spanning tree generated is as follows : The above spanning tree has 6 nodes and 5 edges Broadcast and Convergecast Algorithm on a Tree # A spanning tree is useful for distributing (via Broadcast ) and collecting information (via Convergecast ) to and from all the nodes Broadcast Algorithm # - BC1: - The root sends the information to be sent to all its children - BC2: - When a non root node receives information from its parent, it copies it and forwards it to its children Convergecast Algorithm # - CVC1: - Leaf node sends what it needs to report to its parent - CVC2: - At a non leaf node that is not root, a report is received from all the child nodes, the collective report is sent to its parent - CVC3: - When a root node receives information from its child nodes, the global function is evaluated using the reports Complexity # Each broadcast and each convergecast requires \\(n - 1\\) messages. Each broadcast and each convergecast requires time equal to the maximum height \\(h\\) of the tree which is \\(\\mathcal{O}(n)\\) Message Ordering # Group Communication # Broadcast - Sending a message to all members in the distributed system Multicasting - A message is sent to a certain subset, identified as a group, of the processes in the system. Unicasting - Point-to-point message communication Causal Order # Causal Order is explained here: Week3DC#Causal Ordering Model 2 criteria must be satisfied by causal ordering protocol Safety: A message M arriving at a process may need to be buffered until all system wide messages sent in the causal past of the send(M) event to the same destination have already arrived Distinction is made between: Arrival of messages at a process Event at which the message is given to the application process Liveness: A message that arrives at a process must be eventually be delivered to the process Raynal-Schiper-Toueg Algorithm # Each message M should carry a log of All other messages Send causally before M's send event, and sent to the same destination dest(M) Log can be examined to ensure when it is safe to deliver a message Channels are assumed to be FIFO Local Variables # array of int \\(SENT[1 .... n, 1 .... n]\\) (n x n array) Where \\(SENT_i[j, k]\\) = no. of messages sent by \\(P_j\\) to \\(P_k\\) as known to \\(P_i\\) array of int \\(DELIV[1 .... n]\\) Where \\(DELIV_i[j]\\) = no. of messages from \\(P_j\\) that have been delivered to \\(P_i\\) The Algorithm # Message Send Event , where \\(P_i\\) wants to send message \\(M\\) to \\(P_j\\) : \\(send(M, SENT)\\) to \\(P_j\\) (Here \\(SENT\\) array is the log which will be used to determine if the message needs to be buffered or not) \\(SENT[i, j] = SENT[i, j] + 1\\) Message Arrival Event , when \\((M, SENT_j)\\) arrives at \\(P_i\\) from \\(P_j\\) : deliver \\(M\\) to \\(P_i\\) when for each process \\(x\\) , \\(DELIV_i[x] \\ge SENT_j[x, i]\\) \\(\\forall x, y, SENT_i[x, y] = max(SENT_i[x, y], SENT_j[x, y])\\) \\(DELIV_i[j] = DELIV_i[j] + 1\\) Algorithm Complexity # Space complexity at each process: \\(\\mathcal{O}(n^2)\\) integers Space overhead per message: \\(n^2\\) integers Time complexity at each process for each send and deliver event: \\(\\mathcal{O}(n^2)\\) Algorithm in action # Assume following steps have occurred till now - \\(P_1\\) sent 3 messages to \\(P_2\\) - \\(P_1\\) sent 4 messages to \\(P_3\\) - \\(P_2\\) sent 5 messages to \\(P_1\\) - \\(P_2\\) sent 2 messages to \\(P_3\\) - \\(P_3\\) sent 4 messages to \\(P_2\\) Variable state Assuming \\(SENT\\) of all \\(P\\) is aware of all the other values of \\(SENT\\) , \\(SENT\\) of \\(P_1\\) : | 0 | 3 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | Assume the following values for \\(DELIV\\) arrays \\(DELIV_1 = [0, 4, 0]\\) \\(DELIV_2 = [3, 0, 4]\\) \\(DELIV_3 = [3, 2, 0]\\) MESSAGE EVENTS: Now if, \\(P_1\\) sends \\(m_1\\) to \\(P_2\\) 1. \\(SEND\\) event from \\(P_1\\) 1. \\(SENT_1\\) | 0 | 3 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | 2. Send \\((m_1, SENT_1)\\) 3. Updated \\(SENT_1\\) | 0 | 3+1 | 4 | | 0 | 4 | 4 | | 5 | 0 | 2 | => | 5 | 0 | 2 | | 0 | 4 | 0 | | 0 | 4 | 0 | 2. \\(RECEIVE\\) \\(m_1\\) from \\(P_1\\) at \\(P_2\\) 1. \\(DELIV_2[1] \\ge SENT_1[1, 2]\\) 2. \\(DELIV_2[3] \\ge SENT_1[3, 2]\\) 3. Deliver \\(m_1\\) to \\(P_2\\) 4. \\(DELIV_2[1] = DELIV_2[1] + 1 = 4\\) 5. \\(DELIV_2 = [4, 0, 4]\\) 6. \\(SENT_2\\) | 0 | 3 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | Now if, \\(P_3\\) sends \\(m_2\\) to \\(P_2\\) 1. \\(SEND\\) event from \\(P_3\\) 1. \\(SENT_3\\) | 0 | 3 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | 2. Send \\((m_2, SENT_3)\\) 3. Updated \\(SENT_3\\) | 0 | 3 | 4 | | 0 | 3 | 4 | | 5 | 0 | 2 | => | 5 | 0 | 2 | | 0 | 4+1 | 0 | | 0 | 5 | 0 | 2. \\(RECEIVE\\) \\(m_2\\) from \\(P_3\\) at \\(P_2\\) 1. \\(DELIV_2[1] \\ge SENT_3[1, 2]\\) 2. \\(DELIV_2[3] \\ge SENT_3[3, 2]\\) 3. Deliver \\(m_2\\) to \\(P_2\\) 4. \\(DELIV_2[3] = DELIV_2[3] + 1 = 5\\) 5. \\(DELIV_2 = [4, 0, 5]\\) 6. \\(SENT_2\\) | 0 | 3 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | Now if, \\(P_1\\) sends \\(m_3\\) to \\(P_3\\) 1. \\(SEND\\) event from \\(P_1\\) 1. \\(SENT_1\\) | 0 | 4 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | 2. Send \\((m_2, SENT_3)\\) 3. Updated \\(SENT_3\\) | 0 | 4 | 4+1 | | 0 | 4 | 5 | | 5 | 0 | 2 | => | 5 | 0 | 2 | | 0 | 4 | 0 | | 0 | 5 | 0 | 2. \\(RECEIVE\\) \\(m_3\\) from \\(P_1\\) at \\(P_3\\) 1. \\(DELIV_3[1] \\ge SENT_1[1, 3]\\) (FALSE) 2. \\(DELIV_3[2] \\ge SENT_1[2, 3]\\) (TRUE) 3. Put \\(m_3\\) in buffer since the first condition failed, only process it after the other \\(P_1\\) messages are delivered to \\(P_3\\) Tags: !DistributedComputingIndex","title":"Week 4 (cont.)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#week-4-cont","text":"Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 22/Aug/2021","title":"Week 4 (cont.)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#topics-covered","text":"Terminology and Basic Algorithms Notations and Definitions Synchronous Single-Initiator Spanning Tree Algorithm using Flooding Algorithm Design Struct for each process \\(P_i\\) Algorithm pseudo code Algorithm in action Broadcast and Convergecast Algorithm on a Tree Broadcast Algorithm Convergecast Algorithm Complexity Message Ordering","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#terminology-and-basic-algorithms","text":"","title":"Terminology and Basic Algorithms"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#notations-and-definitions","text":"Undirected unweighted graph \\(G = (M, L)\\) , represents topology of an example graph such as the one shown below: Vertices are nodes Edges are channels \\(n = |N|\\) , Cardinality of set of all nodes \\(N = [A, B, C, D, E, F]\\) \\(l = |L|\\) , Cardinality of set of all edges \\(L = [AB, BC, CF, DE, EF, AD, AE, CE]\\) diameter of a graph : minimum number of edges that need to be traversed to go from any node to any other node \\(Diameter = max_{i, j \\in N}\\) , Length of the shortest path between i and j where j belongs to the set N. We basically find all the minimum distances from i to all j and the diameter is the maximum value In the above example let \\(i = A\\) and \\(j = [A, B, C, D, E, F]\\) then we can say that the max value of the lengths is 2 (In case of the path length for A to F), so the \\(diameter = 2\\) A spanning tree is a tree where the graph does not have any edges that will cause cycles in it. An example for a spanning tree for the above example is shown below: As a rule of thumb, a spanning tree for a graph with \\(n\\) nodes, will have \\(n - 1\\) edges So in the example graph has 6 nodes and the number of edges in the spanning tree is 5.","title":"Notations and Definitions"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#synchronous-single-initiator-spanning-tree-algorithm-using-flooding","text":"Algorithm executes steps synchronously (When a message is sent, the sender waits till all the other nodes receives the messages) Root of the graph initiates the algorithm (An arbitrary node can be selected as the root) QUERY messages are flooded . This means that first the root node will send a message to all its nearby nodes, and inturn those nodes will send it to its neighbors and so on. The final spanning tree will have the root node as the initial arbitrary node selected in the graph. Each process \\(P_i (P_i \\ne root)\\) should output its own parent for the spanning tree. In distributed computing we interchangeably use nodes and processes","title":"Synchronous Single-Initiator Spanning Tree Algorithm using Flooding"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#algorithm-design","text":"","title":"Algorithm Design"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#struct-for-each-process-p_i","text":"Variables maintained at each \\(P_i\\) Initial variable values at each \\(P_i\\) int visited 0 int depth 0 int parent NULL set of int Neighbors set of neighbors","title":"Struct for each process \\(P_i\\)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#algorithm-pseudo-code","text":"Algorithm for Pi When Round r = 1 if Pi = root then visited = 1 depth = 0 send QUERY to Neighbors if Pi receives a QUERY message then visited = 1 depth = r parent = root plan to send QUERY to Neighbors at the next round When Round r > 1 and r < = diameter if Pi planned to send in previous round then Pi sends QUERY to Neighbors if Pi receives QUERY messages then visited = 1 depth = r parent = any randomly selected nodes from which Query was receives plan to send QUERY to Neighbors but not to any nodes from which send was received","title":"Algorithm pseudo code"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#algorithm-in-action","text":"Round 1 : Root \\(A\\) sends \\(QUERY\\) to neighbors \\([B, F]\\) \\(B\\) and \\(F\\) set \\(A\\) as parent and plans to send \\(QUERY\\) to its neighbors Round 2 : \\(B\\) sends \\(QUERY\\) to neighbors \\([C, E]\\) and \\(F\\) sends \\(QUERY\\) to neighbors \\([E]\\) \\(E\\) randomly chooses \\(F\\) as parent and \\(C\\) chooses \\(B\\) as parent and both \\(E\\) and \\(F\\) plans to send \\(QUERY\\) to its neighbors Round 3 : \\(E\\) sends \\(QUERY\\) to neighbors \\([C, D]\\) and \\(C\\) sends \\(QUERY\\) to neighbors \\([E, D]\\) Since \\(C\\) and \\(E\\) are already visited, the \\(QUERY\\) is ignored in those cases and \\(D\\) randomly chooses \\(C\\) as parent over \\(E\\) The spanning tree generated is as follows : The above spanning tree has 6 nodes and 5 edges","title":"Algorithm in action"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#broadcast-and-convergecast-algorithm-on-a-tree","text":"A spanning tree is useful for distributing (via Broadcast ) and collecting information (via Convergecast ) to and from all the nodes","title":"Broadcast and Convergecast Algorithm on a Tree"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#broadcast-algorithm","text":"- BC1: - The root sends the information to be sent to all its children - BC2: - When a non root node receives information from its parent, it copies it and forwards it to its children","title":"Broadcast Algorithm"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#convergecast-algorithm","text":"- CVC1: - Leaf node sends what it needs to report to its parent - CVC2: - At a non leaf node that is not root, a report is received from all the child nodes, the collective report is sent to its parent - CVC3: - When a root node receives information from its child nodes, the global function is evaluated using the reports","title":"Convergecast Algorithm"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#complexity","text":"Each broadcast and each convergecast requires \\(n - 1\\) messages. Each broadcast and each convergecast requires time equal to the maximum height \\(h\\) of the tree which is \\(\\mathcal{O}(n)\\)","title":"Complexity"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#message-ordering","text":"","title":"Message Ordering"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#group-communication","text":"Broadcast - Sending a message to all members in the distributed system Multicasting - A message is sent to a certain subset, identified as a group, of the processes in the system. Unicasting - Point-to-point message communication","title":"Group Communication"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#causal-order","text":"Causal Order is explained here: Week3DC#Causal Ordering Model 2 criteria must be satisfied by causal ordering protocol Safety: A message M arriving at a process may need to be buffered until all system wide messages sent in the causal past of the send(M) event to the same destination have already arrived Distinction is made between: Arrival of messages at a process Event at which the message is given to the application process Liveness: A message that arrives at a process must be eventually be delivered to the process","title":"Causal Order"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#raynal-schiper-toueg-algorithm","text":"Each message M should carry a log of All other messages Send causally before M's send event, and sent to the same destination dest(M) Log can be examined to ensure when it is safe to deliver a message Channels are assumed to be FIFO","title":"Raynal-Schiper-Toueg Algorithm"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#local-variables","text":"array of int \\(SENT[1 .... n, 1 .... n]\\) (n x n array) Where \\(SENT_i[j, k]\\) = no. of messages sent by \\(P_j\\) to \\(P_k\\) as known to \\(P_i\\) array of int \\(DELIV[1 .... n]\\) Where \\(DELIV_i[j]\\) = no. of messages from \\(P_j\\) that have been delivered to \\(P_i\\)","title":"Local Variables"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#the-algorithm","text":"Message Send Event , where \\(P_i\\) wants to send message \\(M\\) to \\(P_j\\) : \\(send(M, SENT)\\) to \\(P_j\\) (Here \\(SENT\\) array is the log which will be used to determine if the message needs to be buffered or not) \\(SENT[i, j] = SENT[i, j] + 1\\) Message Arrival Event , when \\((M, SENT_j)\\) arrives at \\(P_i\\) from \\(P_j\\) : deliver \\(M\\) to \\(P_i\\) when for each process \\(x\\) , \\(DELIV_i[x] \\ge SENT_j[x, i]\\) \\(\\forall x, y, SENT_i[x, y] = max(SENT_i[x, y], SENT_j[x, y])\\) \\(DELIV_i[j] = DELIV_i[j] + 1\\)","title":"The Algorithm"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#algorithm-complexity","text":"Space complexity at each process: \\(\\mathcal{O}(n^2)\\) integers Space overhead per message: \\(n^2\\) integers Time complexity at each process for each send and deliver event: \\(\\mathcal{O}(n^2)\\)","title":"Algorithm Complexity"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week4DC2.html#algorithm-in-action_1","text":"Assume following steps have occurred till now - \\(P_1\\) sent 3 messages to \\(P_2\\) - \\(P_1\\) sent 4 messages to \\(P_3\\) - \\(P_2\\) sent 5 messages to \\(P_1\\) - \\(P_2\\) sent 2 messages to \\(P_3\\) - \\(P_3\\) sent 4 messages to \\(P_2\\) Variable state Assuming \\(SENT\\) of all \\(P\\) is aware of all the other values of \\(SENT\\) , \\(SENT\\) of \\(P_1\\) : | 0 | 3 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | Assume the following values for \\(DELIV\\) arrays \\(DELIV_1 = [0, 4, 0]\\) \\(DELIV_2 = [3, 0, 4]\\) \\(DELIV_3 = [3, 2, 0]\\) MESSAGE EVENTS: Now if, \\(P_1\\) sends \\(m_1\\) to \\(P_2\\) 1. \\(SEND\\) event from \\(P_1\\) 1. \\(SENT_1\\) | 0 | 3 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | 2. Send \\((m_1, SENT_1)\\) 3. Updated \\(SENT_1\\) | 0 | 3+1 | 4 | | 0 | 4 | 4 | | 5 | 0 | 2 | => | 5 | 0 | 2 | | 0 | 4 | 0 | | 0 | 4 | 0 | 2. \\(RECEIVE\\) \\(m_1\\) from \\(P_1\\) at \\(P_2\\) 1. \\(DELIV_2[1] \\ge SENT_1[1, 2]\\) 2. \\(DELIV_2[3] \\ge SENT_1[3, 2]\\) 3. Deliver \\(m_1\\) to \\(P_2\\) 4. \\(DELIV_2[1] = DELIV_2[1] + 1 = 4\\) 5. \\(DELIV_2 = [4, 0, 4]\\) 6. \\(SENT_2\\) | 0 | 3 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | Now if, \\(P_3\\) sends \\(m_2\\) to \\(P_2\\) 1. \\(SEND\\) event from \\(P_3\\) 1. \\(SENT_3\\) | 0 | 3 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | 2. Send \\((m_2, SENT_3)\\) 3. Updated \\(SENT_3\\) | 0 | 3 | 4 | | 0 | 3 | 4 | | 5 | 0 | 2 | => | 5 | 0 | 2 | | 0 | 4+1 | 0 | | 0 | 5 | 0 | 2. \\(RECEIVE\\) \\(m_2\\) from \\(P_3\\) at \\(P_2\\) 1. \\(DELIV_2[1] \\ge SENT_3[1, 2]\\) 2. \\(DELIV_2[3] \\ge SENT_3[3, 2]\\) 3. Deliver \\(m_2\\) to \\(P_2\\) 4. \\(DELIV_2[3] = DELIV_2[3] + 1 = 5\\) 5. \\(DELIV_2 = [4, 0, 5]\\) 6. \\(SENT_2\\) | 0 | 3 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | Now if, \\(P_1\\) sends \\(m_3\\) to \\(P_3\\) 1. \\(SEND\\) event from \\(P_1\\) 1. \\(SENT_1\\) | 0 | 4 | 4 | | 5 | 0 | 2 | | 0 | 4 | 0 | 2. Send \\((m_2, SENT_3)\\) 3. Updated \\(SENT_3\\) | 0 | 4 | 4+1 | | 0 | 4 | 5 | | 5 | 0 | 2 | => | 5 | 0 | 2 | | 0 | 4 | 0 | | 0 | 5 | 0 | 2. \\(RECEIVE\\) \\(m_3\\) from \\(P_1\\) at \\(P_3\\) 1. \\(DELIV_3[1] \\ge SENT_1[1, 3]\\) (FALSE) 2. \\(DELIV_3[2] \\ge SENT_1[2, 3]\\) (TRUE) 3. Put \\(m_3\\) in buffer since the first condition failed, only process it after the other \\(P_1\\) messages are delivered to \\(P_3\\) Tags: !DistributedComputingIndex","title":"Algorithm in action"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html","text":"Week 5 # Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 28/Aug/2021 Topics Covered # Message Ordering (cont.) Birman-Schiper-Stephenson Protocol \\(P_i\\) sends a message \\(m\\) to \\(P_j\\) \\(P_j\\) receives a message \\(m\\) to \\(P_i\\) Distributed Mutual Exclusion Types of Approaches Quorum Based Requirements of Mutual Exclusion Algorithms Performance Metrics Lamport's Algorithm Requesting the Critical Section Executing the Critical Section Releasing the Critical Section Example Problem Message Ordering (cont.) # Birman-Schiper-Stephenson Protocol # \\(C_i\\) = Vector clock of \\(P_i\\) \\(C_i[j]\\) = \\(j^{th}\\) element of \\(C_i\\) \\(tm\\) = Vector timestamp for message \\(m\\) , stamped after local clock is incremented. NOTE , we also assume that all messages taking part in this algorithm is a broadcast \\(P_i\\) sends a message \\(m\\) to \\(P_j\\) # \\(P_i\\) increments \\(C_i[i]\\) \\(P_i\\) sets the timestamp \\(tm = C_i\\) for message \\(m\\) \\(P_j\\) receives a message \\(m\\) to \\(P_i\\) # When \\(P_j (j \\ne i)\\) reveives \\(m\\) with timestamp \\(tm\\) , it delays message delivery until: \\(C_j[i] = tm[i] - 1\\) , \\(P_j\\) has received all preceding messages sent by \\(P_i\\) \\(\\forall k \\le n\\) and \\(k \\ne i\\) , \\(C_j[k] \\ge tm[k]\\) , P_j has received all the messages that were received at \\(P_i\\) from other processes before \\(P_i\\) sent \\(m\\) Here we need to check if \\(P_j\\) also received \\(P_k\\) message before message from \\(P_i\\) is processed When \\(m\\) is delivered to \\(P_j\\) , update \\(P_j\\) 's vector clock, \\(\\forall i, C_j[i] = max(C_j[i], tm[i])\\) Check buffered messages to see if any can be delivered Example Problem # \\(P_3\\) executes a broadcast - \\(C_3 = [0, 0, 1]\\) - \\(tm_1 = [0, 0, 1]\\) \\(P_2\\) receives message \\(m_1\\) - \\(C_2 = [0, 0, 0]\\) - Condition checks: 1. \\(C_2[3] = tm_1[3] - 1\\) is TRUE 2. \\(C_2[i] \\ge tm_1[i]\\) \\(\\forall i \\le n\\) and \\(i \\ne 3\\) is TRUE - \\(C_2[i] = max(C_2[i], tm_1[i]), \\forall i\\) - \\(C_2 = [0, 0, 1]\\) \\(P_2\\) sends message \\(m_2\\) - \\(C_2 = [0, 1, 1]\\) - \\(tm_2 = [0, 1, 1]\\) \\(P_3\\) receives message \\(m_2\\) - \\(C_3 = [0, 0, 1]\\) - Condition checks: 1. \\(C_3[2] = tm_2[2] - 1\\) is TRUE 2. \\(C_3[i] \\ge tm_2[i]\\) \\(\\forall i \\le n\\) and \\(i \\ne 2\\) is TRUE - \\(C_3[i] = max(C_3[i], tm_2[i]), \\forall i\\) - \\(C_3 = [0, 1, 1]\\) \\(P_1\\) receives message \\(m_2\\) - \\(C_1 = [0, 0, 0]\\) - Condition checks: 1. \\(C_1[2] = tm_2[2] - 1\\) is TRUE 2. \\(C_1[i] \\ge tm_2[i]\\) \\(\\forall i \\le n\\) and \\(i \\ne 2\\) is FALSE - \\(m_2\\) is added to BUFFER \\(P_1\\) receives message \\(m_1\\) - \\(C_1 = [0, 0, 0]\\) - Condition checks: 1. \\(C_1[3] = tm_1[3] - 1\\) is TRUE 2. \\(C_1[i] \\ge tm_1[i]\\) \\(\\forall i \\le n\\) and \\(i \\ne 3\\) is TRUE - \\(C_1[i] = max(C_1[i], tm_1[i]), \\forall i\\) - \\(C_1 = [0, 0, 1]\\) Deliver \\(m_2\\) from BUFFER to \\(P_1\\) - \\(C_1 = [0, 0, 1]\\) - Condition checks: 1. \\(C_1[2] = tm_2[2] - 1\\) is TRUE 2. \\(C_1[i] \\ge tm_2[i]\\) \\(\\forall i \\le n\\) and \\(i \\ne 2\\) is TRUE - \\(C_1[i] = max(C_1[i], tm_1[i]), \\forall i\\) - \\(C_1 = [0, 1, 1]\\) NOTE , in the exam make sure that all the above steps are also written in the paper, annotating the diagram alone will lead to getting partial marks Distributed Mutual Exclusion # Types of Approaches # Token based Assertion based From Recorded Lecture Quorum based Quorum Based # Each site requests permission to execute the CS from a subset of sites called quorum Quorums are formed in such a way that when two sites concurrently request access to the CS At least one site receives both the requests This site is responsible to make sure that only one request executes the CS at any time Requirements of Mutual Exclusion Algorithms # Safety Property: At any instant, only one process can execute the CS Liveness Property: A site must not wait indefinitely to execute the CS while other sites are repeatedly executing the CS Fairness: Each process gets a fair chance to execute the CS CS execution requests are executed in order of their arrival time Time is determined by a logical clock Performance Metrics # From Recorded lectures Lamport's Algorithm # Every site \\(S_i\\) keeps a queue, \\(request\\_queue_i\\) \\(request\\_queue_i\\) contains mutual exclusion requests ordered by their timestamps FIFO \\(CS\\) requests are executed in increasing order of timestamps Requesting the Critical Section # When a site \\(S_i\\) wants to enter the CS, it broadcasts a \\(REQUEST(ts_i, i)\\) message to all other sites and places the request on \\(request\\_queue_i\\) . When site \\(S_j\\) receives the \\(REQUEST(ts_i, i)\\) message from site \\(S_i\\) , it places site \\(S_j\\) 's request on \\(request\\_queue_j\\) and returns a timestamped REPLY message to \\(S_i\\) Executing the Critical Section # Site \\(S_i\\) enters the CS when the following conditions hold: - L1: \\(S_i\\) has received a message with timestamp larger than \\((ts_i, i)\\) - L2: \\(S_i\\) 's request is at the top of \\(request\\_queue_i\\) Releasing the Critical Section # Site \\(S_i\\) , upon exiting the CS, removes its request from the top of its request queue and broadcasts a timestamped RELEASE message to all other sites When a site \\(S_j\\) receives a RELEASE message from site \\(S_i\\) , it removes \\(S_i\\) 's request from its request queue Example Problem # \\(S_1\\) and \\(S_2\\) are requesting for the CS at \\(S_2\\) \\(request\\_queue_2\\) \\(= [(1, 2)]\\) at \\(S_1\\) \\(request\\_queue_1\\) \\(= [(1, 1)]\\) \\(S_1\\) Receive request for CS from \\(S_2\\) : \\(request\\_queue_1\\) \\(= [(1, 1),(1, 2)]\\) (This priority is calculated based on the index value \\(i\\) ) \\(S_1\\) sends a REPLY to \\(S_2\\) \\(S_3\\) Receive request for CS from \\(S_2\\) : \\(request\\_queue_3\\) \\(= [(1, 2)]\\) \\(S_3\\) sends a REPLY to \\(S_2\\) \\(S_3\\) Receive request for CS from \\(S_1\\) : \\(request\\_queue_3\\) \\(= [(1, 1), (1, 2)]\\) \\(S_3\\) sends a REPLY to \\(S_1\\) \\(S_1\\) enters the CS \\(S_1\\) sends RELEASE message \\(S_2\\) removes \\((1,1)\\) from \\(request\\_queue_2\\) \\(S_2\\) enters the CS \\(S_3\\) removes \\((1,1)\\) from \\(request\\_queue_3\\) \\(S_2\\) sends RELEASE message \\(S_1\\) removes \\((1,2)\\) from \\(request\\_queue_1\\) \\(S_3\\) removes \\((1,2)\\) from \\(request\\_queue_3\\) Tags: !DistributedComputingIndex","title":"Week 5"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#week-5","text":"Lecturer : Barsha Mitra , BITS Pilani, Hyderabad Campus Date : 28/Aug/2021","title":"Week 5"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#topics-covered","text":"Message Ordering (cont.) Birman-Schiper-Stephenson Protocol \\(P_i\\) sends a message \\(m\\) to \\(P_j\\) \\(P_j\\) receives a message \\(m\\) to \\(P_i\\) Distributed Mutual Exclusion Types of Approaches Quorum Based Requirements of Mutual Exclusion Algorithms Performance Metrics Lamport's Algorithm Requesting the Critical Section Executing the Critical Section Releasing the Critical Section Example Problem","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#message-ordering-cont","text":"","title":"Message Ordering (cont.)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#birman-schiper-stephenson-protocol","text":"\\(C_i\\) = Vector clock of \\(P_i\\) \\(C_i[j]\\) = \\(j^{th}\\) element of \\(C_i\\) \\(tm\\) = Vector timestamp for message \\(m\\) , stamped after local clock is incremented. NOTE , we also assume that all messages taking part in this algorithm is a broadcast","title":"Birman-Schiper-Stephenson Protocol"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#p_i-sends-a-message-m-to-p_j","text":"\\(P_i\\) increments \\(C_i[i]\\) \\(P_i\\) sets the timestamp \\(tm = C_i\\) for message \\(m\\)","title":"\\(P_i\\) sends a message \\(m\\) to \\(P_j\\)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#p_j-receives-a-message-m-to-p_i","text":"When \\(P_j (j \\ne i)\\) reveives \\(m\\) with timestamp \\(tm\\) , it delays message delivery until: \\(C_j[i] = tm[i] - 1\\) , \\(P_j\\) has received all preceding messages sent by \\(P_i\\) \\(\\forall k \\le n\\) and \\(k \\ne i\\) , \\(C_j[k] \\ge tm[k]\\) , P_j has received all the messages that were received at \\(P_i\\) from other processes before \\(P_i\\) sent \\(m\\) Here we need to check if \\(P_j\\) also received \\(P_k\\) message before message from \\(P_i\\) is processed When \\(m\\) is delivered to \\(P_j\\) , update \\(P_j\\) 's vector clock, \\(\\forall i, C_j[i] = max(C_j[i], tm[i])\\) Check buffered messages to see if any can be delivered","title":"\\(P_j\\) receives a message \\(m\\) to \\(P_i\\)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#example-problem","text":"\\(P_3\\) executes a broadcast - \\(C_3 = [0, 0, 1]\\) - \\(tm_1 = [0, 0, 1]\\) \\(P_2\\) receives message \\(m_1\\) - \\(C_2 = [0, 0, 0]\\) - Condition checks: 1. \\(C_2[3] = tm_1[3] - 1\\) is TRUE 2. \\(C_2[i] \\ge tm_1[i]\\) \\(\\forall i \\le n\\) and \\(i \\ne 3\\) is TRUE - \\(C_2[i] = max(C_2[i], tm_1[i]), \\forall i\\) - \\(C_2 = [0, 0, 1]\\) \\(P_2\\) sends message \\(m_2\\) - \\(C_2 = [0, 1, 1]\\) - \\(tm_2 = [0, 1, 1]\\) \\(P_3\\) receives message \\(m_2\\) - \\(C_3 = [0, 0, 1]\\) - Condition checks: 1. \\(C_3[2] = tm_2[2] - 1\\) is TRUE 2. \\(C_3[i] \\ge tm_2[i]\\) \\(\\forall i \\le n\\) and \\(i \\ne 2\\) is TRUE - \\(C_3[i] = max(C_3[i], tm_2[i]), \\forall i\\) - \\(C_3 = [0, 1, 1]\\) \\(P_1\\) receives message \\(m_2\\) - \\(C_1 = [0, 0, 0]\\) - Condition checks: 1. \\(C_1[2] = tm_2[2] - 1\\) is TRUE 2. \\(C_1[i] \\ge tm_2[i]\\) \\(\\forall i \\le n\\) and \\(i \\ne 2\\) is FALSE - \\(m_2\\) is added to BUFFER \\(P_1\\) receives message \\(m_1\\) - \\(C_1 = [0, 0, 0]\\) - Condition checks: 1. \\(C_1[3] = tm_1[3] - 1\\) is TRUE 2. \\(C_1[i] \\ge tm_1[i]\\) \\(\\forall i \\le n\\) and \\(i \\ne 3\\) is TRUE - \\(C_1[i] = max(C_1[i], tm_1[i]), \\forall i\\) - \\(C_1 = [0, 0, 1]\\) Deliver \\(m_2\\) from BUFFER to \\(P_1\\) - \\(C_1 = [0, 0, 1]\\) - Condition checks: 1. \\(C_1[2] = tm_2[2] - 1\\) is TRUE 2. \\(C_1[i] \\ge tm_2[i]\\) \\(\\forall i \\le n\\) and \\(i \\ne 2\\) is TRUE - \\(C_1[i] = max(C_1[i], tm_1[i]), \\forall i\\) - \\(C_1 = [0, 1, 1]\\) NOTE , in the exam make sure that all the above steps are also written in the paper, annotating the diagram alone will lead to getting partial marks","title":"Example Problem"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#distributed-mutual-exclusion","text":"","title":"Distributed Mutual Exclusion"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#types-of-approaches","text":"Token based Assertion based From Recorded Lecture Quorum based","title":"Types of Approaches"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#quorum-based","text":"Each site requests permission to execute the CS from a subset of sites called quorum Quorums are formed in such a way that when two sites concurrently request access to the CS At least one site receives both the requests This site is responsible to make sure that only one request executes the CS at any time","title":"Quorum Based"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#requirements-of-mutual-exclusion-algorithms","text":"Safety Property: At any instant, only one process can execute the CS Liveness Property: A site must not wait indefinitely to execute the CS while other sites are repeatedly executing the CS Fairness: Each process gets a fair chance to execute the CS CS execution requests are executed in order of their arrival time Time is determined by a logical clock","title":"Requirements of Mutual Exclusion Algorithms"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#performance-metrics","text":"From Recorded lectures","title":"Performance Metrics"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#lamports-algorithm","text":"Every site \\(S_i\\) keeps a queue, \\(request\\_queue_i\\) \\(request\\_queue_i\\) contains mutual exclusion requests ordered by their timestamps FIFO \\(CS\\) requests are executed in increasing order of timestamps","title":"Lamport's Algorithm"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#requesting-the-critical-section","text":"When a site \\(S_i\\) wants to enter the CS, it broadcasts a \\(REQUEST(ts_i, i)\\) message to all other sites and places the request on \\(request\\_queue_i\\) . When site \\(S_j\\) receives the \\(REQUEST(ts_i, i)\\) message from site \\(S_i\\) , it places site \\(S_j\\) 's request on \\(request\\_queue_j\\) and returns a timestamped REPLY message to \\(S_i\\)","title":"Requesting the Critical Section"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#executing-the-critical-section","text":"Site \\(S_i\\) enters the CS when the following conditions hold: - L1: \\(S_i\\) has received a message with timestamp larger than \\((ts_i, i)\\) - L2: \\(S_i\\) 's request is at the top of \\(request\\_queue_i\\)","title":"Executing the Critical Section"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#releasing-the-critical-section","text":"Site \\(S_i\\) , upon exiting the CS, removes its request from the top of its request queue and broadcasts a timestamped RELEASE message to all other sites When a site \\(S_j\\) receives a RELEASE message from site \\(S_i\\) , it removes \\(S_i\\) 's request from its request queue","title":"Releasing the Critical Section"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Distributed%20Computing/Week5DC.html#example-problem_1","text":"\\(S_1\\) and \\(S_2\\) are requesting for the CS at \\(S_2\\) \\(request\\_queue_2\\) \\(= [(1, 2)]\\) at \\(S_1\\) \\(request\\_queue_1\\) \\(= [(1, 1)]\\) \\(S_1\\) Receive request for CS from \\(S_2\\) : \\(request\\_queue_1\\) \\(= [(1, 1),(1, 2)]\\) (This priority is calculated based on the index value \\(i\\) ) \\(S_1\\) sends a REPLY to \\(S_2\\) \\(S_3\\) Receive request for CS from \\(S_2\\) : \\(request\\_queue_3\\) \\(= [(1, 2)]\\) \\(S_3\\) sends a REPLY to \\(S_2\\) \\(S_3\\) Receive request for CS from \\(S_1\\) : \\(request\\_queue_3\\) \\(= [(1, 1), (1, 2)]\\) \\(S_3\\) sends a REPLY to \\(S_1\\) \\(S_1\\) enters the CS \\(S_1\\) sends RELEASE message \\(S_2\\) removes \\((1,1)\\) from \\(request\\_queue_2\\) \\(S_2\\) enters the CS \\(S_3\\) removes \\((1,1)\\) from \\(request\\_queue_3\\) \\(S_2\\) sends RELEASE message \\(S_1\\) removes \\((1,2)\\) from \\(request\\_queue_1\\) \\(S_3\\) removes \\((1,2)\\) from \\(request\\_queue_3\\) Tags: !DistributedComputingIndex","title":"Example Problem"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/%21MathematicalFoundationsIndex.html","text":"Mathematical Foundations for Data Science Index # This is an Index page for all Mathematical Foundations for Data Science Content Octave Cheat Sheet: OctaveCheatSheet Week 1 Lecture Notes: Week1MFDS Week 2 Lecture Notes: Week2MFDS Gaussian Elimination Code and Analysis in Python: GaussianEliminationPython Week 3 Lecture Notes: Week3MFDS Week 4 Lecture Notes: Week4MFDS Tags: !Semester1Index","title":"Mathematical Foundations for Data Science Index"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/%21MathematicalFoundationsIndex.html#mathematical-foundations-for-data-science-index","text":"This is an Index page for all Mathematical Foundations for Data Science Content Octave Cheat Sheet: OctaveCheatSheet Week 1 Lecture Notes: Week1MFDS Week 2 Lecture Notes: Week2MFDS Gaussian Elimination Code and Analysis in Python: GaussianEliminationPython Week 3 Lecture Notes: Week3MFDS Week 4 Lecture Notes: Week4MFDS Tags: !Semester1Index","title":"Mathematical Foundations for Data Science Index"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/GaussianEliminationPython.html","text":"Gaussian Elimination Code # Code in Python # import copy # This class is to hold matrix data class Matrix : def __init__ ( self , row : int , col : int , listOfList : list ): self . n : int = row self . m : int = col self . data : list = listOfList # This class has functions for different operations on a matrix class MatrixOperations : def print ( self , message : str , matrix : Matrix ): '''Print Matrix Input: message (A string to print before the matrix), matrix (A Matrix Object) Output: A multi line string of the Matrix data ''' print () print ( message ) for row in matrix . data : line : str = \"\" for element in row : line += str ( element ) + \" \\t \" print ( line ) print () def REF ( self , matrix : Matrix ): '''Calculate the Row Echelon Form for a Matrix Input: matrix (A Matrix Object) Output: REF (A Matrix Object holding the REF form for matrix) ''' REF : Matrix = Matrix ( matrix . n , matrix . m , matrix . data ) for i in range ( REF . n ): # Pivot the row when the pivot element is 0 if ( REF . data [ i ][ i ] == 0 ): for j in range ( i , REF . n ): # Find the row with greatest value below pivot element and swap with that row if abs ( REF . data [ j ][ i ]) > abs ( REF . data [ i ][ i ]): REF . data [ j ], REF . data [ i ] = REF . data [ i ], REF . data [ j ] for j in range ( i + 1 , REF . n ): # Doing this once so that I minimize the number of divisions ratio : float = REF . data [ j ][ i ] / REF . data [ i ][ i ] # Assign 0 hence reducing multiplication and addition by one for elements under the pivot REF . data [ j ][ i ] = 0 for k in range ( i + 1 , REF . m ): REF . data [ j ][ k ] = REF . data [ j ][ k ] - ratio * REF . data [ i ][ k ] return REF def augment ( self , matrixA : Matrix , matrixB : Matrix ): '''Augments two matrices Input: matrixA (A Matrix Object), matrixB (B Matrix Object) Output: matrix (A Matrix Object holding the REF form for matrix) ''' listOfList : list = copy . deepcopy ( matrixA . data ) for i in range ( matrixA . n ): listOfList [ i ] . extend ( matrixB . data [ i ]) matrix : Matrix = Matrix ( matrixA . n , matrixA . m + matrixB . m , listOfList ) return matrix def rank ( self , matrix : Matrix , isREF : bool = False ): '''Calculate rank of matrix Input: matrix (Matrix Object), isREF (A boolean flag that denotes if the given matrix is in REF form) Output: rank (Rank of matrix) ''' if not ref : matrix = self . REF ( matrix ) rank : int = matrix . n while ( rank - 1 >= 0 ): flag : bool = False for element in matrix . data [ rank - 1 ]: print ( element ) if element == 0 : continue flag = True if flag : break rank -= 1 return rank def backSubstitute ( self , matrix : Matrix , isREF : bool = False ): '''Solve set of linear equations given as an augmented matrix Input: matrix (Augmented Matrix Object), isREF (A boolean flag that denotes if the given matrix is in REF form) Output: x (Matrix object of the result x) ''' if not isREF : matrix = self . REF ( matrix ) n = matrix . n data = matrix . data x : list = [ 0 ] * n x [ n - 1 ] = data [ n - 1 ][ n ] / data [ n - 1 ][ n - 1 ] for i in range ( n - 2 , - 1 , - 1 ): x [ i ] = matrix . data [ i ][ n ] for j in range ( i + 1 , n ): x [ i ] = x [ i ] - data [ i ][ j ] * x [ j ] x [ i ] = x [ i ] / data [ i ][ i ] return Matrix ( 1 , n , [ x ]) def main (): print ( '=======================================================================' ) print ( 'This commandline utility accepts two matrices is Ax = b format' ) print ( 'Enter details for A: ' ) print ( 'Enter number of rows: ' ) n : int = int ( input ()) print ( 'Enter number of columns: ' ) m : int = int ( input ()) listOfList : list = [] i : int = 0 while ( i < n ): print ( 'Enter the ' + str ( i ) + ' row elements' ) row : list = list ( map ( float , input () . split ())) if len ( row ) > m : print ( 'number of elements in row greater than column count hence truncating' ) del row [ m :] print ( row ) listOfList . append ( row ) i += 1 matrixA : Matrix = Matrix ( n , m , listOfList ) print ( '=======================================================================' ) print ( 'Enter details for b: ' ) listOfList : list = [] i : int = 0 while ( i < n ): print ( 'Enter the ' + str ( i ) + ' row element' ) row : list = list ( map ( float , input () . split ())) if len ( row ) > 1 : print ( 'number of elements in row greater than 1 truncating' ) del row [ 1 :] print ( row ) listOfList . append ( row ) i += 1 matrixB : Matrix = Matrix ( n , 1 , listOfList ) print ( '=======================================================================' ) operation : MatrixOperations = MatrixOperations () operation . print ( 'Input Matrix A is:' , matrixA ) operation . print ( 'Input Matrix B is:' , matrixB ) matrix : Matrix = operation . augment ( matrixA , matrixB ) operation . print ( 'Augmented Matrix is:' , matrix ) matrix : Matrix = operation . REF ( matrix ) operation . print ( 'REF for Matrix is:' , matrix ) x : Matrix = operation . backSubstitute ( matrix , True ) operation . print ( 'Solution Matrix x is:' , x ) print ( '=======================================================================' ) if __name__ == '__main__' : main () Operations Count # Look at the function for calculating the REF for a matrix: def REF ( self , matrix : Matrix ): '''Calculate the Row Echelon Form for a Matrix Input: matrix (A Matrix Object) Output: REF (A Matrix Object holding the REF form for matrix) ''' REF : Matrix = Matrix ( matrix . n , matrix . m , matrix . data ) for i in range ( REF . n ): # Pivot the row when the pivot element is 0 if ( REF . data [ i ][ i ] == 0 ): for j in range ( i , REF . n ): # Find the row with greatest value below pivot element and swap with that row if abs ( REF . data [ j ][ i ]) > abs ( REF . data [ i ][ i ]): REF . data [ j ], REF . data [ i ] = REF . data [ i ], REF . data [ j ] # Row operations starts here for j in range ( i + 1 , REF . n ): # Doing this once so that I minimize the number of divisions ratio : float = REF . data [ j ][ i ] / REF . data [ i ][ i ] # Assign 0 hence reducing multiplication and addition by one for elements under the pivot REF . data [ j ][ i ] = 0 for k in range ( i + 1 , REF . m ): REF . data [ j ][ k ] = REF . data [ j ][ k ] - ratio * REF . data [ i ][ k ] return REF For the first Pivot element: \\[Total\\ number\\ of\\ Multiplications= (n-1)(n-1+1)\\] \\[Total\\ number\\ of\\ Additions= (n-1)(n-1+1)\\] Final counts as seen in REF function: \\[Total\\ number\\ of\\ Multiplications = \\sum_{k=1}^{n-1} (n-k)(n-k+1) = \\mathcal{O}(n^3)\\] \\[Total\\ number\\ of\\ Additions = \\sum_{k=1}^{n-1} (n-k)(n-k+1) = \\mathcal{O}(n^3)\\] \\[Total\\ number\\ of\\ Divisions = (n-1) + (n-2) + \\dots + 1 = \\sum_{k=1}^{n-1}(n-k) = \\mathcal{O}(n^2)\\] Tags: !MathematicalFoundationsIndex Week2MFDS","title":"Gaussian Elimination Code"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/GaussianEliminationPython.html#gaussian-elimination-code","text":"","title":"Gaussian Elimination Code"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/GaussianEliminationPython.html#code-in-python","text":"import copy # This class is to hold matrix data class Matrix : def __init__ ( self , row : int , col : int , listOfList : list ): self . n : int = row self . m : int = col self . data : list = listOfList # This class has functions for different operations on a matrix class MatrixOperations : def print ( self , message : str , matrix : Matrix ): '''Print Matrix Input: message (A string to print before the matrix), matrix (A Matrix Object) Output: A multi line string of the Matrix data ''' print () print ( message ) for row in matrix . data : line : str = \"\" for element in row : line += str ( element ) + \" \\t \" print ( line ) print () def REF ( self , matrix : Matrix ): '''Calculate the Row Echelon Form for a Matrix Input: matrix (A Matrix Object) Output: REF (A Matrix Object holding the REF form for matrix) ''' REF : Matrix = Matrix ( matrix . n , matrix . m , matrix . data ) for i in range ( REF . n ): # Pivot the row when the pivot element is 0 if ( REF . data [ i ][ i ] == 0 ): for j in range ( i , REF . n ): # Find the row with greatest value below pivot element and swap with that row if abs ( REF . data [ j ][ i ]) > abs ( REF . data [ i ][ i ]): REF . data [ j ], REF . data [ i ] = REF . data [ i ], REF . data [ j ] for j in range ( i + 1 , REF . n ): # Doing this once so that I minimize the number of divisions ratio : float = REF . data [ j ][ i ] / REF . data [ i ][ i ] # Assign 0 hence reducing multiplication and addition by one for elements under the pivot REF . data [ j ][ i ] = 0 for k in range ( i + 1 , REF . m ): REF . data [ j ][ k ] = REF . data [ j ][ k ] - ratio * REF . data [ i ][ k ] return REF def augment ( self , matrixA : Matrix , matrixB : Matrix ): '''Augments two matrices Input: matrixA (A Matrix Object), matrixB (B Matrix Object) Output: matrix (A Matrix Object holding the REF form for matrix) ''' listOfList : list = copy . deepcopy ( matrixA . data ) for i in range ( matrixA . n ): listOfList [ i ] . extend ( matrixB . data [ i ]) matrix : Matrix = Matrix ( matrixA . n , matrixA . m + matrixB . m , listOfList ) return matrix def rank ( self , matrix : Matrix , isREF : bool = False ): '''Calculate rank of matrix Input: matrix (Matrix Object), isREF (A boolean flag that denotes if the given matrix is in REF form) Output: rank (Rank of matrix) ''' if not ref : matrix = self . REF ( matrix ) rank : int = matrix . n while ( rank - 1 >= 0 ): flag : bool = False for element in matrix . data [ rank - 1 ]: print ( element ) if element == 0 : continue flag = True if flag : break rank -= 1 return rank def backSubstitute ( self , matrix : Matrix , isREF : bool = False ): '''Solve set of linear equations given as an augmented matrix Input: matrix (Augmented Matrix Object), isREF (A boolean flag that denotes if the given matrix is in REF form) Output: x (Matrix object of the result x) ''' if not isREF : matrix = self . REF ( matrix ) n = matrix . n data = matrix . data x : list = [ 0 ] * n x [ n - 1 ] = data [ n - 1 ][ n ] / data [ n - 1 ][ n - 1 ] for i in range ( n - 2 , - 1 , - 1 ): x [ i ] = matrix . data [ i ][ n ] for j in range ( i + 1 , n ): x [ i ] = x [ i ] - data [ i ][ j ] * x [ j ] x [ i ] = x [ i ] / data [ i ][ i ] return Matrix ( 1 , n , [ x ]) def main (): print ( '=======================================================================' ) print ( 'This commandline utility accepts two matrices is Ax = b format' ) print ( 'Enter details for A: ' ) print ( 'Enter number of rows: ' ) n : int = int ( input ()) print ( 'Enter number of columns: ' ) m : int = int ( input ()) listOfList : list = [] i : int = 0 while ( i < n ): print ( 'Enter the ' + str ( i ) + ' row elements' ) row : list = list ( map ( float , input () . split ())) if len ( row ) > m : print ( 'number of elements in row greater than column count hence truncating' ) del row [ m :] print ( row ) listOfList . append ( row ) i += 1 matrixA : Matrix = Matrix ( n , m , listOfList ) print ( '=======================================================================' ) print ( 'Enter details for b: ' ) listOfList : list = [] i : int = 0 while ( i < n ): print ( 'Enter the ' + str ( i ) + ' row element' ) row : list = list ( map ( float , input () . split ())) if len ( row ) > 1 : print ( 'number of elements in row greater than 1 truncating' ) del row [ 1 :] print ( row ) listOfList . append ( row ) i += 1 matrixB : Matrix = Matrix ( n , 1 , listOfList ) print ( '=======================================================================' ) operation : MatrixOperations = MatrixOperations () operation . print ( 'Input Matrix A is:' , matrixA ) operation . print ( 'Input Matrix B is:' , matrixB ) matrix : Matrix = operation . augment ( matrixA , matrixB ) operation . print ( 'Augmented Matrix is:' , matrix ) matrix : Matrix = operation . REF ( matrix ) operation . print ( 'REF for Matrix is:' , matrix ) x : Matrix = operation . backSubstitute ( matrix , True ) operation . print ( 'Solution Matrix x is:' , x ) print ( '=======================================================================' ) if __name__ == '__main__' : main ()","title":"Code in Python"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/GaussianEliminationPython.html#operations-count","text":"Look at the function for calculating the REF for a matrix: def REF ( self , matrix : Matrix ): '''Calculate the Row Echelon Form for a Matrix Input: matrix (A Matrix Object) Output: REF (A Matrix Object holding the REF form for matrix) ''' REF : Matrix = Matrix ( matrix . n , matrix . m , matrix . data ) for i in range ( REF . n ): # Pivot the row when the pivot element is 0 if ( REF . data [ i ][ i ] == 0 ): for j in range ( i , REF . n ): # Find the row with greatest value below pivot element and swap with that row if abs ( REF . data [ j ][ i ]) > abs ( REF . data [ i ][ i ]): REF . data [ j ], REF . data [ i ] = REF . data [ i ], REF . data [ j ] # Row operations starts here for j in range ( i + 1 , REF . n ): # Doing this once so that I minimize the number of divisions ratio : float = REF . data [ j ][ i ] / REF . data [ i ][ i ] # Assign 0 hence reducing multiplication and addition by one for elements under the pivot REF . data [ j ][ i ] = 0 for k in range ( i + 1 , REF . m ): REF . data [ j ][ k ] = REF . data [ j ][ k ] - ratio * REF . data [ i ][ k ] return REF For the first Pivot element: \\[Total\\ number\\ of\\ Multiplications= (n-1)(n-1+1)\\] \\[Total\\ number\\ of\\ Additions= (n-1)(n-1+1)\\] Final counts as seen in REF function: \\[Total\\ number\\ of\\ Multiplications = \\sum_{k=1}^{n-1} (n-k)(n-k+1) = \\mathcal{O}(n^3)\\] \\[Total\\ number\\ of\\ Additions = \\sum_{k=1}^{n-1} (n-k)(n-k+1) = \\mathcal{O}(n^3)\\] \\[Total\\ number\\ of\\ Divisions = (n-1) + (n-2) + \\dots + 1 = \\sum_{k=1}^{n-1}(n-k) = \\mathcal{O}(n^2)\\] Tags: !MathematicalFoundationsIndex Week2MFDS","title":"Operations Count"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/OctaveCheatSheet.html","text":"Octave Cheat Sheet # Define a 3x3 matrix # A = [ - 1 , 1 , 2 ; 3 , - 1 , 1 ; - 1 , 3 , 4 ] Matrix properties # A = [ - 1 , 1 , 2 ; 3 , - 1 , 1 ; - 1 , 3 , 4 ] det ( A ) Norms # A = [ - 1 , 1 , 2 ; 3 , - 1 , 1 ; - 1 , 3 , 4 ] norm ( A , 1 ) norm ( A , 2 ) norm ( A , 'fro' ) norm ( A , 'inf' ) Inverse of a matrix # A = [ - 1 , 1 , 2 ; 3 , - 1 , 1 ; - 1 , 3 , 4 ] inv ( A ) Determinant of a matrix # A = [ - 1 , 1 , 2 ; 3 , - 1 , 1 ; - 1 , 3 , 4 ] det ( A ) LU decompose a matrix # # LU decompose withoput pivot function [L, U] = lu_nopivot ( A ) n = size ( A , 1 ); % Obtain number of rows (should equal number of columns) L = eye ( n ); % Start L off as identity and populate the lower triangular half slowly for k = 1 : n % For each row k, access columns from k+1 to the end and divide by % the diagonal coefficient at A(k ,k) L ( k + 1 : n , k ) = A ( k + 1 : n , k ) / A ( k , k ); % For each row k+1 to the end, perform Gaussian elimination % In the end, A will contain U for l = k + 1 : n A ( l , :) = A ( l , :) - L ( l , k ) * A ( k , :); end end U = A ; end # LU decompose [ L , U , I ] = lu ( A ) Solve linear system of equations # A = [ 2 , 1 , - 2 ; 1 , - 1 , - 1 ; 1 , 1 , 3 ] B = [ 3 ; 0 ; 12 ] A \\ B %%%%%%%%%%%%%%%%%%%%% % ans = % % % % 3.5000 % % 1.0000 % % 2.5000 % %%%%%%%%%%%%%%%%%%%%%","title":"Octave Cheat Sheet"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/OctaveCheatSheet.html#octave-cheat-sheet","text":"","title":"Octave Cheat Sheet"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/OctaveCheatSheet.html#define-a-3x3-matrix","text":"A = [ - 1 , 1 , 2 ; 3 , - 1 , 1 ; - 1 , 3 , 4 ]","title":"Define a 3x3 matrix"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/OctaveCheatSheet.html#matrix-properties","text":"A = [ - 1 , 1 , 2 ; 3 , - 1 , 1 ; - 1 , 3 , 4 ] det ( A )","title":"Matrix properties"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/OctaveCheatSheet.html#norms","text":"A = [ - 1 , 1 , 2 ; 3 , - 1 , 1 ; - 1 , 3 , 4 ] norm ( A , 1 ) norm ( A , 2 ) norm ( A , 'fro' ) norm ( A , 'inf' )","title":"Norms"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/OctaveCheatSheet.html#inverse-of-a-matrix","text":"A = [ - 1 , 1 , 2 ; 3 , - 1 , 1 ; - 1 , 3 , 4 ] inv ( A )","title":"Inverse of a matrix"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/OctaveCheatSheet.html#determinant-of-a-matrix","text":"A = [ - 1 , 1 , 2 ; 3 , - 1 , 1 ; - 1 , 3 , 4 ] det ( A )","title":"Determinant of a matrix"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/OctaveCheatSheet.html#lu-decompose-a-matrix","text":"# LU decompose withoput pivot function [L, U] = lu_nopivot ( A ) n = size ( A , 1 ); % Obtain number of rows (should equal number of columns) L = eye ( n ); % Start L off as identity and populate the lower triangular half slowly for k = 1 : n % For each row k, access columns from k+1 to the end and divide by % the diagonal coefficient at A(k ,k) L ( k + 1 : n , k ) = A ( k + 1 : n , k ) / A ( k , k ); % For each row k+1 to the end, perform Gaussian elimination % In the end, A will contain U for l = k + 1 : n A ( l , :) = A ( l , :) - L ( l , k ) * A ( k , :); end end U = A ; end # LU decompose [ L , U , I ] = lu ( A )","title":"LU decompose a matrix"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/OctaveCheatSheet.html#solve-linear-system-of-equations","text":"A = [ 2 , 1 , - 2 ; 1 , - 1 , - 1 ; 1 , 1 , 3 ] B = [ 3 ; 0 ; 12 ] A \\ B %%%%%%%%%%%%%%%%%%%%% % ans = % % % % 3.5000 % % 1.0000 % % 2.5000 % %%%%%%%%%%%%%%%%%%%%%","title":"Solve linear system of equations"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week1MFDS.html","text":"Week 1 # Lecturer : G Venkiteswaran, Faculty for BITS Pilani Date : 25/Jul/2021 Topics Covered # Matrices and their types REF and RREF Rank, its computation and properties Determinent, it's computation and properties Consistency and inconsistency of linear systems Modelling using linear equations Vector and matrix norms Matrices and their types # A rectangular array of numbers or functions enclosed in brrackets are considered as matrices (Matrix for singular). All of the following are valid matrices: \\[A = \\begin{bmatrix}a & b & c & d\\\\e & f & g & h\\end{bmatrix},B = \\begin{bmatrix}a & b & c\\\\d & e & f\\\\g & h & i\\end{bmatrix},C = \\begin{bmatrix}a\\\\b\\\\c\\end{bmatrix},D = \\begin{bmatrix}a & b & c\\end{bmatrix}\\] Each element within the matrix ( \\(a\\) , \\(b\\) , \\(c\\) etc) are called entities Each matrix has a size that is represented as \\(n\\ x\\ m\\) where \\(n\\) is the number of rows and \\(m\\) is the number of columns. In the above example the array \\(A\\) has a size of \\(2\\ x\\ 4\\) out of the last two matrices in the above example the matrix \\(C\\) is what we call a column matrix and \\(D\\) is called a row matrix. The other word for it is column/row Vector and Vectors are usually denoted with lower case characters like this: \\[a = \\begin{bmatrix}1\\\\2\\\\3\\end{bmatrix},b = \\begin{bmatrix}4 & 5 & 6\\end{bmatrix}\\] Two matrices are equal if both have the same size (same number of rows and columns) and every element in one matrix matches with every element in the other (including their positions) Matrix operations # Addition : Two matrices can be added if both the matrices have the same size . The addition is merely adding the same values that have the same position on both matrices. Consider the following example \\[ \\begin{aligned} A = \\begin{bmatrix}1 & 2 & 3 & 4\\\\5 & 6 & 7 & 8\\end{bmatrix}, B = \\begin{bmatrix}9 & 10 & 11 & 12\\\\13 & 14 & 15 & 16\\end{bmatrix} \\\\ \\\\ C = A + B = \\begin{bmatrix}1 & 2 & 3 & 4\\\\5 & 6 & 7 & 8\\end{bmatrix} + \\begin{bmatrix}9 & 10 & 11 & 12\\\\13 & 14 & 15 & 16\\end{bmatrix} \\\\ \\\\ C = \\begin{bmatrix}1 + 9 & 2 + 10 & 3 + 11 & 4 + 12\\\\5 + 13 & 6 + 14 & 7 + 15 & 8 + 16\\end{bmatrix} \\\\ \\\\ C = \\begin{bmatrix}10 & 12 & 14 & 16\\\\18 & 20 & 22 & 24\\end{bmatrix} \\end{aligned} \\] Addition adhere to the following rules: \\[ A + B = B + A \\] \\[ (A + B) + C = A + (B + C) \\] \\[ A + 0 = A \\] \\[ A + (-A) = 0 \\] Multiplication : Two matrices can only be multiplied if the number of columns in the first part of the product equals the number of rows in the second part of the product to yield a product matrix with a size of the number of rows of the first part and the number of columns of the second part. The size of matrices after a product would look like this: \\[A_(m*p) * B_(p*n) = C_(m*n)\\] The formulae for calculating the entities within the product matrix are as follows, given that \\(i\\) and \\(j\\) are the row and column number that identifies element of that matrix: \\[A\\ is\\ an\\ array\\ with\\ a_{ij}\\ for\\ entities\\ and\\ have\\ size\\ m*n\\] \\[B\\ is\\ an\\ array\\ with\\ b_{ij}\\ for\\ entites\\ and\\ have\\ size\\ n*p\\] \\[C\\ is\\ the\\ product\\ array\\ with\\ c_{ij}\\ for\\ entites\\ and\\ have\\ size\\ n*m, then\\] \\[c_{ij} = \\begin{equation}\\sum_{k = 1}^{n}a_{ik}b_{kj}\\end{equation}\\] \\[where\\ j = 1, . . . , m\\ and\\ k = 1, . . . , p\\] Tags: !MathematicalFoundationsIndex","title":"Week 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week1MFDS.html#week-1","text":"Lecturer : G Venkiteswaran, Faculty for BITS Pilani Date : 25/Jul/2021","title":"Week 1"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week1MFDS.html#topics-covered","text":"Matrices and their types REF and RREF Rank, its computation and properties Determinent, it's computation and properties Consistency and inconsistency of linear systems Modelling using linear equations Vector and matrix norms","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week1MFDS.html#matrices-and-their-types","text":"A rectangular array of numbers or functions enclosed in brrackets are considered as matrices (Matrix for singular). All of the following are valid matrices: \\[A = \\begin{bmatrix}a & b & c & d\\\\e & f & g & h\\end{bmatrix},B = \\begin{bmatrix}a & b & c\\\\d & e & f\\\\g & h & i\\end{bmatrix},C = \\begin{bmatrix}a\\\\b\\\\c\\end{bmatrix},D = \\begin{bmatrix}a & b & c\\end{bmatrix}\\] Each element within the matrix ( \\(a\\) , \\(b\\) , \\(c\\) etc) are called entities Each matrix has a size that is represented as \\(n\\ x\\ m\\) where \\(n\\) is the number of rows and \\(m\\) is the number of columns. In the above example the array \\(A\\) has a size of \\(2\\ x\\ 4\\) out of the last two matrices in the above example the matrix \\(C\\) is what we call a column matrix and \\(D\\) is called a row matrix. The other word for it is column/row Vector and Vectors are usually denoted with lower case characters like this: \\[a = \\begin{bmatrix}1\\\\2\\\\3\\end{bmatrix},b = \\begin{bmatrix}4 & 5 & 6\\end{bmatrix}\\] Two matrices are equal if both have the same size (same number of rows and columns) and every element in one matrix matches with every element in the other (including their positions)","title":"Matrices and their types"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week1MFDS.html#matrix-operations","text":"Addition : Two matrices can be added if both the matrices have the same size . The addition is merely adding the same values that have the same position on both matrices. Consider the following example \\[ \\begin{aligned} A = \\begin{bmatrix}1 & 2 & 3 & 4\\\\5 & 6 & 7 & 8\\end{bmatrix}, B = \\begin{bmatrix}9 & 10 & 11 & 12\\\\13 & 14 & 15 & 16\\end{bmatrix} \\\\ \\\\ C = A + B = \\begin{bmatrix}1 & 2 & 3 & 4\\\\5 & 6 & 7 & 8\\end{bmatrix} + \\begin{bmatrix}9 & 10 & 11 & 12\\\\13 & 14 & 15 & 16\\end{bmatrix} \\\\ \\\\ C = \\begin{bmatrix}1 + 9 & 2 + 10 & 3 + 11 & 4 + 12\\\\5 + 13 & 6 + 14 & 7 + 15 & 8 + 16\\end{bmatrix} \\\\ \\\\ C = \\begin{bmatrix}10 & 12 & 14 & 16\\\\18 & 20 & 22 & 24\\end{bmatrix} \\end{aligned} \\] Addition adhere to the following rules: \\[ A + B = B + A \\] \\[ (A + B) + C = A + (B + C) \\] \\[ A + 0 = A \\] \\[ A + (-A) = 0 \\] Multiplication : Two matrices can only be multiplied if the number of columns in the first part of the product equals the number of rows in the second part of the product to yield a product matrix with a size of the number of rows of the first part and the number of columns of the second part. The size of matrices after a product would look like this: \\[A_(m*p) * B_(p*n) = C_(m*n)\\] The formulae for calculating the entities within the product matrix are as follows, given that \\(i\\) and \\(j\\) are the row and column number that identifies element of that matrix: \\[A\\ is\\ an\\ array\\ with\\ a_{ij}\\ for\\ entities\\ and\\ have\\ size\\ m*n\\] \\[B\\ is\\ an\\ array\\ with\\ b_{ij}\\ for\\ entites\\ and\\ have\\ size\\ n*p\\] \\[C\\ is\\ the\\ product\\ array\\ with\\ c_{ij}\\ for\\ entites\\ and\\ have\\ size\\ n*m, then\\] \\[c_{ij} = \\begin{equation}\\sum_{k = 1}^{n}a_{ik}b_{kj}\\end{equation}\\] \\[where\\ j = 1, . . . , m\\ and\\ k = 1, . . . , p\\] Tags: !MathematicalFoundationsIndex","title":"Matrix operations"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html","text":"Week 2 # Lecturer : G Venkiteswaran, Faculty for BITS Pilani Date : 01/Aug/2021 Topics Covered # Vector Norms Common Norms Equivalence of Norms Matrix Norms Solution of Linear systems Gauss elimination methods Pitfalls of Gauss Elimination Algorithms Division By Zero Round-off Errors Operations Count for Gaussian Elimination Ill Conditioned Systems Condition Number Vector Norms # A function \\(|| . || : R^n \\rightarrow R\\) is a vector norm if it has the following properties: 1. \\(||x|| \\ge 0\\) for any vector \\(x \\in R^n\\) , and \\(||x|| = 0\\) if and only if \\(x = 0\\) . 2. \\(||\\alpha x|| = |\\alpha|\\ ||x||\\) for any vector \\(x \\in R^n\\) , and any scalar \\(\\alpha \\in R\\) . 3. \\(||x+y|| \\le ||x|| + ||y||\\) for any vectors \\(x,\\ y \\in R^n\\) . This property is called the triangle inequality (Sum of two sides is greater than the third) 4. Also to be noted is if the dimension value \\(n=1\\) then the modulus value function ( \\(|x|\\) ) is a vector norm. (where mod function is \\(|x| = \\max(x,-x)\\) ) Common Norms # The most commonly used vector norm is belong to the family of \\(l_p\\) norms, which are defined by: \\[||x||_p = \\begin{equation}(\\sum_{i = 1}^{n}|x|^p)^{1/p}\\end{equation}\\] The following \\(l_p\\) norms are more used than others: 1. \\(p=1:\\ The\\ l_1\\ norm\\ ||x||_1 = |x_1| + |x_2| + \\dots + |x_n|\\) 2. \\(p=2:\\ The\\ l_2\\ norm\\ or\\ Euclidean\\ norm ||x||_2 = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2} = \\sqrt{x^Tx}\\) 3. \\(p=1:\\ The\\ l_\\infty\\ norm\\ ||x||_{\\infty} = \\max_{1\\le i\\le n}|x_i|\\) Equivalence of Norms # We say that two vector norms are equivalent if there exists constants \\(C_1\\) and \\(C_2\\) , that are independent of \\(x\\) , such that for any vector \\(x \\in R^n\\) \\[C_1||x||_\\alpha \\le ||x||_\\beta \\le C_2||x||_\\alpha\\] Remember that the above equation does not show any relation between \\(C_1\\) or \\(C_2\\) or \\(\\alpha\\) or \\(\\beta\\) Consider the above example, we take the two forms of \\(l_p\\) norms, the \\(l_1\\) and the \\(l_\\infty\\) . You can see that each term of \\(||x||_1\\) is \\(\\le \\ ||x||_\\infty\\) hence we can say that the total sum \\(||x||_1 \\le n||x||_\\infty\\) . This shows the equivalence of \\(l_1\\) and \\(l_\\infty\\) norm. Matrix Norms # Some commonly used matrix norms are: 1. Matrix norm corresponding to vector \\(1\\) -norm is maximum modulus/absolute column sum: \\[||A||_1 = \\max_{j}(\\begin{equation} \\sum_{i=1}^{n} |a_{ij}| \\end{equation})\\] You can see that we take the maximum of the absolute sum of the columns Matrix norm corresponding to vector \\(\\infty\\) -norm is maximum modulus/absolute column sum: \\[||A||_\\infty = \\max_{i}(\\begin{equation} \\sum_{j=1}^{n} |a_{ij}| \\end{equation})\\] You can see that we take the maximum of the absolute sum of the columns Matrix norm corresponding to vector \\(2\\) -norm is given as: \\[||A||_2 = ||A||_F = \\sqrt{\\sum_{i=1}^{M}\\sum_{j=1}^{N} |a_{ij}|^2}\\] Question asked : What is the significance of a norm for a matrix? Visualizing the above through Octave commands: >> A = [ 2 , 1 , 1 ; 3 , 2 , 1 ; - 2 , 0 , 1 ] A = 2 1 1 3 2 1 - 2 0 1 >> norm ( A , 1 ) ans = 7 >> norm ( A , 'inf' ) ans = 6 >> norm ( A , 'fro' ) ans = 5 >> norm ( A , 2 ) ans = 4.6758 Question to ask : if \\(||A||_2 = |A||_F\\) why are the results different in the above octave result? Solution of Linear systems # Matrix form of Linear Systems We can take m linear equations and write them as a single Vector equation like \\[Ax=b\\] Where coefficient matrix \\(A = [a_{jk}]\\) is the \\(m\\ x\\ n\\) matrix Where all the variables are in the vector \\(x = [x_k]\\) with size \\(n\\ x\\ 1\\) Where all the constants are in vector b \\(b = [b_j]\\) with size \\(m\\ x\\ 1\\) Gauss Elimination # Consider the above image, at the end of gauss elimination, the row echelon form would hold a rank say \\(r\\) , then we can say: 1. The matrix is a upper triangular form 2. The first \\(r\\) rows are non zero 3. Exactly \\(m-r\\) rows would be zero rows 4. The rhs can have two possibilities: 1. The rhs has exactly \\(m-r\\) zero rows: This means there is atleast one solution for the linear system of equations 2. The rhs has less than \\(m-r\\) zero rows: This means the equations are inconsistent 5. If the system is consistent and the \\(r = n\\) then there is exactly one solution 6. In case of infinitely many solutions, take arbiterary values for \\(x_{r+1},\\dots x_n\\) , then solve the \\(r\\) th equation for \\(x_r\\) , then the \\((r-1)\\) st equaation for \\(x_{r-1}\\) , and so on up the line till the solutions are found 7. The complexity for calculating this is \\(O(n^3)\\) , where \\(n\\) is the number of rows Pitfalls of Gauss Elimination Algorithms # Division By Zero # It is possible that in the above considered example, the denominator can end up being a zero value. For example consider the example below: Here the coefficient of \\(x_1\\) in the first equation is 0, hence to avoid the above issue we can interchange rows \\(R_1 \\rightarrow R_2\\) . This is called pivoting and that will make it easier to bring about the REF form for the matrix. Round-off Errors # Because computers can carry limited number of significant figures, round off errors will occur and they will propagate for every iteration. This problem becomes very apparent when the number of equations become very large. To avoid this one must use double-precision numbers. Albeit it being slow, the result will be more correct Operations Count for Gaussian Elimination # The details for the operation counts for several operations done is explained in the page here: GaussianEliminationPython#Operations Count Ill Conditioned Systems # Consider the following system of linear equations: \\(x_1 + 2x_2 = 10\\) \\(1.1x_1 + 2x_2 = 10.4\\) We get the values of \\(x_1 = 4.0\\) and \\(x_2 = 3.0\\) If let us say that when someone modeled this equation they had made a miscalculation leading to changing one of the coefficients of \\(x_1\\) from \\(1.1\\) to \\(1.05\\) making the above system of equations as follows: \\(x_1 + 2x_2 = 10\\) \\(1.05x_1 + 2x_2 = 10.4\\) We get the values of \\(x_1 = 8.0\\) and \\(x_2 = 1.0\\) From the above two results you can see that there is a big variance in the results when there is a small change in the coefficients, such system of equations are said to be ill conditioned Condition Number # The condition number is a metric that is used to see if a system of equations is ill informed or not. Condition number of a non singular matrix A is defined as: \\[\\kappa(A) = ||A|| ||A^{-1}||\\] By convention \\(\\kappa(A) = \\infty\\) if \\(A\\) is singular (A matrix whose determinant is 0, and hence has no inverse) Example: \\[A = \\begin{bmatrix}2 & -1 & 1\\\\1 & 0 & 1\\\\3 & -1 & 4\\end{bmatrix},\\ ||A||_1 = 6,\\ ||A||_\\infty = 8\\] \\[A^{-1} = \\begin{bmatrix}0.5 & 1.5 & -0.5\\\\-0.5 & 2.5 & -0.5\\\\-0.5 & -0.5 & 0.5\\end{bmatrix},\\ ||A^{-1}||_1 = 4.5,\\ ||A^{-1}||_\\infty = 3.5\\] \\[\\kappa_1(A) = 6 * 4.5\\] \\[\\kappa_\\infty(A) = 8 * 3.5\\] Once conditions are calculated, we can say that whenever the condition number is in the range of 4 to 5 then they are well informed but if the condition is around a 100 or so then they are more ill conditioned in nature . There is no clear distinction between well informed and ill informed system of equations Tags: !MathematicalFoundationsIndex","title":"Week 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#week-2","text":"Lecturer : G Venkiteswaran, Faculty for BITS Pilani Date : 01/Aug/2021","title":"Week 2"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#topics-covered","text":"Vector Norms Common Norms Equivalence of Norms Matrix Norms Solution of Linear systems Gauss elimination methods Pitfalls of Gauss Elimination Algorithms Division By Zero Round-off Errors Operations Count for Gaussian Elimination Ill Conditioned Systems Condition Number","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#vector-norms","text":"A function \\(|| . || : R^n \\rightarrow R\\) is a vector norm if it has the following properties: 1. \\(||x|| \\ge 0\\) for any vector \\(x \\in R^n\\) , and \\(||x|| = 0\\) if and only if \\(x = 0\\) . 2. \\(||\\alpha x|| = |\\alpha|\\ ||x||\\) for any vector \\(x \\in R^n\\) , and any scalar \\(\\alpha \\in R\\) . 3. \\(||x+y|| \\le ||x|| + ||y||\\) for any vectors \\(x,\\ y \\in R^n\\) . This property is called the triangle inequality (Sum of two sides is greater than the third) 4. Also to be noted is if the dimension value \\(n=1\\) then the modulus value function ( \\(|x|\\) ) is a vector norm. (where mod function is \\(|x| = \\max(x,-x)\\) )","title":"Vector Norms"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#common-norms","text":"The most commonly used vector norm is belong to the family of \\(l_p\\) norms, which are defined by: \\[||x||_p = \\begin{equation}(\\sum_{i = 1}^{n}|x|^p)^{1/p}\\end{equation}\\] The following \\(l_p\\) norms are more used than others: 1. \\(p=1:\\ The\\ l_1\\ norm\\ ||x||_1 = |x_1| + |x_2| + \\dots + |x_n|\\) 2. \\(p=2:\\ The\\ l_2\\ norm\\ or\\ Euclidean\\ norm ||x||_2 = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2} = \\sqrt{x^Tx}\\) 3. \\(p=1:\\ The\\ l_\\infty\\ norm\\ ||x||_{\\infty} = \\max_{1\\le i\\le n}|x_i|\\)","title":"Common Norms"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#equivalence-of-norms","text":"We say that two vector norms are equivalent if there exists constants \\(C_1\\) and \\(C_2\\) , that are independent of \\(x\\) , such that for any vector \\(x \\in R^n\\) \\[C_1||x||_\\alpha \\le ||x||_\\beta \\le C_2||x||_\\alpha\\] Remember that the above equation does not show any relation between \\(C_1\\) or \\(C_2\\) or \\(\\alpha\\) or \\(\\beta\\) Consider the above example, we take the two forms of \\(l_p\\) norms, the \\(l_1\\) and the \\(l_\\infty\\) . You can see that each term of \\(||x||_1\\) is \\(\\le \\ ||x||_\\infty\\) hence we can say that the total sum \\(||x||_1 \\le n||x||_\\infty\\) . This shows the equivalence of \\(l_1\\) and \\(l_\\infty\\) norm.","title":"Equivalence of Norms"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#matrix-norms","text":"Some commonly used matrix norms are: 1. Matrix norm corresponding to vector \\(1\\) -norm is maximum modulus/absolute column sum: \\[||A||_1 = \\max_{j}(\\begin{equation} \\sum_{i=1}^{n} |a_{ij}| \\end{equation})\\] You can see that we take the maximum of the absolute sum of the columns Matrix norm corresponding to vector \\(\\infty\\) -norm is maximum modulus/absolute column sum: \\[||A||_\\infty = \\max_{i}(\\begin{equation} \\sum_{j=1}^{n} |a_{ij}| \\end{equation})\\] You can see that we take the maximum of the absolute sum of the columns Matrix norm corresponding to vector \\(2\\) -norm is given as: \\[||A||_2 = ||A||_F = \\sqrt{\\sum_{i=1}^{M}\\sum_{j=1}^{N} |a_{ij}|^2}\\] Question asked : What is the significance of a norm for a matrix? Visualizing the above through Octave commands: >> A = [ 2 , 1 , 1 ; 3 , 2 , 1 ; - 2 , 0 , 1 ] A = 2 1 1 3 2 1 - 2 0 1 >> norm ( A , 1 ) ans = 7 >> norm ( A , 'inf' ) ans = 6 >> norm ( A , 'fro' ) ans = 5 >> norm ( A , 2 ) ans = 4.6758 Question to ask : if \\(||A||_2 = |A||_F\\) why are the results different in the above octave result?","title":"Matrix Norms"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#solution-of-linear-systems","text":"Matrix form of Linear Systems We can take m linear equations and write them as a single Vector equation like \\[Ax=b\\] Where coefficient matrix \\(A = [a_{jk}]\\) is the \\(m\\ x\\ n\\) matrix Where all the variables are in the vector \\(x = [x_k]\\) with size \\(n\\ x\\ 1\\) Where all the constants are in vector b \\(b = [b_j]\\) with size \\(m\\ x\\ 1\\)","title":"Solution of Linear systems"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#gauss-elimination","text":"Consider the above image, at the end of gauss elimination, the row echelon form would hold a rank say \\(r\\) , then we can say: 1. The matrix is a upper triangular form 2. The first \\(r\\) rows are non zero 3. Exactly \\(m-r\\) rows would be zero rows 4. The rhs can have two possibilities: 1. The rhs has exactly \\(m-r\\) zero rows: This means there is atleast one solution for the linear system of equations 2. The rhs has less than \\(m-r\\) zero rows: This means the equations are inconsistent 5. If the system is consistent and the \\(r = n\\) then there is exactly one solution 6. In case of infinitely many solutions, take arbiterary values for \\(x_{r+1},\\dots x_n\\) , then solve the \\(r\\) th equation for \\(x_r\\) , then the \\((r-1)\\) st equaation for \\(x_{r-1}\\) , and so on up the line till the solutions are found 7. The complexity for calculating this is \\(O(n^3)\\) , where \\(n\\) is the number of rows","title":"Gauss Elimination"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#pitfalls-of-gauss-elimination-algorithms","text":"","title":"Pitfalls of Gauss Elimination Algorithms"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#division-by-zero","text":"It is possible that in the above considered example, the denominator can end up being a zero value. For example consider the example below: Here the coefficient of \\(x_1\\) in the first equation is 0, hence to avoid the above issue we can interchange rows \\(R_1 \\rightarrow R_2\\) . This is called pivoting and that will make it easier to bring about the REF form for the matrix.","title":"Division By Zero"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#round-off-errors","text":"Because computers can carry limited number of significant figures, round off errors will occur and they will propagate for every iteration. This problem becomes very apparent when the number of equations become very large. To avoid this one must use double-precision numbers. Albeit it being slow, the result will be more correct","title":"Round-off Errors"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#operations-count-for-gaussian-elimination","text":"The details for the operation counts for several operations done is explained in the page here: GaussianEliminationPython#Operations Count","title":"Operations Count for Gaussian Elimination"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#ill-conditioned-systems","text":"Consider the following system of linear equations: \\(x_1 + 2x_2 = 10\\) \\(1.1x_1 + 2x_2 = 10.4\\) We get the values of \\(x_1 = 4.0\\) and \\(x_2 = 3.0\\) If let us say that when someone modeled this equation they had made a miscalculation leading to changing one of the coefficients of \\(x_1\\) from \\(1.1\\) to \\(1.05\\) making the above system of equations as follows: \\(x_1 + 2x_2 = 10\\) \\(1.05x_1 + 2x_2 = 10.4\\) We get the values of \\(x_1 = 8.0\\) and \\(x_2 = 1.0\\) From the above two results you can see that there is a big variance in the results when there is a small change in the coefficients, such system of equations are said to be ill conditioned","title":"Ill Conditioned Systems"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week2MFDS.html#condition-number","text":"The condition number is a metric that is used to see if a system of equations is ill informed or not. Condition number of a non singular matrix A is defined as: \\[\\kappa(A) = ||A|| ||A^{-1}||\\] By convention \\(\\kappa(A) = \\infty\\) if \\(A\\) is singular (A matrix whose determinant is 0, and hence has no inverse) Example: \\[A = \\begin{bmatrix}2 & -1 & 1\\\\1 & 0 & 1\\\\3 & -1 & 4\\end{bmatrix},\\ ||A||_1 = 6,\\ ||A||_\\infty = 8\\] \\[A^{-1} = \\begin{bmatrix}0.5 & 1.5 & -0.5\\\\-0.5 & 2.5 & -0.5\\\\-0.5 & -0.5 & 0.5\\end{bmatrix},\\ ||A^{-1}||_1 = 4.5,\\ ||A^{-1}||_\\infty = 3.5\\] \\[\\kappa_1(A) = 6 * 4.5\\] \\[\\kappa_\\infty(A) = 8 * 3.5\\] Once conditions are calculated, we can say that whenever the condition number is in the range of 4 to 5 then they are well informed but if the condition is around a 100 or so then they are more ill conditioned in nature . There is no clear distinction between well informed and ill informed system of equations Tags: !MathematicalFoundationsIndex","title":"Condition Number"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week3MFDS.html","text":"Week 3 # Lecturer : G Venkiteswaran, Faculty for BITS Pilani Date : 08/Aug/2021 Topics Covered # Gauss Elimination Analysis (cont.) # A time analysis of the algorithm for different size of inputs is shown below: Algorithm n = 1000 n = 10000 Elimination 0.7 s 11 min Back substitution 0.001 s 0.1 s Corollary # Doolittle L Crout Method U Cholesky's Method \\(U = L^T\\) when A is symmetric and positive definite - A is written as \\(A = U^T U\\) . Hence we may have \\(U^T Ux = b\\) Iterative methods # Gauss Jacobi # Computations for each element can be done in parallel since each step independent Convergence is generally faster than Jacobi method Gauss Seidel # The gauss seidel method can be applied to any matrix with non zero elements on diagonal, but convergence is not guaranteed Computations for each element cannot be done in parallel since each step depends on the previous calculation Convergence is generally faster than Jacobi method Tags: !MathematicalFoundationsIndex","title":"Week 3"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week3MFDS.html#week-3","text":"Lecturer : G Venkiteswaran, Faculty for BITS Pilani Date : 08/Aug/2021","title":"Week 3"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week3MFDS.html#topics-covered","text":"","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week3MFDS.html#gauss-elimination-analysis-cont","text":"A time analysis of the algorithm for different size of inputs is shown below: Algorithm n = 1000 n = 10000 Elimination 0.7 s 11 min Back substitution 0.001 s 0.1 s","title":"Gauss Elimination Analysis (cont.)"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week3MFDS.html#corollary","text":"Doolittle L Crout Method U Cholesky's Method \\(U = L^T\\) when A is symmetric and positive definite - A is written as \\(A = U^T U\\) . Hence we may have \\(U^T Ux = b\\)","title":"Corollary"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week3MFDS.html#iterative-methods","text":"","title":"Iterative methods"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week3MFDS.html#gauss-jacobi","text":"Computations for each element can be done in parallel since each step independent Convergence is generally faster than Jacobi method","title":"Gauss Jacobi"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week3MFDS.html#gauss-seidel","text":"The gauss seidel method can be applied to any matrix with non zero elements on diagonal, but convergence is not guaranteed Computations for each element cannot be done in parallel since each step depends on the previous calculation Convergence is generally faster than Jacobi method Tags: !MathematicalFoundationsIndex","title":"Gauss Seidel"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week4MFDS.html","text":"Week 4 # Lecturer : G Venkiteswaran, Faculty for BITS Pilani Date : 22/Aug/2021 Topics Covered # Field Field # Axioms Vector Space # Axioms: Inner Product # Linear Dependence and Independence of Vectors # S_1 = {1rs Note, 5rs Note} Here S is not independent since 5 1rs notes can become 5rs S_2 = {Coffee powder, Water, Milk, Sugar} Here S is linearly independent Basis and Dimension # Tags: !MathematicalFoundationsIndex","title":"Week 4"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week4MFDS.html#week-4","text":"Lecturer : G Venkiteswaran, Faculty for BITS Pilani Date : 22/Aug/2021","title":"Week 4"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week4MFDS.html#topics-covered","text":"Field","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week4MFDS.html#field","text":"Axioms","title":"Field"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week4MFDS.html#vector-space","text":"Axioms:","title":"Vector Space"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week4MFDS.html#inner-product","text":"","title":"Inner Product"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week4MFDS.html#linear-dependence-and-independence-of-vectors","text":"S_1 = {1rs Note, 5rs Note} Here S is not independent since 5 1rs notes can become 5rs S_2 = {Coffee powder, Water, Milk, Sugar} Here S is linearly independent","title":"Linear Dependence and Independence of Vectors"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week4MFDS.html#basis-and-dimension","text":"Tags: !MathematicalFoundationsIndex","title":"Basis and Dimension"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html","text":"Week 5 # Lecturer : G Venkiteswaran, Faculty for BITS Pilani Date : 29/Aug/2021 Topics Covered # S LI, LS(s) = V S is a basus No. of elements of S is dimension Several bases for V but dimenstion is the same Any set that contains 0 is LD Any non zero vector is LI Construction of Basis \\(S = {v_1}\\) \\(v_1 \\ne 0\\) Span S = Example Consider a 3d space of x, y, z, and a span set as: S = {(1, 0, 0)} We can say that this does not span the entire spce, but it does cover the x axis Now if we take: S = {(1, 0, 0), (0, 1, 0), (0, 0, 1)} This set S is the Basis of Row space and common space # Row Space # Column Space # Null Space/ Solution Space # Example # Theorem Nullity and Rank of Matrix # Example # Linear Transformation # Range and Kernel # Rank Nullity Theorem Example # Example 1: Example 2: Tags: !MathematicalFoundationsIndex","title":"Week 5"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#week-5","text":"Lecturer : G Venkiteswaran, Faculty for BITS Pilani Date : 29/Aug/2021","title":"Week 5"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#topics-covered","text":"S LI, LS(s) = V S is a basus No. of elements of S is dimension Several bases for V but dimenstion is the same Any set that contains 0 is LD Any non zero vector is LI Construction of Basis \\(S = {v_1}\\) \\(v_1 \\ne 0\\) Span S = Example Consider a 3d space of x, y, z, and a span set as: S = {(1, 0, 0)} We can say that this does not span the entire spce, but it does cover the x axis Now if we take: S = {(1, 0, 0), (0, 1, 0), (0, 0, 1)} This set S is the Basis of","title":"Topics Covered"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#row-space-and-common-space","text":"","title":"Row space and common space"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#row-space","text":"","title":"Row Space"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#column-space","text":"","title":"Column Space"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#null-space-solution-space","text":"","title":"Null Space/ Solution Space"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#example","text":"Theorem","title":"Example"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#nullity-and-rank-of-matrix","text":"","title":"Nullity and Rank of Matrix"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#example_1","text":"","title":"Example"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#linear-transformation","text":"","title":"Linear Transformation"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#range-and-kernel","text":"","title":"Range and Kernel"},{"location":"Knowledge%20Base/All%20Semesters/Semester%201/Mathematical%20Foundations%20for%20Data%20Science/Week5MFDS.html#rank-nullity-theorem-example","text":"Example 1: Example 2: Tags: !MathematicalFoundationsIndex","title":"Rank Nullity Theorem Example"}]}